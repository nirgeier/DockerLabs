{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DockerLabs Hands-on","text":"<ul> <li>Welcome to the lab workspace that accompanies the DockerLabs project. </li> <li>Each folder below is a self-contained lab that you can complete independently to sharpen specific containerization skills. </li> <li>Follow the README file in each lab for detailed steps.</li> </ul>"},{"location":"#how-to-use-those-labs","title":"How to Use Those Labs","text":"<ul> <li>There are several ways to run the Docker Labs. </li> <li>Choose the method that works best for you.<ul> <li> Killercoda  (Recommended)</li> <li>\ud83d\udcdc From Source</li> <li> Using Google Cloud Shell</li> </ul> </li> </ul>  Killercoda  (Recommended)\ud83d\udcdc From Source Using Google Cloud Shell <ul> <li>The easiest way to get started with the labs</li> <li>Learn Docker in your browser without any local installation</li> </ul> <p>\ud83c\udf10 Launch on Killercoda</p> <p>Benefits:</p> <ul> <li>No installation required</li> <li>Pre-configured environment</li> <li>Works on any device with a web browser</li> <li>All tools pre-installed</li> </ul> <p>For those who prefer to run it directly on their machine:</p> <p><pre><code># Clone the repository\ngit clone https://github.com/nirgeier/DockerLabs.git\n# Change to the Labs directory\ncd DockerLabs/Labs\n# Start with the Docker CLI lab\ncd 001-DockerCli\n# Follow the instructions in the README of each lab\ncat README.md\n</code></pre> Prerequisites:</p> <ul> <li>Ansible installed on your system</li> <li>A Unix-like operating system (Linux, macOS, or Windows with WSL)</li> <li>Basic command-line tools</li> </ul> <ul> <li>Google Cloud Shell provides a free, browser-based environment with all necessary tools pre-installed.</li> <li>Click on the <code>Open in Google Cloud Shell</code> button below:</li> </ul> <p></p> <ul> <li>The repository will automatically be cloned into a free Cloud instance.</li> <li>Use CTRL + click to open it in a new window.</li> <li>Follow the instructions in the README of each lab.</li> </ul> <p>Benefits:</p> <ul> <li>No local installation required</li> <li>Pre-configured environment</li> <li>Works on any device with a web browser</li> <li>All tools pre-installed</li> <li>Free tier available</li> </ul>"},{"location":"#lab-index","title":"Lab Index","text":""},{"location":"#001-docker-cli","title":"001 - Docker CLI","text":"<p>Practice the core Docker CLI commands for running, inspecting, and managing containers.</p> <p> Get started</p>"},{"location":"#002-dockerfile-basics","title":"002 - Dockerfile Basics","text":"<p>Build your first Node.js container image from a Dockerfile and publish it to a registry.</p> <p> Get started</p>"},{"location":"#003-dockerfile-multi-stage","title":"003 - Dockerfile Multi-Stage","text":"<p>Learn how multi-stage Dockerfiles produce lean images across build targets.</p> <p> Get started</p>"},{"location":"#004-local-registry","title":"004 - Local Registry","text":"<p>Stand up a private registry, retag images, and push or pull them locally.</p> <p> Get started</p>"},{"location":"#005-docker-compose-stack","title":"005 - Docker Compose Stack","text":"<p>Orchestrate a WordPress and MariaDB stack with Docker Compose.</p> <p> Get started</p>"},{"location":"#006-compose-environments","title":"006 - Compose Environments","text":"<p>Structure Compose files and env vars for dev and prod workflows.</p> <p> Get started</p>"},{"location":"#007-docker-compose-fragments","title":"007 - Docker Compose Fragments","text":"<p>Learn advanced Docker Compose features with fragments and modular configurations.</p> <p> Get started</p>"},{"location":"#008-cri-crictl","title":"008 - CRI <code>crictl</code>","text":"<p>Learn about container runtime interface tooling using crictl.</p> <p> Get started</p>"},{"location":"#009-dive-layers","title":"009 - Dive Layers","text":"<p>Explore image layer creation and visualize them with the dive tool.</p> <p> Get started</p>"},{"location":"#010-docker-bake","title":"010 - Docker Bake","text":"<p>Use Docker Buildx Bake to coordinate complex, multi-target image builds.</p> <p> Get started</p>"},{"location":"#011-security-trust","title":"011 - Security &amp; Trust","text":"<p>Learn advanced Docker security features and best practices for container security.</p> <p> Get started</p>"},{"location":"#012-gvisor-seccomp","title":"012 - gVisor Seccomp","text":"<p>Apply a gVisor runtime profile to block privileged syscalls inside a container.</p> <p> Get started</p>"},{"location":"#013-onictl","title":"013 - onictl","text":"<p>Learn about container networking with onictl.</p> <p> Get started</p>"},{"location":"#100-hands-on-intro","title":"100 - Hands-On Intro","text":"<p>Guided Node.js exercise covering the full build, run, and publish workflow.</p> <p> Get started</p>"},{"location":"#tasks","title":"Tasks","text":"Task Description DockerCommit In-class exercise for capturing container changes with <code>docker commit</code>. DockerDebug Debugging challenge: troubleshoot a crashing Flask container and fix missing configurations. DockerfileAdvanced Advanced Dockerfile exercise covering BuildKit secrets, caching, and health checks. DockerLogs In-class exercise for running cowsay container, managing logs, and debugging. MultiStage In-class exercise for creating multi-stage Dockerfiles with alpine and node images. <p>Happy learning and hacking with Docker!</p>"},{"location":"001-DockerCli/","title":"001-DockerCli","text":""},{"location":"001-DockerCli/#lab-001-docker-cli","title":"Lab 001 - Docker CLI","text":"<ul> <li>This lab covers the basics of the Docker CLI.</li> <li>You will learn how to run, manage, and interact with Docker containers using various Docker commands.</li> <li>By the end of this lab, you will have a solid understanding of how to use the Docker CLI for container management.</li> </ul>"},{"location":"001-DockerCli/#docker-cli-commands","title":"Docker CLI Commands","text":"<ul> <li><code>docker attach</code></li> <li><code>docker build</code></li> <li><code>docker commit</code></li> <li><code>docker cp</code></li> <li><code>docker create</code></li> <li><code>docker exec</code></li> <li><code>docker images</code></li> <li><code>docker inspect</code></li> <li><code>docker kill</code></li> <li><code>docker logs</code></li> <li><code>docker pause</code></li> <li><code>docker ps</code></li> <li><code>docker pull</code></li> <li><code>docker push</code></li> <li><code>docker rename</code></li> <li><code>docker restart</code></li> <li><code>docker rm</code></li> <li><code>docker rmi</code></li> <li><code>docker run</code></li> <li><code>docker run -a</code></li> <li><code>docker run -d</code></li> <li><code>docker run -it</code></li> <li><code>docker run -name</code></li> <li><code>docker run -p</code></li> <li><code>docker run &lt;command&gt;</code></li> <li><code>docker start</code></li> <li><code>docker stats</code></li> <li><code>docker stop</code></li> <li><code>docker top</code></li> <li><code>docker unpause</code></li> <li><code>docker wait</code></li> </ul>"},{"location":"001-DockerCli/#docker-attach","title":"<code>docker attach</code>","text":"<ul> <li><code>docker attach</code> is used to attach your terminal to a running container.</li> <li>This is useful when you want to interact with a container that is already running.</li> <li>For example, if you have a container running a shell or an application that accepts input, you can use <code>docker attach</code> to connect to it.</li> </ul> <pre><code># Spin an alpine image and start it in the background\ndocker run -it -d --name alpine001 alpine sleep 10000\n\n# Attach to the container and start a shell inside it\ndocker attach alpine001\n</code></pre> <p>Detaching from a Container</p> <ul> <li>To detach from the container without stopping it, you can use the CTRL + P followed by CTRL + Q key combination.    </li> <li>This will leave the container running in the background while you return to your terminal.  <ul> <li>This detach sequence only works if the container was started with the <code>-it</code> flags (interactive with a TTY)</li> </ul> </li> </ul>"},{"location":"001-DockerCli/#docker-build","title":"<code>docker build</code>","text":"<ul> <li><code>docker build</code> creates a Docker image from a Dockerfile.</li> <li> <p>This is one of the most important commands for creating custom images.</p> <pre><code># Create a simple Dockerfile\nmkdir -p /tmp/docker-build-example\ncd /tmp/docker-build-example\n\ncat &lt;&lt;'EOF' &gt; Dockerfile\nFROM alpine:latest\nRUN apk add --no-cache curl\nCMD [\"echo\", \"Hello from custom image\"]\nEOF\n\n# Build the image with a tag\ndocker build -t my-custom-alpine:v1.0 .\n\n# Build with a different tag\ndocker build -t my-custom-alpine:latest .\n\n# Build without using cache\ndocker build --no-cache -t my-custom-alpine:v1.0 .\n\n# Test the built image\ndocker run --rm my-custom-alpine:v1.0\n\n# Clean up\ncd -\nrm -rf /tmp/docker-build-example\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-commit","title":"<code>docker commit</code>","text":"<ul> <li> <p><code>docker commit</code> will create a new images out of an existing container.</p> <pre><code># Clean up and remove the container\ndocker stop nginx\ndocker rm   nginx\n\n# Spin the container\ndocker  run  -it -d -p 8888:80 --name nginx nginx\n\n# Wait for the container to start\nsleep 5\n\n# Prepare the desired welcome page\ndocker  exec -it nginx sh -c \"                  \\\n        echo 'This is a custom message ... ' &gt;  \\\n        /usr/share/nginx/html/index.html\"\n\n# Verify the changes\ncurl -s localhost:8888\n\n# Create the custom image\ndocker commit nginx nirgeier/custom-nginx-image\n\n# Clean up and remove the container\ndocker stop nginx\ndocker rm   nginx\n\n# Push to the registry\ndocker push nirgeier/custom-nginx-image\n\n# Clean up and remove the container\ndocker stop custom-nginx\ndocker rm   custom-nginx\n\n# Push to the registry\ndocker  run -it -d --name custom-nginx  \\\n        -p 8888:80                      \\\n        nirgeier/custom-nginx-image\n\n# Wait for the container to start\nsleep 5\n\n# Verify the changes\ncurl -s localhost:8888\n\n# Clean up and remove the container\ndocker stop custom-nginx\ndocker rm   custom-nginx\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-cp","title":"<code>docker cp</code>","text":"<ul> <li><code>docker cp</code> is used to copy files between the container and the host</li> <li>Lets spin a container and then lets grab the logs of this container to our host</li> </ul> <p>Copying files from and to a Container</p> <p>Since container are \u201cfile system\u201d we can grab files even when the container is stopped.</p> <ul> <li> <p>Example 1 - Copy file from Container to Host</p> <pre><code># Spin a container\ndocker run -it -d --name nginx -p 8888:80 nginx\n\n# grab the nginx default configuration \ndocker cp nginx:/etc/nginx/nginx.conf nginx.conf \n\n# Verify that the file exists locally\ncat nginx.conf \n</code></pre> </li> <li> <p>Example 2 - Copy file from Host to Container</p> <ul> <li>In the second example we will upload file to our container</li> <li>We will change the default nginx welcome page with our own page</li> </ul> <pre><code># Prepare the desired welcome page\necho 'Welcome to the world of Docker' &gt; index.html\n\n# Copy the file to the container \ndocker cp index.html nginx:/usr/share/nginx/html\n\n# Test the changes to the container\ncurl -s localhost:8888\n\n# Clean up and remove the container\ndocker stop nginx\ndocker rm   nginx\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-create","title":"<code>docker create</code>","text":"<ul> <li><code>docker create</code> creates a new container but does not start it.</li> <li>This is useful when you want to prepare a container and start it later.     <pre><code># Create a container without starting it\ndocker create --name my-nginx nginx\n\n# Verify the container is created but not running\ndocker ps -a | grep my-nginx\n\n# Create a container with port mapping\ndocker create --name web-server -p 8080:80 nginx\n\n# Create with environment variables\ndocker create --name db-container -e POSTGRES_PASSWORD=secret postgres\n\n# Create with volume mount\ndocker create --name data-container -v /data alpine\n\n# Start the created container\ndocker start my-nginx\n\n# Clean up\ndocker stop my-nginx\ndocker rm my-nginx web-server db-container data-container\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-exec","title":"<code>docker exec</code>","text":"<ul> <li>Execute a command in a running container     <pre><code># Remove old containers with the same name\ndocker stop alpine001\ndocker rm   alpine001\n\n# Spin an alpine image\ndocker run -it -d --name alpine001 alpine sleep 10000\n\n# Test that curl is not installed on the container\ndocker exec -it alpine001 curl\n\n# Install a new package on the container\ndocker exec -it alpine001 apk add curl\n\n# Test that curl is installed\ndocker exec -it alpine001 curl codewizard.co.il\n\n# Interact with the alpine image and open bash shell\ndocker exec -it alpine001 sh\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-images","title":"<code>docker images</code>","text":"<ul> <li><code>docker images</code> lists all Docker images on your system.</li> <li> <p>This command helps you see what images you have available locally.</p> <pre><code># List all images\ndocker images\n\n# List images with specific format\ndocker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\"\n\n# List all image IDs\ndocker images -q\n\n# List dangling images (images with no tag)\ndocker images -f \"dangling=true\"\n\n# Filter images by name\ndocker images alpine\n\n# Show all images including intermediate layers\ndocker images -a\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-inspect","title":"<code>docker inspect</code>","text":"<ul> <li><code>docker inspect</code> provides detailed information about Docker objects (containers, images, volumes, networks).</li> <li>Returns a JSON array with all the metadata.     <pre><code># Create a container for inspection\ndocker run -d --name nginx-inspect -p 8080:80 nginx\n\n# Inspect a container\ndocker inspect nginx-inspect\n\n# Get specific information using format flag\ndocker inspect --format='{{.State.Running}}' nginx-inspect\n\n# Get IP address of container\ndocker inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' nginx-inspect\n\n# Inspect an image\ndocker inspect nginx:latest\n\n# Get image creation date\ndocker inspect --format='{{.Created}}' nginx:latest\n\n# Clean up\ndocker stop nginx-inspect\ndocker rm nginx-inspect\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-kill","title":"<code>docker kill</code>","text":"<ul> <li><code>docker kill</code> immediately terminates a running container.</li> <li>Unlike <code>docker stop</code>, it sends SIGKILL by default (no graceful shutdown).     <pre><code># Create a running container\ndocker run -d --name kill-test alpine sleep 10000\n\n# Kill the container immediately\ndocker kill kill-test\n\n# Verify the container is stopped\ndocker ps -a | grep kill-test\n\n# Kill with specific signal\ndocker run -d --name kill-test2 nginx\ndocker kill --signal=SIGTERM kill-test2\n\n# Kill multiple containers\ndocker run -d --name c1 alpine sleep 1000\ndocker run -d --name c2 alpine sleep 1000\ndocker kill c1 c2\n\n# Clean up\ndocker rm kill-test kill-test2 c1 c2\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-logs","title":"<code>docker logs</code>","text":"<ul> <li><code>docker logs</code> fetches the logs of a container.</li> <li>Useful for debugging and monitoring container output.</li> <li>By default, it shows all logs since the container started.</li> <li>You can use various options to filter and format the logs.     <pre><code># Create a container that generates logs\ndocker run -d --name log-example alpine sh -c \"while true; do echo 'Hello from container'; sleep 2; done\"\n\n# View container logs\ndocker logs log-example\n\n# Follow log output (like tail -f)\ndocker logs -f log-example\n\n# Show only last 10 lines\ndocker logs --tail 10 log-example\n\n# Show logs with timestamps\ndocker logs -t log-example\n\n# Show logs since specific time\ndocker logs --since 5m log-example\n\n# Combine options\ndocker logs -f --tail 5 -t log-example\n\n# Clean up (press Ctrl+C to stop following logs)\ndocker stop log-example\ndocker rm log-example\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-pause","title":"<code>docker pause</code>","text":"<ul> <li><code>docker pause</code> suspends all processes in a container.</li> <li> <p>The container continues to exist but is frozen.</p> <pre><code># Create a running container\ndocker run -d --name pause-test alpine sh -c \"while true; do echo 'Running'; sleep 1; done\"\n\n# Pause the container\ndocker pause pause-test\n\n# Verify the container is paused\ndocker ps -a | grep pause-test\n\n# Try to see logs (no new logs while paused)\ndocker logs --tail 5 pause-test\n\n# Note: Container remains paused until unpaused\n# See docker unpause to resume\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-ps","title":"<code>docker ps</code>","text":"<ul> <li>The \u201cproblem\u201d with the previous command is that the container is not removed once it exits.</li> <li>Lets look at the list of containers that we have right now on the host machine     <pre><code># List exiting containers on our host machine\n\n# Display running containers\ndocker ps\n\n# Display all containers\ndocker ps -a\n\n# Display all containers ids\ndocker ps -aq\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-pull","title":"<code>docker pull</code>","text":"<ul> <li><code>docker pull</code> downloads an image from a Docker registry (like Docker Hub).</li> <li>This command is useful when you want to download an image without running it immediately.     <pre><code># Pull the latest version of an image\ndocker pull alpine:latest\n\n# Pull a specific version\ndocker pull nginx:1.21\n\n# Pull from a specific registry\ndocker pull gcr.io/google-containers/busybox\n\n# Pull all tags of a repository\ndocker pull --all-tags alpine\n\n# Verify the pulled image\ndocker images | grep alpine\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-push","title":"<code>docker push</code>","text":"<ul> <li><code>docker push</code> uploads an image to a Docker registry.</li> <li>You need to be logged in to the registry and have proper permissions.     <pre><code># Tag an image for pushing (replace 'yourusername' with your Docker Hub username)\ndocker tag alpine:latest yourusername/my-alpine:v1.0\n\n# Login to Docker Hub (you'll be prompted for credentials)\n# docker login\n\n# Push the image to Docker Hub\n# docker push yourusername/my-alpine:v1.0\n\n# Push all tags\n# docker push --all-tags yourusername/my-alpine\n\n# Note: The push commands are commented out to prevent accidental pushes\n# Uncomment and replace 'yourusername' with your actual username when ready to use\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-rename","title":"<code>docker rename</code>","text":"<ul> <li><code>docker rename</code> changes the name of an existing container.</li> <li> <p>Useful for organizing or clarifying container purposes.</p> <pre><code># Create a container with a generic name\ndocker run -d --name old-name alpine sleep 10000\n\n# Rename the container\ndocker rename old-name new-name\n\n# Verify the new name\ndocker ps | grep new-name\n\n# Clean up\ndocker stop new-name\ndocker rm new-name\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-restart","title":"<code>docker restart</code>","text":"<ul> <li><code>docker restart</code> stops and then starts a container.</li> <li> <p>Combines <code>docker stop</code> and <code>docker start</code> in one command.</p> <pre><code># Create a running container\ndocker run -d --name restart-test nginx\n\n# Restart the container (default 10 second grace period)\ndocker restart restart-test\n\n# Restart with custom timeout\ndocker restart -t 30 restart-test\n\n# Restart multiple containers\ndocker run -d --name r1 alpine sleep 1000\ndocker run -d --name r2 alpine sleep 1000\ndocker restart r1 r2\n\n# Clean up\ndocker stop restart-test r1 r2\ndocker rm restart-test r1 r2\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-rm","title":"<code>docker rm</code>","text":"<ul> <li>Lets clean and remove the containers which are not running anymore</li> <li><code>docker rm</code> removes one or more stopped containers from your system.</li> <li>This helps free up system resources by deleting containers that are no longer needed.</li> </ul> <p>Removing Containers</p> <ul> <li>You <code>cannot</code> remove a running container without stopping it first.</li> <li>Use <code>docker ps -a</code> to list all containers (including stopped ones) before removing them.</li> <li>Warning: This action is irreversible.</li> </ul> <ul> <li>Example:     <pre><code># Remove all stopped containers\n# We use docker rm with the previous command we learned docker ps\ndocker rm $(docker ps -aq)\n\n# Verify that only running containers are still running\ndocker ps -a\n\n# Remove a specific container (must be stopped first)\ndocker stop nginx\ndocker rm nginx\n\n# Force remove a running container\ndocker rm -f nginx\n\n# Remove multiple containers\ndocker rm container1 container2 container3\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-rmi","title":"<code>docker rmi</code>","text":"<ul> <li><code>docker rmi</code> removes one or more Docker images from your system.</li> <li>This helps free up disk space by removing unused images.</li> <li>You cannot remove an image that is being used by a running container.</li> <li>If you need to remove such an image, you must stop and remove the container using it first.</li> <li>Tip: Use <code>docker ps -a</code> to list all containers (including stopped ones) before removing them.     <pre><code># Remove a specific image\ndocker rmi alpine:latest\n\n# Remove multiple images\ndocker rmi image1:tag1 image2:tag2\n\n# Remove image by ID\ndocker rmi abc123def456\n\n# Force remove an image (even if containers are using it)\ndocker rmi -f nginx:latest\n\n# Remove all dangling images (untagged images)\ndocker rmi $(docker images -f \"dangling=true\" -q)\n\n# Remove all images\n# WARNING: This removes ALL images on your system\n# docker rmi $(docker images -q)\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-run","title":"<code>docker run</code>","text":"<ul> <li>The <code>run</code> command container many options (flags), we will not cover all of them</li> <li>docs.docker.com - run</li> <li>Run your first container:      <pre><code># Run the first container\ndocker run hello-world\n\n### Output:\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n...\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-run-a","title":"<code>docker run -a</code>","text":"<ul> <li>The <code>--attach</code> [<code>-a</code>] flag tells docker run to bind to the container\u2019s <code>STDIN</code>, <code>STDOUT</code> or <code>STDERR</code>.      <pre><code># Pass input from stdin to container\ndocker run -a stdout alpine echo \"Docker rocks !!\"\n\n# Redirect stdout logs to a file\ndocker run -a stdout -a stderr alpine echo 'Docker rocks again !!' &gt; log.txt 2&gt;&amp;1\n\n# Print the log content\ncat log.txt\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-run-d","title":"<code>docker run -d</code>","text":"<ul> <li>Spin up the container which will run in the background</li> <li>By default when you spin a docker container it will attach itself to the current terminal.</li> <li>In order to avoid it we will use the -d flag to specify that the container should be running in the background.     <pre><code># Spin an nginx in the background.\n# Add a sleep timeout so that the container will not exit immediately\ndocker run -d alpine sleep 10000\n\n# Verify that the container is still running\ndocker ps -a\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-run-it","title":"<code>docker run -it</code>","text":"<p>Interactive Terminal</p> <ul> <li>The flags <code>-it</code> stands for:  <code>-i</code> [<code>--interactive</code>]   keeps the container\u2019s STDIN open, and lets you send input to the container through standard input.   <code>-t</code> [<code>--tty</code>]   Attaches a pseudo-TTY to the container, connecting your terminal to the I/O streams of the container.</li> </ul> <ul> <li>Example - Run an interactive shell inside an alpine container     <pre><code># Execute a command on the container and interact with the container\n# This command will change the password for root user\ndocker run -it alpine passwd root\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-run-name","title":"<code>docker run -name</code>","text":"<ul> <li>By default the container will be assigned a semi-random name based upon the following code: docker-ce/names-generator.go</li> <li>We can assign our desired name to the container with the <code>--name</code> option     <pre><code># Spin an nginx in the background.\n# Add a sleep timeout so that the container will not exit immediately\ndocker run --name alpine001 alpine\n\n# Verify that the container has been created with the given name\ndocker ps -a |  grep alpine001\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-run-p","title":"<code>docker run -p</code>","text":"<p>Port Mapping</p> <ul> <li>We can specify the exact ports we wish to open <code>-p</code> or open them all <code>-P</code> </li> </ul> <ul> <li>Run a container and connect to a port on the host which will be used to connect to the container     <pre><code># Execute an nginx container and test the container\n\n# Remove any containers with the same name\ndocker stop nginx\ndocker rm   nginx\n\n# We will combine few flags here\ndocker  run   -it  --rm     \\\n              -d            \\\n              -p 8888:80    \\\n              --name nginx  \\\n              nginx\n\n# Wait for the container to be created\nsleep 3\n\n# test the container\ncurl -s localhost:8888\n\n# Remove the container\ndocker kill nginx\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-start","title":"<code>docker start</code>","text":"<ul> <li><code>docker start</code> starts one or more stopped containers.</li> <li>Unlike <code>docker run</code>, this command starts an existing container.</li> <li>It does not create a new container.     <pre><code># Create a container but don't start it immediately\ndocker create --name my-alpine alpine echo \"Hello World\"\n\n# Start the container\ndocker start my-alpine\n\n# Start and attach to container output\ndocker start -a my-alpine\n\n# Start multiple containers\ndocker start container1 container2 container3\n\n# Start a stopped container interactively\ndocker run -it --name interactive-alpine alpine sh\n# (exit the shell to stop the container)\ndocker start -ai interactive-alpine\n\n# Clean up\ndocker rm my-alpine interactive-alpine\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-stats","title":"<code>docker stats</code>","text":"<ul> <li><code>docker stats</code> displays a live stream of resource usage statistics for containers.</li> <li>Shows CPU, memory, network I/O, and disk I/O usage.</li> <li>Useful for monitoring container performance in real-time.</li> <li>Can be used to identify resource bottlenecks and optimize container performance.</li> <li>Supports filtering and formatting options for customized output.     <pre><code># Create some containers\ndocker run -d --name stats-test1 nginx\ndocker run -d --name stats-test2 alpine sleep 10000\n\n# Display stats for all running containers (live stream)\n# Press Ctrl+C to exit\ndocker stats\n\n# Display stats for specific containers\ndocker stats stats-test1 stats-test2\n\n# Display stats without streaming (single snapshot)\ndocker stats --no-stream\n\n# Custom format\ndocker stats --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\"\n\n# Clean up\ndocker stop stats-test1 stats-test2\ndocker rm stats-test1 stats-test2\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-stop","title":"<code>docker stop</code>","text":"<ul> <li><code>docker stop</code> stops one or more running containers gracefully.</li> <li> <p>Sends SIGTERM signal first, then SIGKILL after grace period.</p> <pre><code># Create a running container\ndocker run -d --name test-nginx nginx\n\n# Stop the container (default 10 second grace period)\ndocker stop test-nginx\n\n# Stop with custom timeout\ndocker stop -t 30 test-nginx\n\n# Stop multiple containers\ndocker stop container1 container2 container3\n\n# Stop all running containers\ndocker stop $(docker ps -q)\n\n# Verify container is stopped\ndocker ps -a | grep test-nginx\n\n# Clean up\ndocker rm test-nginx\n</code></pre> </li> </ul>"},{"location":"001-DockerCli/#docker-top","title":"<code>docker top</code>","text":"<ul> <li><code>docker top</code> displays the running processes inside a container.</li> <li>Similar to the Linux <code>top</code> command but for containers.   <pre><code># Create a running container\ndocker run -d --name top-test nginx\n\n# Display running processes in the container\ndocker top top-test\n\n# Display with custom ps options\ndocker top top-test aux\n\n# Display specific columns\ndocker top top-test -eo pid,comm\n\n# Create a busier container to see more processes\ndocker run -d --name busy-container alpine sh -c \"sleep 100 &amp; sleep 200 &amp; sleep 300 &amp; wait\"\ndocker top busy-container\n\n# Clean up\ndocker stop top-test busy-container\ndocker rm top-test busy-container\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-unpause","title":"<code>docker unpause</code>","text":"<ul> <li><code>docker unpause</code> resumes all processes in a paused container.</li> <li>Used in conjunction with <code>docker pause</code>.   <pre><code># Create and pause a container\ndocker run -d --name unpause-test alpine sh -c \"while true; do echo 'Running'; sleep 1; done\"\ndocker pause unpause-test\n\n# Verify container is paused\ndocker ps -a | grep unpause-test\n\n# Unpause the container\ndocker unpause unpause-test\n\n# Verify container is running again\ndocker ps | grep unpause-test\n\n# Check logs to see it resumed\ndocker logs --tail 5 unpause-test\n\n# Clean up\ndocker stop unpause-test\ndocker rm unpause-test\n</code></pre></li> </ul>"},{"location":"001-DockerCli/#docker-wait","title":"<code>docker wait</code>","text":"<ul> <li><code>docker wait</code> blocks until one or more containers stop.</li> <li> <p>Returns the exit code of the container.</p> <pre><code># Create a container that will exit after 5 seconds\ndocker run -d --name wait-test alpine sh -c \"sleep 5; exit 42\"\n\n# Wait for the container to exit and get the exit code\necho \"Waiting for container to exit...\"\ndocker wait wait-test\n# This will return 42 after 5 seconds\n\n# Wait for multiple containers\ndocker run -d --name w1 alpine sh -c \"sleep 3; exit 0\"\ndocker run -d --name w2 alpine sh -c \"sleep 2; exit 1\"\ndocker wait w1 w2\n\n# Clean up\ndocker rm wait-test w1 w2\n</code></pre> </li> </ul>"},{"location":"002-DockerFile/","title":"002-DockerFile","text":""},{"location":"002-DockerFile/#lab-002-create-a-basic-container-using-dockerfile","title":"Lab 002 - Create a basic container using Dockerfile","text":"<ul> <li>In this lab we will create our first container using <code>Dockerfile</code></li> <li>The container will be used to serve a simple <code>NodeJs</code> web server</li> <li>No NodeJs knowledge is required</li> <li>You will need to create, build, tag &amp; push your container to DockerHub</li> <li> <p>The lab is divided into the several tasks.</p> <ul> <li>01. Prepare the server code</li> <li>02. Test the <code>server.js</code> code</li> <li>03. Write the <code>Dockerfile</code></li> <li>04. Build the image</li> <li>05. Login to DockerHub</li> <li>06. Push the image to DockerHub</li> <li>07. Verify the push</li> <li>08. Test the image</li> <li>09. Test the server</li> <li>10. Clean up</li> </ul> </li> </ul>"},{"location":"002-DockerFile/#01-prepare-the-server-code","title":"01. Prepare the server code","text":"<ul> <li>Our container will include the following NodeJs simple web server</li> <li>Copy the code below and save it to a file named <code>server.js</code> <pre><code>//\n// Filename: server.js\n//\n// Simple NodeJs Server\n// The server is listening by default to port 8888\n//\n\n// import the HTTP module\nvar http = require('http');\n\n// Define a port we want to listen to\n// Later on we will pass the port as env parameter\n// Default port is set to 8888\nconst PORT= process.env.PORT || 8888; \n\n// Create the server and listen for requests\n// Create the server and listen for requests\nhttp.createServer((request, response)=&gt;{\n    response.end('Server is running.!! You asked for: ' + request.url);\n}).listen(PORT, ()=&gt;{\n    // Callback is triggered when server is getting a request\n    console.log(\"Server listening on: http://localhost:%s\", PORT);\n});\n</code></pre></li> </ul>"},{"location":"002-DockerFile/#02-test-the-serverjs-code","title":"02. Test the <code>server.js</code> code","text":"<ul> <li>Before we \u201cpack\u201d our code in Docker image lets test the code</li> <li>We will test the code inside <code>nodejs</code> docker      <pre><code># Test the node code\n#   --rm            =   remove the container when done\n#   -d              =   run in detached mode\n#   -p              =   open the required ports\n#   -v              =   volume\n#   -w              =   workdir\n#   --name          =   the container name\n#   node            =   Execute a nodejs container to test our code\n#   node server.js  =   Execute the code\ndocker   run --rm -d       \\\n  -v     $(pwd):/usr/src  \\\n  -w     /usr/src         \\\n  -p     8888:8888        \\\n  --name node_server      \\\n  node                    \\\n  node server.js   \n</code></pre></li> </ul>"},{"location":"002-DockerFile/#03-write-the-dockerfile","title":"03. Write the <code>Dockerfile</code>","text":"<ul> <li>Now lets create a <code>Dockerfile</code> with the code we just created above</li> <li>The <code>Dockerfile</code> will be based upon <code>nodejs</code> image and will include our <code>server.js</code> <pre><code>#\n# Filename: Dockerfile\n#\n# Use node as our base image\nFROM      node\n\n# Optional: Set working directory\nWORKDIR   /usr/src\n\n# Copy the server code to our working directory [.]\nCOPY      server.js .\n\n# Mark the port which will required for the server\nEXPOSE    8888\n\n# Start the server when the container is started\nCMD       [\"node\", \"./server.js\"]\n</code></pre></li> </ul>"},{"location":"002-DockerFile/#04-build-the-image","title":"04 - Build the image","text":"<ul> <li>Once we have the docker file we can build the image</li> <li>Once the image is ready we will push it to DockerHub so you will need an account.</li> <li>We will name the image: \u201cYour Dockerhub username/repository:version\u201d     <pre><code>###\n### Build the image\n### Tag the image with the following \n###     DockerHub username/repository:version\n###\ndocker build -t nirgeier/docker-labs-002 .\n</code></pre></li> </ul>"},{"location":"002-DockerFile/#05-login-to-dockerhub","title":"05. Login to DockerHub","text":"<ul> <li>Login to DockerHub</li> <li>Execute <code>docker login</code> and enter your Docker Hub credentials when prompted</li> <li>If you don\u2019t have a DockerHub account, create one at https://hub.docker.com/signup</li> <li>You will need to push the image to DockerHub in the next step</li> </ul>"},{"location":"002-DockerFile/#06-push-the-image-to-dockerhub","title":"06. - Push the image to DockerHub","text":"<p>Docker Login Required</p> <p>You must login to Docker Hub before you can push to DockerHub</p> <ul> <li>Example: <code>docker push username/image:tag</code> </li> </ul>"},{"location":"002-DockerFile/#07-verify-the-push","title":"07. Verify the push","text":"<ul> <li>Login to your DockerHub account and verify that the image exists under your DockerHub account.</li> </ul>"},{"location":"002-DockerFile/#08-test-the-image","title":"08 - Test the image","text":"<ul> <li>Last step is to test our image</li> <li>To do so we will pull and run the image from DockerHub</li> <li>Once the container is started we will test the server     <pre><code>###\n### Pull the image from DockerHub\n###  Replace the image tag with your image tag\n### \ndocker   run -d               \\\n        --name 002-container \\\n        -p 8888:8888         \\\n        nirgeier/docker-labs-002\n\n### Check that the container is working as expected\ndocker logs 002-container         \n</code></pre></li> </ul>"},{"location":"002-DockerFile/#09-test-the-server","title":"09. Test the server","text":"<ul> <li> <p>Test the server that he is running on docker.</p> <pre><code># Test the server that he is running on docker\ncurl -s localhost:8888\n\n### ExpectedOutput:\nServer is running.!! You asked for: /\n</code></pre> </li> </ul>"},{"location":"002-DockerFile/#10-clean-up","title":"10. Clean up","text":"<ul> <li>Stop and remove the container     <pre><code># Stop the container\n# If we used --rm the container should remove itself\ndocker stop 002-container\n\n# If not used --rm - remove the container\ndocker rm 002-container\n</code></pre></li> </ul>"},{"location":"003-DockerFile-MultiStage/","title":"003-DockerFile-MultiStage","text":""},{"location":"003-DockerFile-MultiStage/#lab-003-writing-docker-multi-stage-build","title":"Lab 003 - Writing Docker multi-stage build","text":"<ul> <li>In this lab we will learn how to write a multi-stage Docker file</li> <li>A multistage build allows you to use multiple images to build a final product. </li> <li>In a multistage build, you have a single Dockerfile which build up multiple images inside it to help build the final image.</li> </ul>"},{"location":"003-DockerFile-MultiStage/#why-use-multistage-builds","title":"Why Use Multistage Builds?","text":"<ul> <li> <p> Reduce Image Size</p> <ul> <li>Use a minimal base image for the final stage</li> <li>Only copy necessary artifacts to the final image</li> <li>Exclude build tools and intermediate files from production image</li> </ul> </li> <li> <p> Improve Security</p> <ul> <li>Exclude build tools and secrets from the runtime image</li> <li>Limit the attack surface by using a smaller final image</li> <li>Use a non-root user in the final stage</li> <li>Reduce vulnerabilities by minimizing installed packages</li> </ul> </li> <li> <p> Better Build Performance</p> <ul> <li>Leverage Docker\u2019s layer caching mechanism to speed up builds</li> <li>Only rebuild stages that have changed</li> <li>Each stage can be built and tested independently</li> <li>Parallel stage execution when possible</li> </ul> </li> <li> <p> Cleaner and More Maintainable Dockerfiles</p> <ul> <li>Separate concerns by using multiple named stages</li> <li>No need for manual cleanup of build dependencies</li> <li>Easier to read and maintain with clear stage purposes</li> <li>Use meaningful stage names for better clarity</li> <li>Add comments to explain each stage\u2019s role</li> </ul> </li> <li> <p> Flexible Dependency Management</p> <ul> <li>Install build dependencies in one stage and runtime dependencies in another</li> <li>Use different base images optimized for each stage (e.g., <code>golang:alpine</code> for build, <code>alpine</code> for runtime)</li> <li>Use the best-suited image for each stage without bloating the final image</li> </ul> </li> <li> <p> Simplified CI/CD Pipelines</p> <ul> <li>Combine build, test, and deploy stages in a single Dockerfile</li> <li>Use <code>--target</code> flag to build specific stages for different environments</li> <li>Consistent build process across development and production</li> </ul> </li> </ul>"},{"location":"003-DockerFile-MultiStage/#01-create-multi-stage-docker-file","title":"01. Create multi-stage docker file","text":"<ul> <li>The first step is to create a Dockerfile.</li> <li>Later on we will pass build time arguments to this file to build the desired image</li> <li><code>Dockerfile</code> <pre><code># Get the value of the desired image to build\nARG     BASE_IMG=curl\n\n# Build the base image \nFROM    alpine AS base_image\n\n# Add some content to the 2nd image\nFROM    base_image  AS build-curl\nRUN     echo -e \"This file is from curl image\" &gt; image.txt\n\n# Add some content to the 3rd image\nFROM    base_image  AS build-bash\nRUN     echo -e \"This file is from bash image\" &gt; image.txt\n\n# Build the desired image\nFROM    build-${BASE_IMG}\n\n# We can use the FROM command as we see in the previous line or use the\n# We can also use image index instead\n# COPY  --from=build-${BASE_IMG} image.txt . to copy a specific content\nRUN     cat image.txt\nCMD     [\"cat\", \"image.txt\"]\n</code></pre></li> </ul>"},{"location":"003-DockerFile-MultiStage/#02-build-the-desired-images","title":"02. Build the desired images","text":"<ul> <li>We will use the following script to build multiple images and to test the results     <pre><code>#!/bin/bash -x\n\n# Build The curl based image (no-cache)\ndocker build --build-arg BASE_IMG=curl --no-cache -t curl1 .\n\n# Build The bash based image (no-cache)\ndocker build --build-arg BASE_IMG=bash --no-cache -t bash1 .\n\n### Build with cache\necho -e \"\"\necho -e \"---------------------------------\"\necho -e \"\"\n# Build The curl based image (with cache)\ndocker build --build-arg BASE_IMG=curl -t curl2 .\n\n# Build The bash based image (with cache)\ndocker build --build-arg BASE_IMG=bash -t bash2 .\n</code></pre></li> </ul>"},{"location":"003-DockerFile-MultiStage/#03-test-the-images","title":"03. Test the images","text":"<ul> <li> <p>We will now test the 4 images we build perviously     <pre><code># Debug mode\nset -x\n\n# Test the output images\ndocker run curl1\ndocker run curl2\ndocker run bash1\ndocker run bash2\n</code></pre></p> </li> <li> <p>You should see output similar to this one:     <pre><code>+ docker run curl1\nThis file is from curl image\n+ docker run curl2\nThis file is from curl image\n+ docker run bash1\nThis file is from bash image\n+ docker run bash2\nThis file is from bash image\n</code></pre></p> </li> </ul>"},{"location":"003-DockerFile-MultiStage/#04-quiz","title":"04. Quiz","text":"<ul> <li>What will be the results of this docker file?</li> <li>Try to answer and then build the following <code>Dockerfile</code> to see the results         <pre><code># Build the base image\nFROM    alpine AS base_image\n\n# Add some packages to the base image\nFROM    base_image  AS build-curl\nRUN     echo -e \"\\033[1;33mThis file is from curl image\\033[0m\" &gt; image.txt\n\n# Add some packages to the base image\nFROM    base_image  AS build-bash\nRUN     echo -e \"\\033[1;32mThis file is from bash image\\033[0m\" &gt; image.txt\n\n#   Build the desired image\nFROM    build-curl\nCOPY    --from=2 image.txt .\nRUN cat image.txt\nCMD [\"cat\", \"image.txt\"]\n</code></pre></li> <li> <p>Test your answer with the following command</p> <pre><code>docker build -f Dockerfile2 .\n</code></pre> </li> </ul>"},{"location":"003-DockerFile-MultiStage/#05-build-a-specific-target","title":"05. Build a specific target","text":"<ul> <li>We can build our specific image and stop at the desired stage</li> <li> <p>In other words we don\u2019t need to build all the images within the docker file</p> <pre><code>docker build --target build-curl -f Dockerfile2 .\n</code></pre> </li> </ul>"},{"location":"003-DockerFile-MultiStage/#06-in-class-exercise","title":"06. In-Class Exercise","text":"<ul> <li>Create a <code>multi-stage</code> docker file that will build 2 images</li> <li>The first image will be based on <code>alpine</code> and will create a file named <code>alpine.txt</code> with the content: <code>This is alpine image</code></li> <li>The second image will be based on <code>node</code> and will create a file named <code>node.txt</code> with the content: <code>This is node image</code></li> <li>The final image should be based on <code>alpine</code> and should copy the files which you created from the previous stages and display their content when the container will run.</li> <li>Hint: Use the <code>COPY --from=</code> command to copy files from previous stages</li> </ul> Solution  ### Dockerfile Solution  Create a file named `Dockerfile-exercise`:  <pre><code># First stage: Alpine image\nFROM  alpine AS alpine-stage\nRUN   echo \"This is alpine image\" &gt; alpine.txt\n\n# Second stage: Node image\nFROM  node AS node-stage\nRUN   echo \"This is node image\" &gt; node.txt\n\n# Final stage: Alpine with files from previous stages\nFROM  alpine\nCOPY  --from=alpine-stage alpine.txt  .\nCOPY  --from=node-stage node.txt      .\n\n# Run the command to display contents\nCMD   cat alpine.txt &amp;&amp; cat node.txt\n</code></pre>  ### Build and Test  Build the image:  <pre><code>docker build -f Dockerfile-exercise -t exercise-solution .\n</code></pre>  Run the container:  <pre><code>docker run exercise-solution\n</code></pre>  Expected output:  <pre><code>This is alpine image\nThis is node image\n</code></pre>  ### Explanation  1. **First Stage (alpine-stage)**: Based on `alpine`, creates `alpine.txt` with the required content 2. **Second Stage (node-stage)**: Based on `node`, creates `node.txt` with the required content 3. **Final Stage**: Based on `alpine` (lightweight), copies both files from previous stages using `COPY --from=` and displays their content when run"},{"location":"004-LocalRegistry/","title":"004-LocalRegistry","text":""},{"location":"004-LocalRegistry/#lab-004-local-docker-registry","title":"Lab 004 - Local Docker Registry","text":"<ul> <li>A collection of Hands-on Docker labs.</li> <li>Each lab is a standalone lab and does not require to complete the previous labs.</li> </ul>"},{"location":"004-LocalRegistry/#pre-requirements","title":"Pre-Requirements","text":"<ul> <li>Docker installed</li> <li>Dockerfile knowledge </li> <li>DockerHub account</li> </ul>"},{"location":"004-LocalRegistry/#lab-setup-basic-local-docker-registry","title":"Lab: Setup Basic Local Docker Registry","text":"<ul> <li>In this lab we will learn how to create a local Docker registry.</li> <li>In this lab we will learn how to push and pull images from the local registry.</li> <li>in this lab we will be using the default configuration, but of course you can change it as you wish.</li> <li>Configuration docs: https://docs.docker.com/registry/configuration</li> </ul> <ul> <li>01. Create a basic local registry</li> <li>02. Prepare the local images</li> <li>02.01. Download busybox image</li> <li>02.01. Tag the image with the local registry prefix</li> <li>02.02. Push the image to the local registry</li> <li>03. Test local images</li> </ul>"},{"location":"004-LocalRegistry/#01-create-a-basic-local-registry","title":"01. Create a basic local registry","text":"<ul> <li>The first step is to create a local registry.</li> <li>For this we will use the <code>docker run</code> command with the docker <code>registry</code>- https://hub.docker.com/_/registry image.</li> </ul> <pre><code># Run the registry container\ndocker  run                     \\\n        -d                      \\\n        -p 5000:5000            \\\n        --restart always        \\\n        --name registry         \\\n        registry:latest\n</code></pre>"},{"location":"004-LocalRegistry/#02-prepare-the-local-images","title":"02. Prepare the local images","text":"<ul> <li>We will download the images from DockerHub and push them to the local registry.</li> </ul>"},{"location":"004-LocalRegistry/#0201-download-busybox-image","title":"02.01. Download busybox image","text":"<pre><code># download busybox image from docker-hub\ndocker pull busybox\n</code></pre>"},{"location":"004-LocalRegistry/#0201-tag-the-image-with-the-local-registry-prefix","title":"02.01. Tag the image with the local registry prefix","text":"<pre><code># Tag the busybox image with the local registry prefix\ndocker tag busybox localhost:5000/busybox\n</code></pre>"},{"location":"004-LocalRegistry/#0202-push-the-image-to-the-local-registry","title":"02.02. Push the image to the local registry","text":"<pre><code># Once we have the appropriate tag, we can push the image to the local registry\ndocker push localhost:5000/busybox\n</code></pre>"},{"location":"004-LocalRegistry/#03-test-local-images","title":"03. Test local images","text":"<pre><code># List all local repositories\ncurl -X GET http://localhost:5000/v2/_catalog\n\n# List all tags for a repository\ncurl -X GET https://myregistry:5000/v2/ubuntu/tags/list\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/","title":"Index","text":""},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#docker-hands-on-repository","title":"Docker Hands-on Repository","text":"<ul> <li>A collection of Hands-on Docker labs.</li> <li>Each lab is a standalone lab and does not require to complete the previous labs.</li> </ul>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#ctrl-click-to-open-in-new-window","title":"CTRL + click to open in new window","text":""},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#pre-requirements","title":"Pre-Requirements","text":"<ul> <li>Docker installation</li> </ul>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#lab-0201-setup-advanced-local-docker-registry","title":"Lab 0201. Setup Advanced Local Docker Registry","text":"<ul> <li>In the previous lab we created a basic local registry.</li> <li>In this lab we will create a local registry with advanced features.</li> <li>The local registry will be accessible from the host machine and will be build upon</li> <li>Nginx</li> <li>Docker registry image</li> <li>Docker compose</li> <li>Secured with certificates</li> </ul>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-01-create-registry-directories","title":"Step 01. Create Registry Directories","text":"<pre><code># Create the required directories for the advanced configuration\nmkdir -p                      \\\n      registry/nginx          \\\n      registry/nginx/conf.d   \\\n      registry/nginx/ssl      \\\n      registry/auth\necho 'Docker rocks !!!' | docker run -it -a stdin alpine cat -\n# On GCP shell we cont have tree by default, so lets install it\nsudo apt install -y tree\n\n# Verify that the directories were created\ncd registry &amp;&amp; tree\n\n# We should see the following structure\n.\n\u251c\u2500\u2500 auth\n\u2514\u2500\u2500 nginx\n    \u251c\u2500\u2500 conf.d\n    \u2514\u2500\u2500 ssl\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-02-create-docker-compose-for-the-registry-services","title":"Step 02. Create Docker-Compose for the registry services","text":"<pre><code># Create the docker-compose file in the registry directory\ncat &lt;&lt; EOF &gt; registry/docker-compose.yml\nversion: '3'\nservices:\n  # The docker registry service\n  registry:\n    # The name of the container\n    container_name: registry\n\n    # The registry image which we will use\n    image: registry:2\n    # Ensures to start Docker Registry\n    restart: always\n    # The port on which the registry will be listen on\n    ports:\n    - \"5000:5000\"\n    # Registry environment variables\n\n    # The service will mount the docker volume \"registrydata\" and\n    # the local directory \"auth\",\n    # along with its authentication file \"registry.passwd\".\n    environment:\n      REGISTRY_AUTH: htpasswd\n      REGISTRY_AUTH_HTPASSWD_REALM: Registry-Realm\n      REGISTRY_AUTH_HTPASSWD_PATH: /auth/registry.passwd\n      REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY: /data\n\n    # mounted volumes\n    volumes:\n      - registrydata:/data\n      - ./auth:/auth\n\n    # The desired network\n    networks:\n      - bridge_network\n\n  #### Nginx Service\n  nginx:\n\n    # The name of the container\n    container_name: nginx\n\n    # We depends on the registry service\n    depends_on:\n      - registry\n\n    # nginx image\n    image: nginx:alpine\n    container_name: nginx\n    restart: unless-stopped\n    tty: true\n\n    # The desired listen ports\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n\n    # The mounted volumes for the configuration files\n    # Mount the local directory for virtual configuration (conf.d)\n    # and SSL certificates (ssl).\n    volumes:\n      - ./nginx/conf.d/:/etc/nginx/conf.d/\n      - ./nginx/ssl/:/etc/nginx/ssl/\n\n    # The desired network\n    networks:\n      - bridge_network\n\n# Docker Networks for those services\nnetworks:\n  # Define a bridge network names \"bridge_network\"\n  bridge_network:\n    driver: bridge\n\n# Define custom volume for the registry data named \"registrydata\"\n# using the \"local\" driver\nvolumes:\n  registrydata:\n    driver: local\n\nEOF\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-03-create-the-nginx-configuration-file","title":"Step 03. Create the Nginx configuration file","text":"<ul> <li>The next step is configuring a Nginx virtual host for the Nginx service.</li> <li>Create a new virtual host file named <code>registry.conf</code> under <code>nginx/conf.d/</code></li> </ul> <pre><code># Create a new virtual host file for our nginx service\ncat &lt;&lt; EOF &gt; nginx/conf.d/registry.conf\nupstream docker-registry {\n  server registry:5000;\n}\n\nserver {\n  listen      443 ssl http2;\n\n  # SSL\n  ssl on;\n  ssl_certificate /etc/nginx/ssl/registry.crt;\n  ssl_certificate_key /etc/nginx/ssl/registry.key;\n\n  # disable any limits to avoid HTTP 413 for large image uploads\n  # We will use `/etc/nginx/conf.d/additional.conf` as well later below\n  client_max_body_size 0;\n\n  # required to avoid HTTP 411: see Issue #1486 (https://github.com/docker/docker/issues/1486)\n  chunked_transfer_encoding on;\n\n  location /v2/ {\n    # Do not allow connections from docker 1.5 and earlier\n    # docker pre-1.6.0 did not properly set the user agent on ping, catch \"Go *\" user agents\n    if (\\$http_user_agent ~ \"^(docker\\/1\\.(3|4|5(?!\\.[0-9]-dev))|Go ).*$\" ) {\n      return 404;\n    }\n\n    # To add basic authentication to v2 use auth_basic setting plus add_header\n    # auth_basic \"registry.localhost\";\n    # auth_basic_user_file /etc/nginx/conf.d/registry.password;\n    # add_header 'Docker-Distribution-Api-Version' 'registry/2.0' always;\n\n    proxy_pass                          http://docker-registry;\n    proxy_set_header  Host              \\$http_host;   # required for docker client's sake\n    proxy_set_header  X-Real-IP         \\$remote_addr; # pass on real client's IP\n    proxy_set_header  X-Forwarded-For   \\$proxy_add_x_forwarded_for;\n    proxy_set_header  X-Forwarded-Proto \\$scheme;\n    proxy_read_timeout                  900;\n  }\n}\nEOF\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-04-increase-nginx-file-upload-size","title":"Step 04. Increase Nginx File Upload Size","text":"<ul> <li>By default, Nginx limits the file upload size to <code>1MB</code>.</li> <li>Most Docker images exceed <code>1MB</code> in size so we will increase the maximum file size on our Nginx service to <code>2GB</code>.</li> </ul> <pre><code># Increase the maximum file upload size to 2GB\necho  'client_max_body_size 2G;' &gt; registry/nginx/conf.d/additional.conf\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-05-configure-ssl-certificate","title":"Step 05. Configure SSL Certificate","text":"<ul> <li>For our secured authentication we will use self-signed certificates.</li> <li>lets generate the certificate and key files</li> </ul> <pre><code># Generate the self-signed certificate\nopenssl \\\n    req                     \\\n    -x509                   \\\n    -sha256                 \\\n    -newkey   rsa:4096      \\\n    -days     3650          \\\n    -nodes                  \\\n    -subj \"/CN=localhost\"   \\\n    -addext \"subjectAltName=DNS:localhost,DNS:localhost,IP:127.0.0.1\" \\\n    -keyout   registry/nginx/ssl/registry.key  \\\n    -out      registry/nginx/ssl/registry.crt\n\n\n# Verify the certificate and the key\nopenssl x509 -text  -noout -in registry/nginx/ssl/registry.crt\n\n# Verify that the key and the certificate matches\nopenssl rsa -check -noout -in registry/nginx/ssl/registry.key\n\n# We search a matching certificate and key md5 fingerprint\necho 'registry.key Checksum is: ' \\\n      $(openssl rsa -modulus -noout -in registry/nginx/ssl/registry.key | openssl md5)\n\necho 'registry.crt Checksum is: '  \\\n      $(openssl x509 -modulus -noout -in registry/nginx/ssl/registry.crt | openssl md5)\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-06-configure-authentication","title":"Step 06. Configure authentication","text":"<ul> <li>There are several ways to generate a password file for the registry.</li> </ul> <p>#### Option 01. using <code>htpasswd</code></p> <ul> <li>The <code>htpasswd</code> utility is a simple utility that can be used to create a password file.</li> <li>If you don\u2019t have this installed, first we need to instal it if is not installed.</li> </ul> <pre><code># install htpasswd\nsudo apt install -y apache2-utils\n\n# Now generate the password file\n# Note: You will need to enter the password twice\n#       `-c` - Create a new file.\n#       -B   - Force bcrypt encryption of the password (very secure).\nhtpasswd -Bc registry/nginx/ssl/registry.passwd $USER\n</code></pre> <p>#### Option 02. using <code>openssl</code></p> <pre><code># Generate a random password\nprintf \\\n        \"USER:$(openssl passwd -crypt PASSWORD)\\n\" &gt;&gt; \\\n        registry/nginx/ssl/registry.passwd\n\n# Verify that the password was generated\ncat registry/nginx/ssl/registry.passwd\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-07-add-the-root-ca-certificate","title":"Step 07. Add the Root CA Certificate","text":"<ul> <li>Next step is to add the Root CA certificate to Docker</li> <li>We will place certificates under the docker certificates folder for our domain</li> </ul> <pre><code># Create the required folders for the certificate\nsudo mkdir -p /etc/docker/certs.d/registry.codewizard.co.il\n\n# Copy the certificate to the docker certificates folder\nsudo cp \\\n        registry/nginx/ssl/registry.crt \\\n        /etc/docker/certs.d/registry.codewizard.co.il/rootCA.crt\n\n# Create the second folder for the certificate\nsudo mkdir -p /etc/docker/certs.d/codewizard.co.il\n\n# Copy the certificate to the second certificates folder\nsudo cp \\\n        registry/nginx/ssl/registry.crt \\\n        /etc/docker/certs.d/codewizard.co.il/rootCA.crt\n\n# Copy the certificate into /usr/share/ca-certificate/extra\nsudo mkdir -p /usr/local/share/ca-certificates/\nsudo cp \\\n        registry/nginx/ssl/registry.crt \\\n        /usr/local/share/ca-certificates/rootCA.crt\n</code></pre> <ul> <li>Once we have the certificates in place we can add them to the list of trusted certificates.</li> </ul> <pre><code># Add the certificate to the list of trusted certificates\nsudo update-ca-certificates\n</code></pre>"},{"location":"004-LocalRegistry/AdvancedLocalRegistry/#step-08-restart-docker-registry","title":"Step 08. Restart Docker registry","text":"<p>/etc/docker/daemon.json</p>"},{"location":"005-DockerCompose-Basics/","title":"005-DockerCompose-Basics","text":""},{"location":"005-DockerCompose-Basics/#lab-005-docker-compose-wordpress-mariadb","title":"Lab 005 - Docker Compose - WordPress &amp; MariaDB","text":"<p>This lab demonstrates how to use Docker Compose to orchestrate a simple multi-container application: WordPress with a MariaDB database backend.</p>"},{"location":"005-DockerCompose-Basics/#overview","title":"Overview","text":"<ul> <li> <p>The provided <code>docker-compose.yaml</code> file defines two main services:</p> </li> <li> <p>db: Runs a MariaDB database (can be switched to MySQL if desired).</p> </li> <li> <p>wordpress: Runs the latest WordPress application, connected to the database.</p> </li> <li> <p>A named volume <code>db_data</code> is used to persist database data.</p> </li> </ul>"},{"location":"005-DockerCompose-Basics/#docker-composeyaml-breakdown","title":"docker-compose.yaml Breakdown","text":"<ul> <li>db service</li> <li>Uses the <code>mariadb:10.6.4-focal</code> image (or optionally MySQL).</li> <li>Sets up environment variables for root password, database, user, and password.</li> <li>Persists data in a Docker volume.</li> <li> <p>Exposes ports 3306 and 33060 (internal only).</p> </li> <li> <p>wordpress service</p> </li> <li>Uses the latest WordPress image.</li> <li>Maps port 80 on the host to port 80 in the container.</li> <li> <p>Configures environment variables to connect to the database.</p> </li> <li> <p>volumes</p> </li> <li><code>db_data</code>: Persists MariaDB data between container restarts.</li> </ul>"},{"location":"005-DockerCompose-Basics/#bonus-demo","title":"Bonus Demo","text":"<ul> <li>I prepared a demo of this lab, which you can view on KillerCoda: Portainder Demo.</li> <li>The demo is showcases for setting and running multuple containers using Docker Compose</li> <li>The demo is available on KillerCoda.</li> </ul>"},{"location":"005-DockerCompose-Basics/#how-to-run-the-lab","title":"How to Run the Lab","text":"<ol> <li> <p>Navigate to the lab directory: <pre><code>cd Labs/005-DockerCompose\n</code></pre></p> </li> <li> <p>Start the services: <pre><code>docker compose up -d\n</code></pre></p> </li> <li> <p>This will pull the required images (if not already present) and start both the database and WordPress containers in detached mode.</p> </li> <li> <p>Access WordPress:</p> </li> <li>Open your browser and go to http://localhost</li> <li> <p>Complete the WordPress setup wizard.</p> </li> <li> <p>Stop the services: <pre><code>docker compose down\n</code></pre>    This will stop and remove the containers, but the database data will persist in the <code>db_data</code> volume.</p> </li> </ol>"},{"location":"005-DockerCompose-Basics/#notes","title":"Notes","text":"<ul> <li>To use MySQL instead of MariaDB, uncomment the relevant line in the compose file and comment out the MariaDB image line.</li> <li>The database credentials are set for demonstration purposes. For production, use secure passwords.</li> <li>The <code>db</code> service is only accessible to the <code>wordpress</code> service (not exposed to the host).</li> </ul>"},{"location":"005-DockerCompose-Basics/#advanced-concepts","title":"Advanced Concepts","text":""},{"location":"005-DockerCompose-Basics/#docker-compose-networks","title":"Docker Compose Networks","text":"<p>Docker Compose automatically creates a default network for your services. However, you can define custom networks for better isolation and control:</p> <pre><code>services:\n  wordpress:\n    networks:\n      - frontend\n      - backend\n\n  db:\n    networks:\n      - backend\n\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n    internal: true  # No external access\n</code></pre> <p>Network Types: - <code>bridge</code>: Default network driver for standalone containers - <code>host</code>: Use the host\u2019s network directly - <code>overlay</code>: For multi-host networking (Docker Swarm) - <code>macvlan</code>: Assign MAC addresses to containers - <code>none</code>: Disable networking</p>"},{"location":"005-DockerCompose-Basics/#volume-management","title":"Volume Management","text":"<p>Named Volumes vs Bind Mounts:</p> <pre><code>services:\n  wordpress:\n    volumes:\n      # Named volume (managed by Docker)\n      - wp_data:/var/www/html\n\n      # Bind mount (host directory)\n      - ./my-theme:/var/www/html/wp-content/themes/my-theme\n\n      # Anonymous volume\n      - /var/www/html/tmp\n\nvolumes:\n  wp_data:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /path/on/host\n</code></pre> <p>Volume Best Practices: - Use named volumes for data persistence - Use bind mounts for development (live code updates) - Use anonymous volumes for temporary data - Always backup volumes before major updates</p>"},{"location":"005-DockerCompose-Basics/#health-checks","title":"Health Checks","text":"<p>Add health checks to ensure services are running correctly:</p> <pre><code>services:\n  wordpress:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n\n  db:\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n</code></pre>"},{"location":"005-DockerCompose-Basics/#resource-limits","title":"Resource Limits","text":"<p>Control resource allocation to prevent any service from consuming all resources:</p> <pre><code>services:\n  wordpress:\n    deploy:\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n</code></pre>"},{"location":"005-DockerCompose-Basics/#restart-policies","title":"Restart Policies","text":"<p>Configure how containers should restart:</p> <pre><code>services:\n  wordpress:\n    restart: unless-stopped  # Options: no, always, on-failure, unless-stopped\n</code></pre>"},{"location":"005-DockerCompose-Basics/#dependency-management","title":"Dependency Management","text":"<p>Control startup order with <code>depends_on</code>:</p> <pre><code>services:\n  wordpress:\n    depends_on:\n      db:\n        condition: service_healthy  # Wait for db to be healthy\n</code></pre>"},{"location":"005-DockerCompose-Basics/#logging-configuration","title":"Logging Configuration","text":"<p>Configure log drivers and options:</p> <pre><code>services:\n  wordpress:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n</code></pre>"},{"location":"005-DockerCompose-Basics/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Environment Variables: Store configuration in <code>.env</code> files    <pre><code># .env file\nMYSQL_ROOT_PASSWORD=secure_password\nMYSQL_DATABASE=wordpress\n</code></pre></p> </li> <li> <p>Version Your Compose Files: Always specify the Compose version    <pre><code>version: '3.8'\n</code></pre></p> </li> <li> <p>Use Specific Image Tags: Avoid <code>latest</code> tag in production    <pre><code>image: mariadb:10.6.4-focal\n</code></pre></p> </li> <li> <p>Organize Services Logically: Group related services</p> </li> <li>Frontend services</li> <li>Backend services</li> <li>Database services</li> <li> <p>Cache services</p> </li> <li> <p>Use Multi-Stage Builds: For custom images, use multi-stage Dockerfiles</p> </li> <li> <p>Implement Health Checks: Always add health checks for critical services</p> </li> <li> <p>Secure Secrets: Use Docker secrets or external secret management    <pre><code>services:\n  db:\n    secrets:\n      - db_password\n\nsecrets:\n  db_password:\n    file: ./secrets/db_password.txt\n</code></pre></p> </li> <li> <p>Use .dockerignore: Exclude unnecessary files from build context</p> </li> <li> <p>Network Isolation: Use custom networks to isolate services</p> </li> <li> <p>Monitor Resources: Set resource limits to prevent resource exhaustion</p> </li> </ol>"},{"location":"005-DockerCompose-Basics/#useful-docker-compose-commands","title":"Useful Docker Compose Commands","text":"<pre><code># View configuration (merged from all compose files)\ndocker compose config\n\n# Validate compose file\ndocker compose config --quiet\n\n# Pull all images\ndocker compose pull\n\n# Build services\ndocker compose build\n\n# Start services\ndocker compose up -d\n\n# View running services\ndocker compose ps\n\n# View logs\ndocker compose logs -f [service_name]\n\n# Execute command in running container\ndocker compose exec wordpress bash\n\n# Scale services\ndocker compose up -d --scale wordpress=3\n\n# Stop services\ndocker compose stop\n\n# Stop and remove containers\ndocker compose down\n\n# Stop, remove containers and volumes\ndocker compose down -v\n\n# Restart services\ndocker compose restart\n\n# Pause services\ndocker compose pause\n\n# Unpause services\ndocker compose unpause\n\n# View resource usage\ndocker compose top\n</code></pre>"},{"location":"005-DockerCompose-Basics/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter port conflicts, ensure nothing else is running on port 80.</li> <li>To view logs for a service:   <pre><code>docker compose logs wordpress\ndocker compose logs db\n</code></pre></li> <li>Check service health:   <pre><code>docker compose ps\n</code></pre></li> <li>Inspect network connectivity:   <pre><code>docker network inspect 005-dockercompose_default\n</code></pre></li> <li>Debug startup issues:   <pre><code>docker compose up --no-start\ndocker compose start\n</code></pre></li> </ul> <p>This lab is part of the DockerLabs series. See other labs for more Docker scenarios and hands-on exercises.</p>"},{"location":"006-DockerCompose-env/","title":"006-DockerCompose-env","text":""},{"location":"006-DockerCompose-env/#lab-006-multi-environment-docker-compose-setup","title":"Lab 006 - Multi-Environment Docker Compose Setup","text":"<ul> <li>A comprehensive example of structuring Docker Compose files for multiple environments</li> <li>Demonstrates environment-specific overrides and configuration management</li> <li>Each environment is fully isolated with its own configuration and services</li> </ul>"},{"location":"006-DockerCompose-env/#pre-requirements","title":"Pre-Requirements","text":"<ul> <li>Docker installed</li> <li>Docker Compose knowledge</li> <li>Basic understanding of environment variables</li> </ul> <ul> <li>Overview</li> <li>Project Structure</li> <li>Step 01 - Understanding the Base Configuration</li> <li>Step 02 - Development Environment</li> <li>Step 03 - Production Environment</li> <li>Step 04 - Environment Variables</li> <li>Shared Variables (<code>.env</code>)</li> <li>Development Variables (<code>.env.dev</code>)</li> <li>Production Variables (<code>.env.prod</code>)</li> <li>Step 05 - Quick Start with Scripts</li> <li>Using the run.sh Script</li> <li>Step 06 - Manual Commands</li> <li>Start Specific Environment</li> <li>Stop Services</li> <li>View Logs</li> <li>Scale Services (Production)</li> <li>Step 07 - Testing the Setup</li> <li>Interactive Demo</li> <li>Manual Testing</li> <li>Step 08 - Clean Up</li> <li>Best Practices</li> <li>Troubleshooting</li> <li>Common Issues</li> <li>Debugging Commands</li> <li>Environment-Specific Notes</li> </ul>"},{"location":"006-DockerCompose-env/#overview","title":"Overview","text":"<p>This lab demonstrates how to structure Docker Compose files for multiple environments using:</p> <ul> <li>Base Configuration: Common services shared across environments</li> <li>Environment Overrides: Specific configurations for development and production</li> <li>Environment Variables: Centralized configuration management</li> <li>Utility Scripts: Easy environment management</li> </ul>"},{"location":"006-DockerCompose-env/#project-structure","title":"Project Structure","text":"<pre><code>Labs/006-DockerCompose-env/\n\u251c\u2500\u2500 docker-compose.yml          # Base services configuration\n\u251c\u2500\u2500 docker-compose.dev.yml      # Development overrides\n\u251c\u2500\u2500 docker-compose.prod.yml     # Production overrides\n\u251c\u2500\u2500 .env                        # Shared environment variables\n\u251c\u2500\u2500 .env.dev                    # Development-specific variables\n\u251c\u2500\u2500 .env.prod                   # Production-specific variables\n\u251c\u2500\u2500 README.md                   # This documentation\n\u251c\u2500\u2500 run.sh                      # Bash script for environment management\n\u251c\u2500\u2500 demo.sh                     # Interactive demonstration\n\u251c\u2500\u2500 init.sql                    # Database initialization\n\u251c\u2500\u2500 html/\n\u2502   \u2514\u2500\u2500 index.html             # Sample web application\n\u2514\u2500\u2500 api/\n    \u251c\u2500\u2500 package.json           # Node.js API dependencies\n    \u2514\u2500\u2500 server.js              # Sample API server\n</code></pre>"},{"location":"006-DockerCompose-env/#step-01-understanding-the-base-configuration","title":"Step 01 - Understanding the Base Configuration","text":"<p>The <code>docker-compose.yml</code> file contains the core service definitions that are common across all environments:</p> <ul> <li>Web Service: Nginx web server</li> <li>API Service: Node.js backend application  </li> <li>Database Service: PostgreSQL database</li> <li>Cache Service: Redis caching layer</li> </ul> <p>All services use environment variables with default values using the <code>${VARIABLE:-default}</code> syntax for flexibility.</p>"},{"location":"006-DockerCompose-env/#step-02-development-environment","title":"Step 02 - Development Environment","text":"<p>The development environment (<code>docker-compose.dev.yml</code>) provides developer-friendly features:</p> <pre><code># Start development environment\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml up -d\n</code></pre> <p>Development Features:</p> <ul> <li>Hot reload enabled for API service (nodemon)</li> <li>Debug ports exposed (9229 for Node.js debugging)</li> <li>Additional development tools:</li> <li>Adminer for database management</li> <li>MailCatcher for email testing</li> <li>Read-write volumes for live code editing</li> <li>Detailed logging enabled</li> <li>Non-standard ports to avoid conflicts (8000, 3001, 5433, 6380)</li> </ul> <p>Development Services Access:</p> <ul> <li>Web Application: <code>http://localhost:8000</code></li> <li>API: <code>http://localhost:3001</code></li> <li>Database Admin (Adminer): <code>http://localhost:8080</code></li> <li>Mail Catcher: <code>http://localhost:1080</code></li> </ul>"},{"location":"006-DockerCompose-env/#step-03-production-environment","title":"Step 03 - Production Environment","text":"<p>The production environment (<code>docker-compose.prod.yml</code>) focuses on performance and security:</p> <pre><code># Start production environment\ndocker-compose --env-file .env.prod -f docker-compose.yml -f docker-compose.prod.yml up -d\n</code></pre> <p>Production Features:</p> <ul> <li>Multiple service replicas for high availability</li> <li>Read-only volumes for security</li> <li>Optimized restart policies</li> <li>Structured logging with rotation</li> <li>Monitoring with Prometheus</li> <li>Standard service ports (80, 3000, 5432, 6379)</li> </ul> <p>Production Services Access:</p> <ul> <li>Web Application: <code>http://localhost:80</code></li> <li>API: <code>http://localhost:3000</code></li> <li>Monitoring (Prometheus): <code>http://localhost:9090</code></li> </ul>"},{"location":"006-DockerCompose-env/#step-04-environment-variables","title":"Step 04 - Environment Variables","text":""},{"location":"006-DockerCompose-env/#shared-variables-env","title":"Shared Variables (<code>.env</code>)","text":"<p>Common configuration across all environments:</p> Variable Description <code>APP_NAME</code> Application name for container naming <code>ENVIRONMENT</code> Current environment identifier <code>DB_NAME</code> Database name <code>DB_USER</code> Database user <code>API_SECRET</code> API authentication secret <code>LOG_LEVEL</code> Logging verbosity"},{"location":"006-DockerCompose-env/#development-variables-envdev","title":"Development Variables (<code>.env.dev</code>)","text":"Variable/Setting Description Non-standard ports Avoid conflicts with other services Debug-friendly config Enables debug mode and verbose logging Dev DB credentials Uses development database credentials Enhanced logging More detailed logs for debugging"},{"location":"006-DockerCompose-env/#production-variables-envprod","title":"Production Variables (<code>.env.prod</code>)","text":"Variable/Setting Description Standard service ports Uses standard ports for production Strong, secure passwords Enforces strong credentials Optimized timeouts Sets timeouts suitable for production Security-focused config Enables production security best practices"},{"location":"006-DockerCompose-env/#step-05-quick-start-with-scripts","title":"Step 05 - Quick Start with Scripts","text":""},{"location":"006-DockerCompose-env/#using-the-runsh-script","title":"Using the run.sh Script","text":"<pre><code># Development environment\n./run.sh dev up        # Start development\n./run.sh dev down      # Stop development\n./run.sh dev logs      # View development logs\n./run.sh dev ps        # Show service status\n\n# Production environment\n./run.sh prod up       # Start production\n./run.sh prod down     # Stop production\n./run.sh prod logs     # View production logs\n\n# Help\n./run.sh help          # Show usage information\n</code></pre>"},{"location":"006-DockerCompose-env/#step-06-manual-commands","title":"Step 06 - Manual Commands","text":""},{"location":"006-DockerCompose-env/#start-specific-environment","title":"Start Specific Environment","text":"<pre><code># Development\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml up -d\n\n# Production\ndocker-compose --env-file .env.prod -f docker-compose.yml -f docker-compose.prod.yml up -d\n</code></pre>"},{"location":"006-DockerCompose-env/#stop-services","title":"Stop Services","text":"<pre><code># Development\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml down\n\n# Production  \ndocker-compose --env-file .env.prod -f docker-compose.yml -f docker-compose.prod.yml down\n</code></pre>"},{"location":"006-DockerCompose-env/#view-logs","title":"View Logs","text":"<pre><code># All services logs\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml logs -f\n\n# Specific service logs\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml logs -f api\n</code></pre>"},{"location":"006-DockerCompose-env/#scale-services-production","title":"Scale Services (Production)","text":"<pre><code># Scale API service to 5 replicas\ndocker-compose --env-file .env.prod -f docker-compose.yml -f docker-compose.prod.yml up -d --scale api=5\n</code></pre>"},{"location":"006-DockerCompose-env/#step-07-testing-the-setup","title":"Step 07 - Testing the Setup","text":""},{"location":"006-DockerCompose-env/#interactive-demo","title":"Interactive Demo","text":"<p>Run the complete demonstration:</p> <pre><code># Run the interactive demo\n./demo.sh\n</code></pre> <p>The demo will:</p> <ol> <li>Start development environment</li> <li>Test the application</li> <li>Switch to production environment  </li> <li>Show differences between environments</li> <li>Clean up</li> </ol>"},{"location":"006-DockerCompose-env/#manual-testing","title":"Manual Testing","text":"<pre><code># Start development environment\n./run.sh dev up\n\n# Test the API\ncurl -s http://localhost:3001/health | python3 -m json.tool\n\n# Test the web application\ncurl -s http://localhost:8000\n\n# Check service status\n./run.sh dev ps\n</code></pre>"},{"location":"006-DockerCompose-env/#step-08-clean-up","title":"Step 08 - Clean Up","text":"<pre><code># Stop current environment\n./run.sh dev down     # or ./run.sh prod down\n\n# Complete cleanup (removes volumes)\n./run.sh dev down &amp;&amp; ./run.sh prod down\ndocker system prune -f\n\n# Or manually\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml down -v\ndocker-compose --env-file .env.prod -f docker-compose.yml -f docker-compose.prod.yml down -v\n</code></pre>"},{"location":"006-DockerCompose-env/#best-practices","title":"Best Practices","text":"<ol> <li>Environment Separation: Clear separation between dev, staging, and production configurations</li> <li>Security: Different secrets and passwords per environment</li> <li>Scalability: Production setup with multiple replicas and monitoring</li> <li>Development Experience: Hot reload, debugging ports, and development tools</li> <li>Configuration Management: Centralized environment variable management</li> <li>Volume Management: Read-only volumes in production, read-write in development</li> <li>Logging: Environment-appropriate logging levels and rotation</li> <li>Networking: Consistent network setup across environments</li> </ol>"},{"location":"006-DockerCompose-env/#advanced-docker-compose-techniques","title":"Advanced Docker Compose Techniques","text":""},{"location":"006-DockerCompose-env/#yaml-anchors-and-aliases","title":"YAML Anchors and Aliases","text":"<p>Docker Compose supports YAML anchors (<code>&amp;</code>) and aliases (<code>*</code>) to reduce duplication in your compose files. This is particularly useful when multiple services share common configuration.</p> <p>Basic Anchors Example:</p> <pre><code># Define reusable configuration blocks\nx-logging: &amp;default-logging\n  driver: json-file\n  options:\n    max-size: \"10m\"\n    max-file: \"3\"\n\nx-healthcheck: &amp;default-healthcheck\n  interval: 30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s\n\nservices:\n  web:\n    image: nginx:alpine\n    logging: *default-logging\n    healthcheck:\n      &lt;&lt;: *default-healthcheck\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n\n  api:\n    image: node:18-alpine\n    logging: *default-logging\n    healthcheck:\n      &lt;&lt;: *default-healthcheck\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n</code></pre>"},{"location":"006-DockerCompose-env/#extension-fields-x-","title":"Extension Fields (x-*)","text":"<p>Extension fields are special YAML keys that start with <code>x-</code> and are ignored by Docker Compose. They\u2019re perfect for defining reusable configuration fragments.</p> <p>Common Configuration Patterns:</p> <pre><code># Define common configurations as extension fields\nx-common-variables: &amp;common-vars\n  TZ: UTC\n  LOG_LEVEL: info\n\nx-restart-policy: &amp;restart-policy\n  restart: unless-stopped\n\nx-resource-limits: &amp;resource-limits\n  deploy:\n    resources:\n      limits:\n        cpus: '0.50'\n        memory: 512M\n      reservations:\n        cpus: '0.25'\n        memory: 256M\n\nservices:\n  service1:\n    &lt;&lt;: *restart-policy\n    &lt;&lt;: *resource-limits\n    environment:\n      &lt;&lt;: *common-vars\n      SERVICE_NAME: service1\n\n  service2:\n    &lt;&lt;: *restart-policy\n    &lt;&lt;: *resource-limits\n    environment:\n      &lt;&lt;: *common-vars\n      SERVICE_NAME: service2\n</code></pre>"},{"location":"006-DockerCompose-env/#merge-keys","title":"Merge Keys (&lt;&lt;:)","text":"<p>The merge key <code>&lt;&lt;:</code> allows you to merge one or more mappings into the current mapping. You can merge multiple anchors:</p> <pre><code>x-base-service: &amp;base-service\n  restart: unless-stopped\n  networks:\n    - app-network\n\nx-logging-config: &amp;logging-config\n  logging:\n    driver: json-file\n    options:\n      max-size: \"10m\"\n\nx-health-config: &amp;health-config\n  healthcheck:\n    interval: 30s\n    timeout: 10s\n    retries: 3\n\nservices:\n  web:\n    &lt;&lt;: [*base-service, *logging-config, *health-config]\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n\n  api:\n    &lt;&lt;: [*base-service, *logging-config, *health-config]\n    image: node:18-alpine\n    ports:\n      - \"3000:3000\"\n</code></pre>"},{"location":"006-DockerCompose-env/#complex-fragment-patterns","title":"Complex Fragment Patterns","text":"<p>Service Templates:</p> <pre><code># Define a complete service template\nx-app-template: &amp;app-template\n  restart: unless-stopped\n  networks:\n    - backend\n  logging:\n    driver: json-file\n    options:\n      max-size: \"10m\"\n      max-file: \"3\"\n  deploy:\n    resources:\n      limits:\n        cpus: '1.0'\n        memory: 1G\n\n# Define environment-specific configurations\nx-dev-config: &amp;dev-config\n  build:\n    context: .\n    target: development\n  volumes:\n    - ./src:/app/src\n  environment:\n    NODE_ENV: development\n\nx-prod-config: &amp;prod-config\n  image: myapp:latest\n  read_only: true\n  environment:\n    NODE_ENV: production\n\nservices:\n  # Development service\n  app-dev:\n    &lt;&lt;: [*app-template, *dev-config]\n    ports:\n      - \"3001:3000\"\n\n  # Production service\n  app-prod:\n    &lt;&lt;: [*app-template, *prod-config]\n    ports:\n      - \"3000:3000\"\n</code></pre>"},{"location":"006-DockerCompose-env/#combining-anchors-with-override","title":"Combining Anchors with Override","text":"<p>You can override specific values from anchors:</p> <pre><code>x-database: &amp;database-config\n  image: postgres:15-alpine\n  restart: unless-stopped\n  networks:\n    - db-network\n  healthcheck:\n    test: [\"CMD-SHELL\", \"pg_isready\"]\n    interval: 10s\n    timeout: 5s\n    retries: 5\n\nservices:\n  main-db:\n    &lt;&lt;: *database-config\n    container_name: main-database\n    environment:\n      POSTGRES_DB: maindb\n    volumes:\n      - main-db-data:/var/lib/postgresql/data\n\n  test-db:\n    &lt;&lt;: *database-config\n    container_name: test-database\n    environment:\n      POSTGRES_DB: testdb\n    volumes:\n      - test-db-data:/var/lib/postgresql/data\n    # Override the restart policy for test db\n    restart: \"no\"\n</code></pre>"},{"location":"006-DockerCompose-env/#real-world-example-microservices","title":"Real-World Example: Microservices","text":"<pre><code>version: '3.8'\n\n# Common configurations\nx-service-defaults: &amp;service-defaults\n  restart: unless-stopped\n  networks:\n    - app-network\n  logging: &amp;logging-config\n    driver: json-file\n    options:\n      max-size: \"10m\"\n      max-file: \"3\"\n\nx-node-service: &amp;node-service\n  &lt;&lt;: *service-defaults\n  image: node:18-alpine\n  healthcheck:\n    interval: 30s\n    timeout: 10s\n    retries: 3\n\nx-environment-common: &amp;env-common\n  NODE_ENV: ${NODE_ENV:-production}\n  LOG_LEVEL: ${LOG_LEVEL:-info}\n  DATABASE_URL: postgresql://db:5432/${DB_NAME}\n\nservices:\n  user-service:\n    &lt;&lt;: *node-service\n    container_name: user-service\n    environment:\n      &lt;&lt;: *env-common\n      SERVICE_NAME: user-service\n      PORT: 3001\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-q\", \"-O\", \"-\", \"http://localhost:3001/health\"]\n    ports:\n      - \"3001:3001\"\n\n  order-service:\n    &lt;&lt;: *node-service\n    container_name: order-service\n    environment:\n      &lt;&lt;: *env-common\n      SERVICE_NAME: order-service\n      PORT: 3002\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-q\", \"-O\", \"-\", \"http://localhost:3002/health\"]\n    ports:\n      - \"3002:3002\"\n\n  payment-service:\n    &lt;&lt;: *node-service\n    container_name: payment-service\n    environment:\n      &lt;&lt;: *env-common\n      SERVICE_NAME: payment-service\n      PORT: 3003\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-q\", \"-O\", \"-\", \"http://localhost:3003/health\"]\n    ports:\n      - \"3003:3003\"\n\nnetworks:\n  app-network:\n    driver: bridge\n\nvolumes:\n  db-data:\n</code></pre>"},{"location":"006-DockerCompose-env/#benefits-of-using-fragments","title":"Benefits of Using Fragments","text":"<ol> <li>DRY Principle: Don\u2019t Repeat Yourself - define common configuration once</li> <li>Consistency: Ensure all services use the same base configuration</li> <li>Maintainability: Update configuration in one place</li> <li>Readability: Cleaner, more organized compose files</li> <li>Scalability: Easy to add new services with standard configuration</li> </ol>"},{"location":"006-DockerCompose-env/#tips-for-using-fragments","title":"Tips for Using Fragments","text":"<ul> <li>Use meaningful names for your anchors (e.g., <code>&amp;common-logging</code>, <code>&amp;base-service</code>)</li> <li>Group related configuration into logical fragments</li> <li>Place extension fields at the top of your compose file</li> <li>Document what each fragment contains</li> <li>Test your merged configuration with <code>docker compose config</code></li> <li>Use fragments for environment-specific configurations</li> <li>Combine fragments with environment variables for maximum flexibility</li> </ul>"},{"location":"006-DockerCompose-env/#troubleshooting","title":"Troubleshooting","text":""},{"location":"006-DockerCompose-env/#common-issues","title":"Common Issues","text":"<ul> <li>Port conflicts: Ensure no other services are using the same ports</li> <li>Environment variables: Verify all required variables are set in <code>.env</code> files</li> <li>Docker daemon: Ensure Docker is running and accessible</li> </ul>"},{"location":"006-DockerCompose-env/#debugging-commands","title":"Debugging Commands","text":"<pre><code># Check service logs\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml logs service_name\n\n# Check service status\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml ps\n\n# Inspect container\ndocker inspect container_name\n\n# Execute command in container\ndocker-compose --env-file .env.dev -f docker-compose.yml -f docker-compose.dev.yml exec service_name bash\n</code></pre>"},{"location":"006-DockerCompose-env/#environment-specific-notes","title":"Environment-Specific Notes","text":"Environment/Aspect Notes Development Services may take longer to start due to volume mounts Production Services use restart policies and may auto-restart on failure Networking All services communicate through Docker networks"},{"location":"007-DockerCompose-fragments/","title":"007-DockerCompose-fragments","text":""},{"location":"007-DockerCompose-fragments/#lab-007-advanced-docker-compose-fragments-includes-extends","title":"Lab 007 - Advanced Docker Compose - Fragments, Includes &amp; Extends","text":"<p>This lab covers advanced Docker Compose techniques including YAML fragments, composition patterns, includes, and the extends keyword. Learn how to build maintainable, reusable, and DRY (Don\u2019t Repeat Yourself) Docker Compose configurations.</p>"},{"location":"007-DockerCompose-fragments/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Table of Contents</li> <li>Overview</li> <li>Prerequisites</li> <li>YAML Anchors and Aliases</li> <li>Basic Anchors</li> <li>Extension Fields</li> <li>Merge Keys</li> <li>Docker Compose Include</li> <li>Basic Include Syntax</li> <li>Include with Path</li> <li>Include Best Practices</li> <li>Docker Compose Extends (Legacy)</li> <li>Extends Syntax</li> <li>When to Use Extends</li> <li>Real-World Examples</li> <li>Example 1: Microservices Architecture</li> <li>Example 2: Multi-Environment Setup</li> <li>Example 3: Modular Configuration</li> <li>Best Practices</li> <li>Common Patterns</li> <li>Pattern 1: Base Service Template</li> <li>Pattern 2: Environment Overrides</li> <li>Pattern 3: Multi-Container Application</li> <li>Troubleshooting</li> <li>Common Issues and Solutions</li> <li>Debugging Commands</li> <li>Hands-On Exercises</li> <li>Exercise 1: Create a Microservices Setup</li> <li>Exercise 2: Multi-Environment Configuration</li> <li>Exercise 3: Modular Infrastructure</li> <li>Useful Commands</li> </ul>"},{"location":"007-DockerCompose-fragments/#overview","title":"Overview","text":"<p>As Docker Compose configurations grow, managing multiple services with similar configurations becomes challenging. This lab teaches you advanced composition techniques to:</p> <ul> <li>Reduce duplication using YAML anchors and fragments</li> <li>Modularize configurations with includes</li> <li>Share common settings across services</li> <li>Manage multi-environment setups efficiently</li> <li>Create reusable templates for services</li> </ul>"},{"location":"007-DockerCompose-fragments/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed (version 20.10+)</li> <li>Docker Compose V2 (docker compose, not docker-compose)</li> <li>Basic understanding of YAML syntax</li> <li>Familiarity with basic Docker Compose concepts</li> </ul> <p>Verify your setup:</p> <pre><code>docker compose version\n# Should show: Docker Compose version v2.x.x or higher\n</code></pre>"},{"location":"007-DockerCompose-fragments/#yaml-anchors-and-aliases","title":"YAML Anchors and Aliases","text":"<p>YAML anchors (<code>&amp;</code>) and aliases (<code>*</code>) allow you to define reusable configuration blocks within a single YAML file.</p>"},{"location":"007-DockerCompose-fragments/#basic-anchors","title":"Basic Anchors","text":"<p>Syntax:</p> <ul> <li><code>&amp;anchor-name</code> - Define an anchor</li> <li><code>*anchor-name</code> - Reference an anchor</li> <li><code>&lt;&lt;: *anchor-name</code> - Merge an anchor</li> </ul> <p>Simple Example:</p> <pre><code>version: '3.8'\n\n# Define a logging configuration anchor\nx-logging: &amp;default-logging\n  driver: json-file\n  options:\n    max-size: \"10m\"\n    max-file: \"3\"\n\nservices:\n  web:\n    image: nginx:alpine\n    logging: *default-logging\n\n  api:\n    image: node:18-alpine\n    logging: *default-logging\n\n  worker:\n    image: python:3.11-alpine\n    logging: *default-logging\n</code></pre>"},{"location":"007-DockerCompose-fragments/#extension-fields","title":"Extension Fields","text":"<p>Extension fields start with <code>x-</code> and are ignored by Docker Compose but can be used as anchors. This keeps your configuration organized.</p> <p>Complete Service Template:</p> <pre><code>version: '3.8'\n\n# Extension fields - ignored by Docker Compose\nx-common-variables: &amp;common-vars\n  TZ: UTC\n  LOG_LEVEL: ${LOG_LEVEL:-info}\n  ENVIRONMENT: ${ENVIRONMENT:-production}\n\nx-restart-policy: &amp;restart-policy\n  restart: unless-stopped\n\nx-healthcheck-defaults: &amp;healthcheck-defaults\n  interval: 30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s\n\nx-resource-limits: &amp;resource-limits\n  deploy:\n    resources:\n      limits:\n        cpus: '1.0'\n        memory: 1G\n      reservations:\n        cpus: '0.5'\n        memory: 512M\n\nx-logging-config: &amp;logging-config\n  logging:\n    driver: json-file\n    options:\n      max-size: \"10m\"\n      max-file: \"3\"\n      labels: \"service\"\n\n# Actual services using the fragments\nservices:\n  web:\n    image: nginx:alpine\n    &lt;&lt;: [*restart-policy, *logging-config, *resource-limits]\n    environment:\n      &lt;&lt;: *common-vars\n      SERVICE_NAME: web\n    healthcheck:\n      &lt;&lt;: *healthcheck-defaults\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"]\n    ports:\n      - \"80:80\"\n    networks:\n      - frontend\n\n  api:\n    image: node:18-alpine\n    &lt;&lt;: [*restart-policy, *logging-config, *resource-limits]\n    environment:\n      &lt;&lt;: *common-vars\n      SERVICE_NAME: api\n    healthcheck:\n      &lt;&lt;: *healthcheck-defaults\n      test: [\"CMD\", \"wget\", \"-q\", \"-O\", \"-\", \"http://localhost:3000/health\"]\n    ports:\n      - \"3000:3000\"\n    networks:\n      - frontend\n      - backend\n\nnetworks:\n  frontend:\n  backend:\n</code></pre>"},{"location":"007-DockerCompose-fragments/#merge-keys","title":"Merge Keys","text":"<p>The merge key (<code>&lt;&lt;:</code>) allows combining multiple anchors:</p> <p>Multiple Anchor Merging:</p> <pre><code>version: '3.8'\n\n# Define separate configuration aspects\nx-base-config: &amp;base-config\n  restart: unless-stopped\n  networks:\n    - app-network\n\nx-monitoring: &amp;monitoring\n  labels:\n    - \"prometheus.scrape=true\"\n    - \"prometheus.port=9090\"\n\nx-security: &amp;security\n  security_opt:\n    - no-new-privileges:true\n  read_only: true\n\nx-node-service: &amp;node-service\n  image: node:18-alpine\n  healthcheck:\n    test: [\"CMD\", \"node\", \"--version\"]\n    interval: 30s\n\nservices:\n  # Merge multiple fragments\n  user-service:\n    &lt;&lt;: [*base-config, *monitoring, *security, *node-service]\n    container_name: user-service\n    environment:\n      SERVICE: users\n    ports:\n      - \"3001:3000\"\n\n  order-service:\n    &lt;&lt;: [*base-config, *monitoring, *security, *node-service]\n    container_name: order-service\n    environment:\n      SERVICE: orders\n    ports:\n      - \"3002:3000\"\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre>"},{"location":"007-DockerCompose-fragments/#docker-compose-include","title":"Docker Compose Include","text":"<p>The <code>include</code> directive (Compose V2.20+) allows you to split your configuration across multiple files and combine them at runtime.</p>"},{"location":"007-DockerCompose-fragments/#basic-include-syntax","title":"Basic Include Syntax","text":"<p>Main compose file (<code>docker-compose.yml</code>):</p> <pre><code>include:\n  - ./compose-services.yml\n  - ./compose-networks.yml\n  - ./compose-volumes.yml\n\n# You can still define additional services here\nservices:\n  gateway:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n</code></pre> <p>Separate service file (<code>compose-services.yml</code>):</p> <pre><code>services:\n  api:\n    image: node:18-alpine\n    ports:\n      - \"3000:3000\"\n\n  worker:\n    image: python:3.11-alpine\n</code></pre>"},{"location":"007-DockerCompose-fragments/#include-with-path","title":"Include with Path","text":"<p>You can organize includes in subdirectories:</p> <p>Project Structure:</p> <pre><code>project/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 compose/\n\u2502   \u251c\u2500\u2500 databases.yml\n\u2502   \u251c\u2500\u2500 services.yml\n\u2502   \u251c\u2500\u2500 monitoring.yml\n\u2502   \u2514\u2500\u2500 dev/\n\u2502       \u251c\u2500\u2500 overrides.yml\n\u2502       \u2514\u2500\u2500 debug.yml\n\u2514\u2500\u2500 .env\n</code></pre> <p>docker-compose.yml:</p> <pre><code>include:\n  - path: ./compose/databases.yml\n  - path: ./compose/services.yml\n  - path: ./compose/monitoring.yml\n  # Conditional includes based on environment\n  - path: ./compose/dev/overrides.yml\n    env_file: .env.dev\n</code></pre>"},{"location":"007-DockerCompose-fragments/#include-best-practices","title":"Include Best Practices","text":"<ol> <li>Logical Separation:</li> </ol> <pre><code># docker-compose.yml - Main orchestration\ninclude:\n  - ./infrastructure/databases.yml      # All database services\n  - ./infrastructure/cache.yml          # Redis, Memcached, etc.\n  - ./infrastructure/queues.yml         # RabbitMQ, Kafka, etc.\n  - ./application/backend-services.yml  # Backend microservices\n  - ./application/frontend-services.yml # Frontend services\n  - ./monitoring/observability.yml      # Prometheus, Grafana, etc.\n</code></pre> <ol> <li>Environment-Specific Includes:</li> </ol> <pre><code># docker-compose.yml\ninclude:\n  - ./base/services.yml\n  - path: ./envs/${ENVIRONMENT:-dev}.yml\n</code></pre> <ol> <li>Shared Fragments Across Includes:</li> </ol> <pre><code># shared/fragments.yml\nx-logging: &amp;default-logging\n  driver: json-file\n  options:\n    max-size: \"10m\"\n\n# services/api.yml\ninclude:\n  - path: ../shared/fragments.yml\n\nservices:\n  api:\n    image: node:18-alpine\n    logging: *default-logging\n</code></pre>"},{"location":"007-DockerCompose-fragments/#docker-compose-extends-legacy","title":"Docker Compose Extends (Legacy)","text":"<p>Note: The <code>extends</code> keyword is considered legacy. Modern Docker Compose recommends using <code>include</code> and YAML anchors instead. However, it\u2019s still supported for backward compatibility.</p>"},{"location":"007-DockerCompose-fragments/#extends-syntax","title":"Extends Syntax","text":"<p>Base service file (<code>common.yml</code>):</p> <pre><code>services:\n  base-service:\n    image: node:18-alpine\n    restart: unless-stopped\n    logging:\n      driver: json-file\n      options:\n        max-size: \"10m\"\n</code></pre> <p>Main compose file:</p> <pre><code>services:\n  api:\n    extends:\n      file: common.yml\n      service: base-service\n    container_name: api-service\n    ports:\n      - \"3000:3000\"\n    environment:\n      SERVICE_NAME: api\n</code></pre>"},{"location":"007-DockerCompose-fragments/#when-to-use-extends","title":"When to Use Extends","text":"<p>Use <code>extends</code> when:</p> <ul> <li>Working with legacy Compose files</li> <li>Sharing configuration between different Compose files</li> <li>Need to override specific service configurations</li> </ul> <p>Prefer <code>include</code> and YAML anchors for new projects as they provide:</p> <ul> <li>Better performance</li> <li>Clearer composition</li> <li>More flexibility</li> <li>Better tooling support</li> </ul>"},{"location":"007-DockerCompose-fragments/#real-world-examples","title":"Real-World Examples","text":""},{"location":"007-DockerCompose-fragments/#example-1-microservices-architecture","title":"Example 1: Microservices Architecture","text":"<p>File Structure:</p> <pre><code>microservices/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 fragments/\n\u2502   \u2514\u2500\u2500 common.yml\n\u251c\u2500\u2500 infrastructure/\n\u2502   \u251c\u2500\u2500 databases.yml\n\u2502   \u251c\u2500\u2500 cache.yml\n\u2502   \u2514\u2500\u2500 messaging.yml\n\u2514\u2500\u2500 services/\n    \u251c\u2500\u2500 user-service.yml\n    \u251c\u2500\u2500 order-service.yml\n    \u2514\u2500\u2500 payment-service.yml\n</code></pre> <p>fragments/common.yml:</p> <pre><code># Common configurations as extension fields\nx-service-defaults: &amp;service-defaults\n  restart: unless-stopped\n  networks:\n    - microservices\n  logging: &amp;logging\n    driver: json-file\n    options:\n      max-size: \"10m\"\n      max-file: \"3\"\n\nx-healthcheck: &amp;healthcheck\n  interval: 30s\n  timeout: 10s\n  retries: 3\n  start_period: 40s\n\nx-node-service: &amp;node-service\n  &lt;&lt;: *service-defaults\n  image: node:18-alpine\n  healthcheck:\n    &lt;&lt;: *healthcheck\n\nx-environment-common: &amp;env-common\n  NODE_ENV: ${NODE_ENV:-production}\n  LOG_LEVEL: ${LOG_LEVEL:-info}\n  REDIS_URL: redis://cache:6379\n  DB_HOST: postgres\n</code></pre> <p>infrastructure/databases.yml:</p> <pre><code>include:\n  - path: ../fragments/common.yml\n\nservices:\n  postgres:\n    &lt;&lt;: *service-defaults\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: ${DB_NAME:-appdb}\n      POSTGRES_USER: ${DB_USER:-admin}\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${DB_USER:-admin}\"]\n      &lt;&lt;: *healthcheck\n\nvolumes:\n  postgres-data:\n</code></pre> <p>services/user-service.yml:</p> <pre><code>include:\n  - path: ../fragments/common.yml\n\nservices:\n  user-service:\n    &lt;&lt;: *node-service\n    build:\n      context: ./user-service\n      dockerfile: Dockerfile\n    environment:\n      &lt;&lt;: *env-common\n      SERVICE_NAME: user-service\n      PORT: 3001\n    ports:\n      - \"3001:3001\"\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"-q\", \"-O\", \"-\", \"http://localhost:3001/health\"]\n      &lt;&lt;: *healthcheck\n    depends_on:\n      postgres:\n        condition: service_healthy\n</code></pre> <p>docker-compose.yml (Main):</p> <pre><code>include:\n  - ./infrastructure/databases.yml\n  - ./infrastructure/cache.yml\n  - ./infrastructure/messaging.yml\n  - ./services/user-service.yml\n  - ./services/order-service.yml\n  - ./services/payment-service.yml\n\nnetworks:\n  microservices:\n    driver: bridge\n</code></pre>"},{"location":"007-DockerCompose-fragments/#example-2-multi-environment-setup","title":"Example 2: Multi-Environment Setup","text":"<p>Structure:</p> <pre><code>project/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 compose/\n\u2502   \u251c\u2500\u2500 base.yml\n\u2502   \u251c\u2500\u2500 fragments.yml\n\u2502   \u251c\u2500\u2500 dev.yml\n\u2502   \u2514\u2500\u2500 prod.yml\n\u2514\u2500\u2500 .env\n</code></pre> <p>compose/fragments.yml:</p> <pre><code>x-app-base: &amp;app-base\n  restart: unless-stopped\n  networks:\n    - app-net\n\nx-dev-settings: &amp;dev-settings\n  build:\n    target: development\n  volumes:\n    - ./src:/app/src:rw\n  environment:\n    NODE_ENV: development\n    DEBUG: \"*\"\n\nx-prod-settings: &amp;prod-settings\n  image: ${REGISTRY}/app:${VERSION}\n  read_only: true\n  security_opt:\n    - no-new-privileges:true\n  environment:\n    NODE_ENV: production\n</code></pre> <p>compose/dev.yml:</p> <pre><code>include:\n  - path: ./fragments.yml\n\nservices:\n  app-dev:\n    &lt;&lt;: [*app-base, *dev-settings]\n    container_name: app-dev\n    ports:\n      - \"3001:3000\"\n    command: npm run dev\n\n  # Development tools\n  adminer:\n    image: adminer:latest\n    ports:\n      - \"8080:8080\"\n    networks:\n      - app-net\n</code></pre> <p>compose/prod.yml:</p> <pre><code>include:\n  - path: ./fragments.yml\n\nservices:\n  app-prod:\n    &lt;&lt;: [*app-base, *prod-settings]\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 1G\n    ports:\n      - \"3000:3000\"\n    command: npm start\n</code></pre> <p>docker-compose.yml:</p> <pre><code>include:\n  - compose/base.yml\n  - path: compose/${ENVIRONMENT:-dev}.yml\n\nnetworks:\n  app-net:\n    driver: bridge\n</code></pre> <p>Usage:</p> <pre><code># Development\nENVIRONMENT=dev docker compose up\n\n# Production\nENVIRONMENT=prod docker compose up\n</code></pre>"},{"location":"007-DockerCompose-fragments/#example-3-modular-configuration","title":"Example 3: Modular Configuration","text":"<p>Complete modular setup with fragments and includes:</p> <pre><code># docker-compose.yml\ninclude:\n  # Core infrastructure\n  - path: ./infrastructure/postgres.yml\n  - path: ./infrastructure/redis.yml\n  - path: ./infrastructure/nginx.yml\n\n  # Application services\n  - path: ./services/api.yml\n  - path: ./services/worker.yml\n  - path: ./services/scheduler.yml\n\n  # Monitoring stack\n  - path: ./monitoring/prometheus.yml\n  - path: ./monitoring/grafana.yml\n\n  # Environment-specific overrides\n  - path: ./overrides/${ENV:-development}.yml\n    env_file: .env.${ENV:-development}\n\n# Global networks\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n    internal: true\n  monitoring:\n    driver: bridge\n\n# Global volumes\nvolumes:\n  postgres_data:\n  redis_data:\n  prometheus_data:\n  grafana_data:\n</code></pre>"},{"location":"007-DockerCompose-fragments/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Extension Fields for Reusable Fragments: <pre><code>x-logging: &amp;logging\n  driver: json-file\n  options:\n    max-size: \"10m\"\n</code></pre></p> </li> <li> <p>Organize Includes Logically:</p> <ul> <li>Group by function (infrastructure, services, monitoring)</li> <li>Separate environment-specific configurations</li> <li>Use subdirectories for clarity</li> </ul> </li> <li> <p>Name Anchors Descriptively:</p> <pre><code>x-node-service-defaults: &amp;node-service-defaults\nx-python-service-defaults: &amp;python-service-defaults\nx-database-healthcheck: &amp;database-healthcheck\n</code></pre> </li> <li> <p>Validate Merged Configuration:</p> <ul> <li>Use Docker Compose Config Command:</li> </ul> <pre><code>docker compose config\n</code></pre> </li> <li> <p>Use Environment Variables:</p> <ul> <li>Use Common Environment Variables:</li> </ul> <pre><code>x-common-env: &amp;common-env\n  ENVIRONMENT: ${ENVIRONMENT:-production}\n  LOG_LEVEL: ${LOG_LEVEL:-info}\n</code></pre> </li> <li> <p>Document Your Fragments:</p> <ul> <li>Include comments in your fragment files to explain their purpose and usage.</li> </ul> <pre><code># Logging configuration - 10MB max size, 3 file rotation\nx-logging: &amp;logging\n  driver: json-file\n  options:\n    max-size: \"10m\"\n    max-file: \"3\"\n</code></pre> </li> <li> <p>Keep Fragments DRY but Readable:</p> <ul> <li>Don\u2019t over-fragment</li> <li>Balance reusability with readability</li> <li>Use fragments for truly common configurations</li> </ul> </li> <li> <p>Version Control:</p> <ul> <li>Commit all fragment files</li> <li>Document the composition structure in README</li> <li>Use <code>.env.example</code> for required variables</li> </ul> </li> </ol>"},{"location":"007-DockerCompose-fragments/#common-patterns","title":"Common Patterns","text":""},{"location":"007-DockerCompose-fragments/#pattern-1-base-service-template","title":"Pattern 1: Base Service Template","text":"<pre><code>x-app-template: &amp;app\n  restart: unless-stopped\n  networks:\n    - app-network\n  logging:\n    driver: json-file\n    options:\n      max-size: \"10m\"\n  healthcheck:\n    interval: 30s\n    timeout: 10s\n    retries: 3\n\nservices:\n  service1:\n    &lt;&lt;: *app\n    image: service1:latest\n\n  service2:\n    &lt;&lt;: *app\n    image: service2:latest\n</code></pre>"},{"location":"007-DockerCompose-fragments/#pattern-2-environment-overrides","title":"Pattern 2: Environment Overrides","text":"<pre><code>x-base: &amp;base\n  image: app:latest\n\nx-dev: &amp;dev\n  &lt;&lt;: *base\n  volumes:\n    - ./src:/app/src\n  environment:\n    DEBUG: \"true\"\n\nx-prod: &amp;prod\n  &lt;&lt;: *base\n  read_only: true\n  environment:\n    DEBUG: \"false\"\n</code></pre>"},{"location":"007-DockerCompose-fragments/#pattern-3-multi-container-application","title":"Pattern 3: Multi-Container Application","text":"<pre><code>x-defaults: &amp;defaults\n  restart: unless-stopped\n  networks:\n    - app\n\nservices:\n  web:\n    &lt;&lt;: *defaults\n    image: nginx\n    depends_on:\n      - api\n\n  api:\n    &lt;&lt;: *defaults\n    image: node\n    depends_on:\n      - db\n\n  db:\n    &lt;&lt;: *defaults\n    image: postgres\n</code></pre>"},{"location":"007-DockerCompose-fragments/#troubleshooting","title":"Troubleshooting","text":""},{"location":"007-DockerCompose-fragments/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<ol> <li> <p>Anchor Not Found:</p> <p><pre><code>Error: Unknown anchor 'service-defaults'\n</code></pre> Solution: Ensure the anchor is defined before it\u2019s referenced. Anchors must be defined in the same file or in an included file that\u2019s loaded first.</p> </li> <li> <p>Merge Conflicts:</p> <pre><code># This will override, not merge\nservice:\n  &lt;&lt;: *base\n  environment:  # This replaces entire environment from *base\n    NEW_VAR: value\n\n# Correct way to merge:\nservice:\n  &lt;&lt;: *base\n  environment:\n    &lt;&lt;: *base-env  # Merge base environment\n    NEW_VAR: value # Add new variable\n</code></pre> </li> <li> <p>Include Path Issues:</p> <pre><code>Error: include path not found: ./compose/services.yml\n</code></pre> <p>Solution: Use paths relative to the main compose file location.</p> </li> <li> <p>Circular Dependencies:</p> <pre><code># Avoid this\ninclude:\n  - a.yml  # includes b.yml\n  - b.yml  # includes a.yml\n</code></pre> </li> <li> <p>Validation Errors:</p> <pre><code># Validate your configuration\ndocker compose config --quiet\n\n# View merged configuration\ndocker compose config &gt; merged-config.yml\n</code></pre> </li> </ol>"},{"location":"007-DockerCompose-fragments/#debugging-commands","title":"Debugging Commands","text":"<ul> <li> <p>Debug with Docker Compose Config:</p> <pre><code># Show final merged configuration\ndocker compose config\n\n# Validate without starting services\ndocker compose config --quiet\n\n# Show configuration for specific service\ndocker compose config api\n\n# List all services\ndocker compose config --services\n\n# Show volumes\ndocker compose config --volumes\n\n# Show networks\ndocker compose config --networks\n\n# Resolve environment variables\ndocker compose config --resolve-image-digests\n</code></pre> </li> </ul>"},{"location":"007-DockerCompose-fragments/#hands-on-exercises","title":"Hands-On Exercises","text":""},{"location":"007-DockerCompose-fragments/#exercise-1-create-a-microservices-setup","title":"Exercise 1: Create a Microservices Setup","text":"<p>Create a compose configuration with:</p> <ul> <li>3 microservices using the same base template</li> <li>Shared logging configuration</li> <li>Individual health checks</li> <li>Common environment variables</li> </ul>"},{"location":"007-DockerCompose-fragments/#exercise-2-multi-environment-configuration","title":"Exercise 2: Multi-Environment Configuration","text":"<p>Build a setup that supports:</p> <ul> <li>Development environment with hot-reload</li> <li>Staging environment with production-like settings</li> <li>Production environment with security hardening</li> <li>All using shared base configuration</li> </ul>"},{"location":"007-DockerCompose-fragments/#exercise-3-modular-infrastructure","title":"Exercise 3: Modular Infrastructure","text":"<p>Design a modular compose setup:</p> <ul> <li>Separate files for databases, caching, messaging</li> <li>Include-based composition</li> <li>Environment-specific overrides</li> <li>Shared network and volume definitions</li> </ul>"},{"location":"007-DockerCompose-fragments/#useful-commands","title":"Useful Commands","text":"<pre><code># View merged configuration\ndocker compose config\n\n# Validate compose file\ndocker compose config --quiet\n\n# Start with specific environment\nENV=production docker compose up -d\n\n# View specific service configuration\ndocker compose config service-name\n\n# List all services\ndocker compose config --services\n\n# Pull all images\ndocker compose pull\n\n# Build all services\ndocker compose build\n\n# Up with build\ndocker compose up --build\n\n# Scale specific service\ndocker compose up -d --scale api=3\n\n# View logs\ndocker compose logs -f service-name\n\n# Stop all services\ndocker compose down\n\n# Remove volumes\ndocker compose down -v\n</code></pre>"},{"location":"008-crictl/","title":"008-crictl","text":""},{"location":"008-crictl/#lab-008-debugging-containers-with-crictl","title":"Lab 008 - Debugging Containers with crictl","text":"<ul> <li>In this lab we will explore <code>crictl</code>, a command-line interface for CRI-compatible container runtimes</li> <li><code>crictl</code> is designed for debugging and inspecting containers and images on Kubernetes nodes</li> <li>We will learn how to install, configure, and use <code>crictl</code> to debug Docker containers</li> <li>This tool is essential for troubleshooting container issues in Kubernetes environments</li> <li> <p>The lab is divided into several tasks:</p> </li> <li> <p>01. What is crictl?</p> </li> <li>02. Prerequisites</li> <li>03. Installation</li> <li>04. Basic Configuration</li> <li>05. Working with Container Images</li> <li>06. Container Operations</li> <li>07. Pod Operations</li> <li>08. Debugging Containers</li> <li>09. Inspecting Container Resources</li> <li>10. Logs and Troubleshooting</li> <li>11. Advanced Debugging Techniques</li> <li>12. Clean up</li> </ul>"},{"location":"008-crictl/#01-what-is-crictl","title":"01. What is crictl?","text":"<p>crictl (CRI CLI) is a command-line interface for interacting with CRI-compatible container runtimes. It provides:</p> <ul> <li>Container Runtime Interface (CRI): Direct interaction with container runtimes like containerd, CRI-O, and Docker (via dockershim)</li> <li>Debugging Tool: Designed specifically for debugging containers in Kubernetes environments</li> <li>Inspection Capabilities: Detailed inspection of containers, pods, and images</li> <li>Troubleshooting: Essential for diagnosing container issues on Kubernetes nodes</li> </ul>"},{"location":"008-crictl/#key-features","title":"Key Features","text":"<ul> <li>\u2705 List and inspect containers and pods</li> <li>\u2705 View container logs and execute commands</li> <li>\u2705 Pull and manage container images</li> <li>\u2705 Monitor container resource usage</li> <li>\u2705 Debug container networking and storage</li> <li>\u2705 Compatible with multiple container runtimes</li> </ul>"},{"location":"008-crictl/#crictl-vs-docker-cli","title":"crictl vs docker CLI","text":"Feature crictl docker Purpose Kubernetes debugging General container management Scope CRI-compatible runtimes Docker Engine only Pod Support Native No Use Case K8s troubleshooting Development &amp; production"},{"location":"008-crictl/#02-prerequisites","title":"02. Prerequisites","text":"<p>Before installing <code>crictl</code>, ensure you have:</p> <ul> <li>Operating System: Linux or macOS</li> <li>Container Runtime: One of the following:</li> <li>containerd (standalone or via Kubernetes)</li> <li>CRI-O</li> <li>Docker Desktop (macOS/Windows)</li> <li>Minikube, kind, or k3s (with containerd)</li> <li>Root/Sudo Access: Required for most operations</li> <li>curl or wget: For downloading the binary</li> </ul> <p>OrbStack Users</p> <p>OrbStack doesn\u2019t expose containerd\u2019s CRI socket directly. To use crictl:</p> <ol> <li>Option 1: Use Minikube, kind, or k3s which provide CRI access</li> <li>Option 2: Use Docker CLI for container debugging instead</li> <li>Option 3: Use a Kubernetes cluster (local or remote)</li> </ol> <p>This lab is designed for environments with direct CRI access.</p>"},{"location":"008-crictl/#check-existing-runtime","title":"Check Existing Runtime","text":"<pre><code># Check if containerd is running\nsystemctl status containerd\n\n# Check if Docker is running\nsystemctl status docker\n\n# Check runtime socket locations\nls -la /var/run/containerd/containerd.sock\nls -la /var/run/dockershim.sock\nls -la /var/run/crio/crio.sock\n</code></pre>"},{"location":"008-crictl/#03-installation","title":"03. Installation","text":""},{"location":"008-crictl/#option-1-download-pre-built-binary-recommended","title":"Option 1: Download Pre-built Binary (Recommended)","text":"<pre><code># Set the version\nVERSION=\"v1.28.0\"\n\n# Download crictl\nwget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz\n\n# Extract the binary\nsudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin\n\n# Remove the archive\nrm -f crictl-$VERSION-linux-amd64.tar.gz\n\n# Verify installation\ncrictl --version\n</code></pre>"},{"location":"008-crictl/#option-2-install-via-package-manager","title":"Option 2: Install via Package Manager","text":"<p>On Ubuntu/Debian:</p> <pre><code># Install dependencies\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl\n\n# Add Kubernetes repository\ncurl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\necho \"deb https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list\n\n# Install cri-tools\nsudo apt-get update\nsudo apt-get install -y cri-tools\n\n# Verify installation\ncrictl --version\n</code></pre> <p>On macOS:</p> <pre><code># Using Homebrew\nbrew install crictl\n\n# Verify installation\ncrictl --version\n</code></pre>"},{"location":"008-crictl/#option-3-build-from-source","title":"Option 3: Build from Source","text":"<pre><code># Install Go (if not already installed)\nwget https://go.dev/dl/go1.21.0.linux-amd64.tar.gz\nsudo tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz\nexport PATH=$PATH:/usr/local/go/bin\n\n# Clone the repository\ngit clone https://github.com/kubernetes-sigs/cri-tools.git\ncd cri-tools\n\n# Build crictl\nmake\n\n# Install the binary\nsudo install -m 755 build/bin/linux/amd64/crictl /usr/local/bin/crictl\n\n# Verify installation\ncrictl --version\n</code></pre>"},{"location":"008-crictl/#04-basic-configuration","title":"04. Basic Configuration","text":""},{"location":"008-crictl/#create-configuration-file","title":"Create Configuration File","text":"<p><code>crictl</code> uses a configuration file to determine which runtime socket to connect to:</p> <pre><code># Create the config directory\nsudo mkdir -p /etc/crictl\n\n# Create the configuration file\nsudo tee /etc/crictl/crictl.yaml &gt; /dev/null &lt;&lt;EOF\nruntime-endpoint: unix:///var/run/containerd/containerd.sock\nimage-endpoint: unix:///var/run/containerd/containerd.sock\ntimeout: 10\ndebug: false\npull-image-on-create: false\nEOF\n</code></pre>"},{"location":"008-crictl/#configuration-for-different-runtimes","title":"Configuration for Different Runtimes","text":"<p>For Docker Desktop (macOS/Windows):</p> <p>Docker Desktop Uses Containerd</p> <p>Docker Desktop uses containerd as its runtime. Use the containerd socket, not the Docker socket.</p> <pre><code># For macOS with Docker Desktop\nmkdir -p ~/.config/crictl\ncat &gt; ~/.config/crictl/crictl.yaml &lt;&lt;EOF\nruntime-endpoint: unix:///var/run/containerd/containerd.sock\nimage-endpoint: unix:///var/run/containerd/containerd.sock\ntimeout: 10\ndebug: false\nEOF\n</code></pre> <p>For Docker Engine on Linux (using containerd):</p> <pre><code># Docker Engine uses containerd, not CRI directly\nsudo tee /etc/crictl/crictl.yaml &gt; /dev/null &lt;&lt;EOF\nruntime-endpoint: unix:///run/containerd/containerd.sock\nimage-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 10\nEOF\n</code></pre> <p>For CRI-O:</p> <pre><code>sudo tee /etc/crictl/crictl.yaml &gt; /dev/null &lt;&lt;EOF\nruntime-endpoint: unix:///var/run/crio/crio.sock\nimage-endpoint: unix:///var/run/crio/crio.sock\ntimeout: 10\nEOF\n</code></pre>"},{"location":"008-crictl/#using-runtime-endpoint-flag","title":"Using Runtime Endpoint Flag","text":"<p>Instead of configuration file, you can specify the runtime endpoint directly:</p> <pre><code># Using containerd (Docker Desktop on macOS)\ncrictl --runtime-endpoint unix:///var/run/containerd/containerd.sock version\n\n# Using containerd (Linux)\ncrictl --runtime-endpoint unix:///run/containerd/containerd.sock version\n\n# Set as environment variable (macOS/Docker Desktop)\nexport CONTAINER_RUNTIME_ENDPOINT=unix:///var/run/containerd/containerd.sock\ncrictl version\n\n# Set as environment variable (Linux)\nexport CONTAINER_RUNTIME_ENDPOINT=unix:///run/containerd/containerd.sock\ncrictl version\n</code></pre>"},{"location":"008-crictl/#find-your-container-runtime-socket","title":"Find Your Container Runtime Socket","text":"<pre><code># List all potential runtime sockets\nls -la /var/run/containerd/*.sock 2&gt;/dev/null\nls -la /run/containerd/*.sock 2&gt;/dev/null\nls -la /var/run/crio/*.sock 2&gt;/dev/null\n\n# For Docker Desktop on macOS\nls -la /var/run/containerd/containerd.sock\n\n# Test connectivity\ncrictl --runtime-endpoint unix:///var/run/containerd/containerd.sock version\n</code></pre>"},{"location":"008-crictl/#verify-configuration","title":"Verify Configuration","text":"<pre><code># Check runtime version\ncrictl version\n\n# Get runtime info\ncrictl info\n\n### Expected Output:\n# {\n#   \"status\": {\n#     \"conditions\": [\n#       {\n#         \"type\": \"RuntimeReady\",\n#         \"status\": true,\n#         \"message\": \"\"\n#       }\n#     ]\n#   }\n# }\n</code></pre>"},{"location":"008-crictl/#alternative-using-crictl-with-minikube","title":"Alternative: Using crictl with Minikube","text":"<p>If you\u2019re using OrbStack or another runtime without direct CRI access, you can use Minikube:</p> <pre><code># Start Minikube with containerd\nminikube start --container-runtime=containerd\n\n# Get the socket path\nminikube ssh \"ls -la /run/containerd/containerd.sock\"\n\n# Configure crictl to use Minikube\ncat &gt; ~/.config/crictl/crictl.yaml &lt;&lt;EOF\nruntime-endpoint: unix:///run/containerd/containerd.sock\nimage-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 10\nEOF\n\n# SSH into Minikube and use crictl\nminikube ssh\n\n# Now inside Minikube VM:\ncrictl version\ncrictl images\ncrictl ps\n</code></pre>"},{"location":"008-crictl/#alternative-using-crictl-with-kind","title":"Alternative: Using crictl with kind","text":"<pre><code># Create a kind cluster\nkind create cluster --name crictl-demo\n\n# Get the container ID of the kind control plane\nKIND_CONTAINER=$(docker ps --filter \"name=crictl-demo-control-plane\" -q)\n\n# Execute crictl commands in the kind container\ndocker exec $KIND_CONTAINER crictl version\ndocker exec $KIND_CONTAINER crictl images\ndocker exec $KIND_CONTAINER crictl ps -a\n</code></pre>"},{"location":"008-crictl/#05-working-with-container-images","title":"05. Working with Container Images","text":""},{"location":"008-crictl/#list-images","title":"List Images","text":"<pre><code># List all images\ncrictl images\n\n# List images with detailed output\ncrictl images -v\n\n# List specific image\ncrictl images nginx\n\n# List images in JSON format\ncrictl images -o json\n</code></pre>"},{"location":"008-crictl/#pull-images","title":"Pull Images","text":"<pre><code># Pull an image\ncrictl pull nginx:latest\n\n# Pull with specific registry\ncrictl pull docker.io/library/alpine:latest\n\n# Pull from private registry (requires authentication)\ncrictl pull myregistry.com/myimage:v1.0\n</code></pre>"},{"location":"008-crictl/#inspect-images","title":"Inspect Images","text":"<pre><code># Get detailed image information\ncrictl inspecti nginx:latest\n\n# Get image in JSON format\ncrictl inspecti --output json nginx:latest | jq .\n\n# Check image size and layers\ncrictl inspecti nginx:latest | grep -E 'size|layer'\n</code></pre>"},{"location":"008-crictl/#remove-images","title":"Remove Images","text":"<pre><code># Remove image by name\ncrictl rmi nginx:latest\n\n# Remove image by ID\ncrictl rmi a1b2c3d4e5f6\n\n# Remove all unused images\ncrictl rmi --prune\n\n# Force remove image\ncrictl rmi -f nginx:latest\n</code></pre>"},{"location":"008-crictl/#06-container-operations","title":"06. Container Operations","text":""},{"location":"008-crictl/#list-containers","title":"List Containers","text":"<pre><code># List all running containers\ncrictl ps\n\n# List all containers (including stopped)\ncrictl ps -a\n\n# List containers with detailed information\ncrictl ps -v\n\n# Filter containers by state\ncrictl ps --state running\ncrictl ps --state exited\n\n# Filter by name\ncrictl ps --name nginx\n\n# Filter by pod\ncrictl ps --pod mypod\n</code></pre>"},{"location":"008-crictl/#create-and-run-containers","title":"Create and Run Containers","text":"<p>First, we need to create a pod sandbox, then create containers within it:</p> <p>Step 1: Create Pod Configuration</p> <pre><code># Create pod config file\ncat &gt; pod-config.json &lt;&lt;EOF\n{\n    \"metadata\": {\n        \"name\": \"debug-pod\",\n        \"namespace\": \"default\",\n        \"uid\": \"debug-pod-uid\"\n    },\n    \"log_directory\": \"/tmp\",\n    \"linux\": {}\n}\nEOF\n</code></pre> <p>Step 2: Create Container Configuration</p> <pre><code># Create container config file\ncat &gt; container-config.json &lt;&lt;EOF\n{\n    \"metadata\": {\n        \"name\": \"debug-container\"\n    },\n    \"image\": {\n        \"image\": \"nginx:latest\"\n    },\n    \"command\": [\n        \"nginx\",\n        \"-g\",\n        \"daemon off;\"\n    ],\n    \"log_path\": \"debug-container.log\",\n    \"linux\": {}\n}\nEOF\n</code></pre> <p>Step 3: Create Pod and Container</p> <pre><code># Create the pod sandbox\nPOD_ID=$(crictl runp pod-config.json)\necho \"Pod ID: $POD_ID\"\n\n# Create the container\nCONTAINER_ID=$(crictl create $POD_ID container-config.json pod-config.json)\necho \"Container ID: $CONTAINER_ID\"\n\n# Start the container\ncrictl start $CONTAINER_ID\n\n# Verify the container is running\ncrictl ps\n</code></pre>"},{"location":"008-crictl/#stop-and-remove-containers","title":"Stop and Remove Containers","text":"<pre><code># Stop a container\ncrictl stop $CONTAINER_ID\n\n# Stop with timeout\ncrictl stop --timeout 30 $CONTAINER_ID\n\n# Remove a container\ncrictl rm $CONTAINER_ID\n\n# Force remove a running container\ncrictl rm -f $CONTAINER_ID\n\n# Remove all stopped containers\ncrictl rm $(crictl ps -a -q --state exited)\n</code></pre>"},{"location":"008-crictl/#07-pod-operations","title":"07. Pod Operations","text":""},{"location":"008-crictl/#list-pods","title":"List Pods","text":"<pre><code># List all pods\ncrictl pods\n\n# List pods with details\ncrictl pods -v\n\n# List pods in specific namespace\ncrictl pods --namespace default\n\n# Filter by pod state\ncrictl pods --state ready\ncrictl pods --state notready\n\n# Get pod in JSON format\ncrictl pods -o json\n</code></pre>"},{"location":"008-crictl/#inspect-pods","title":"Inspect Pods","text":"<pre><code># Inspect specific pod\ncrictl inspectp $POD_ID\n\n# Get pod details in JSON\ncrictl inspectp --output json $POD_ID | jq .\n\n# Check pod metadata\ncrictl inspectp $POD_ID | grep -A 10 metadata\n</code></pre>"},{"location":"008-crictl/#pod-lifecycle-management","title":"Pod Lifecycle Management","text":"<pre><code># Create pod from config\ncrictl runp pod-config.json\n\n# Stop a pod (stops all containers in the pod)\ncrictl stopp $POD_ID\n\n# Remove a pod\ncrictl rmp $POD_ID\n\n# Force remove a pod\ncrictl rmp -f $POD_ID\n\n# Remove all stopped pods\ncrictl rmp $(crictl pods -q --state notready)\n</code></pre>"},{"location":"008-crictl/#08-debugging-containers","title":"08. Debugging Containers","text":""},{"location":"008-crictl/#execute-commands-in-containers","title":"Execute Commands in Containers","text":"<pre><code># Execute command in running container\ncrictl exec -it $CONTAINER_ID /bin/sh\n\n# Execute specific command\ncrictl exec $CONTAINER_ID ls -la /etc\n\n# Execute with environment variables\ncrictl exec -e ENV_VAR=value $CONTAINER_ID env\n\n# Execute as specific user\ncrictl exec -u 1000 $CONTAINER_ID whoami\n</code></pre>"},{"location":"008-crictl/#interactive-debugging-session","title":"Interactive Debugging Session","text":"<pre><code># Start interactive shell\ncrictl exec -it $CONTAINER_ID /bin/bash\n\n# Once inside, you can:\n# - Check running processes\nps aux\n\n# - Check network configuration\nip addr\nnetstat -tulpn\n\n# - Check file system\ndf -h\nls -la /\n\n# - Check environment variables\nenv\n\n# - Install debugging tools (if writable)\napt-get update &amp;&amp; apt-get install -y procps net-tools\n</code></pre>"},{"location":"008-crictl/#container-stats-and-resources","title":"Container Stats and Resources","text":"<pre><code># Get container stats (CPU, Memory, etc.)\ncrictl stats\n\n# Get stats for specific container\ncrictl stats $CONTAINER_ID\n\n# Continuous monitoring\nwatch -n 2 crictl stats\n\n# Get stats in JSON format\ncrictl stats -o json\n</code></pre>"},{"location":"008-crictl/#09-inspecting-container-resources","title":"09. Inspecting Container Resources","text":""},{"location":"008-crictl/#inspect-container-details","title":"Inspect Container Details","text":"<pre><code># Full container inspection\ncrictl inspect $CONTAINER_ID\n\n# Get specific fields using JSON query\ncrictl inspect $CONTAINER_ID | jq '.info.config'\n\n# Check container mounts\ncrictl inspect $CONTAINER_ID | jq '.info.mounts'\n\n# Check container environment\ncrictl inspect $CONTAINER_ID | jq '.info.config.envs'\n\n# Check container labels\ncrictl inspect $CONTAINER_ID | jq '.info.config.labels'\n</code></pre>"},{"location":"008-crictl/#check-container-state","title":"Check Container State","text":"<pre><code># Get container state\ncrictl inspect $CONTAINER_ID | jq '.status.state'\n\n# Check exit code\ncrictl inspect $CONTAINER_ID | jq '.status.exitCode'\n\n# Check started and finished times\ncrictl inspect $CONTAINER_ID | jq '.status | {started: .startedAt, finished: .finishedAt}'\n\n# Check container PID\ncrictl inspect $CONTAINER_ID | jq '.info.pid'\n</code></pre>"},{"location":"008-crictl/#inspect-container-networking","title":"Inspect Container Networking","text":"<pre><code># Get container IP address\ncrictl inspect $CONTAINER_ID | jq '.status.network.ip'\n\n# Check network namespace\ncrictl inspect $CONTAINER_ID | jq '.info.runtimeSpec.linux.namespaces[] | select(.type == \"network\")'\n\n# List network interfaces\ncrictl exec $CONTAINER_ID ip link show\n\n# Check DNS configuration\ncrictl exec $CONTAINER_ID cat /etc/resolv.conf\n</code></pre>"},{"location":"008-crictl/#10-logs-and-troubleshooting","title":"10. Logs and Troubleshooting","text":""},{"location":"008-crictl/#view-container-logs","title":"View Container Logs","text":"<pre><code># View container logs\ncrictl logs $CONTAINER_ID\n\n# Follow logs in real-time\ncrictl logs -f $CONTAINER_ID\n\n# Get last N lines\ncrictl logs --tail 50 $CONTAINER_ID\n\n# Show timestamps\ncrictl logs --timestamps $CONTAINER_ID\n\n# Logs since specific time\ncrictl logs --since 1h $CONTAINER_ID\n</code></pre>"},{"location":"008-crictl/#common-debugging-scenarios","title":"Common Debugging Scenarios","text":"<p>Scenario 1: Container Keeps Restarting</p> <pre><code># Check container status\ncrictl ps -a | grep mycontainer\n\n# Get container ID\nCONTAINER_ID=$(crictl ps -a --name mycontainer -q | head -1)\n\n# Check logs for errors\ncrictl logs $CONTAINER_ID\n\n# Inspect exit code\ncrictl inspect $CONTAINER_ID | jq '.status.exitCode'\n\n# Check restart count (from pod perspective)\ncrictl inspectp $(crictl inspect $CONTAINER_ID | jq -r '.info.sandboxID')\n</code></pre> <p>Scenario 2: Container Network Issues</p> <pre><code># Check container IP\ncrictl exec $CONTAINER_ID ip addr\n\n# Test connectivity from container\ncrictl exec $CONTAINER_ID ping -c 3 8.8.8.8\n\n# Check DNS resolution\ncrictl exec $CONTAINER_ID nslookup google.com\n\n# Check listening ports\ncrictl exec $CONTAINER_ID netstat -tuln\n\n# Inspect network configuration\ncrictl inspect $CONTAINER_ID | jq '.info.runtimeSpec.linux.namespaces'\n</code></pre> <p>Scenario 3: Container Storage Issues</p> <pre><code># Check disk usage in container\ncrictl exec $CONTAINER_ID df -h\n\n# List mounts\ncrictl inspect $CONTAINER_ID | jq '.info.mounts'\n\n# Check for read-only file systems\ncrictl exec $CONTAINER_ID mount | grep ro\n\n# Inspect volume mounts\ncrictl exec $CONTAINER_ID ls -la /var/lib/\n</code></pre> <p>Scenario 4: High Resource Usage</p> <pre><code># Check container resource usage\ncrictl stats $CONTAINER_ID\n\n# Check processes inside container\ncrictl exec $CONTAINER_ID ps aux\n\n# Check memory usage\ncrictl exec $CONTAINER_ID free -h\n\n# Check for memory leaks\ncrictl exec $CONTAINER_ID top -b -n 1\n</code></pre>"},{"location":"008-crictl/#11-advanced-debugging-techniques","title":"11. Advanced Debugging Techniques","text":""},{"location":"008-crictl/#attach-to-running-container","title":"Attach to Running Container","text":"<pre><code># Attach to container's main process\ncrictl attach $CONTAINER_ID\n\n# Note: This attaches to the main process (PID 1)\n# Use Ctrl+P, Ctrl+Q to detach without stopping\n</code></pre>"},{"location":"008-crictl/#port-forwarding-for-debugging","title":"Port Forwarding for Debugging","text":"<pre><code># Get container IP\nCONTAINER_IP=$(crictl inspect $CONTAINER_ID | jq -r '.status.network.ip')\n\n# Access service from host\ncurl http://$CONTAINER_IP:80\n\n# Check open ports\ncrictl exec $CONTAINER_ID netstat -tuln\n</code></pre>"},{"location":"008-crictl/#debugging-with-nsenter","title":"Debugging with nsenter","text":"<p>Access container namespaces directly from the host:</p> <pre><code># Get container PID\nPID=$(crictl inspect $CONTAINER_ID | jq -r '.info.pid')\n\n# Enter network namespace\nsudo nsenter -t $PID -n ip addr\n\n# Enter mount namespace\nsudo nsenter -t $PID -m ls /\n\n# Enter all namespaces\nsudo nsenter -t $PID -a /bin/bash\n</code></pre>"},{"location":"008-crictl/#copy-files-tofrom-containers","title":"Copy Files To/From Containers","text":"<p>While crictl doesn\u2019t have a built-in cp command, you can use alternative methods:</p> <pre><code># Copy file from host to container\ncrictl exec $CONTAINER_ID sh -c 'cat &gt; /tmp/file.txt' &lt; local-file.txt\n\n# Copy file from container to host\ncrictl exec $CONTAINER_ID cat /etc/config.yaml &gt; local-config.yaml\n\n# Using tar for directories\ntar -cf - /local/dir | crictl exec -i $CONTAINER_ID tar -xf - -C /container/path\n</code></pre>"},{"location":"008-crictl/#performance-profiling","title":"Performance Profiling","text":"<pre><code># CPU profile\ncrictl exec $CONTAINER_ID top -b -n 1\n\n# Memory profile\ncrictl exec $CONTAINER_ID cat /proc/meminfo\n\n# I/O stats\ncrictl exec $CONTAINER_ID iostat -x 1 5\n\n# Network stats\ncrictl exec $CONTAINER_ID cat /proc/net/dev\n</code></pre>"},{"location":"008-crictl/#debugging-container-images","title":"Debugging Container Images","text":"<pre><code># Create a debug container with custom entrypoint\ncat &gt; debug-container.json &lt;&lt;EOF\n{\n    \"metadata\": {\n        \"name\": \"debug-container\"\n    },\n    \"image\": {\n        \"image\": \"nginx:latest\"\n    },\n    \"command\": [\n        \"/bin/sh\",\n        \"-c\",\n        \"sleep 3600\"\n    ],\n    \"log_path\": \"debug.log\",\n    \"linux\": {}\n}\nEOF\n\n# Create and start debug container\nDEBUG_CONTAINER=$(crictl create $POD_ID debug-container.json pod-config.json)\ncrictl start $DEBUG_CONTAINER\n\n# Now you can exec into it\ncrictl exec -it $DEBUG_CONTAINER /bin/sh\n</code></pre>"},{"location":"008-crictl/#12-clean-up","title":"12. Clean up","text":""},{"location":"008-crictl/#remove-test-resources","title":"Remove Test Resources","text":"<pre><code># Stop and remove containers\nfor container in $(crictl ps -q); do\n    crictl stop $container\n    crictl rm $container\ndone\n\n# Remove all stopped containers\ncrictl rm $(crictl ps -a -q --state exited)\n\n# Stop and remove pods\nfor pod in $(crictl pods -q); do\n    crictl stopp $pod\n    crictl rmp $pod\ndone\n\n# Remove unused images\ncrictl rmi --prune\n\n# Clean up test files\nrm -f pod-config.json container-config.json debug-container.json\n</code></pre>"},{"location":"008-crictl/#complete-cleanup","title":"Complete Cleanup","text":"<pre><code># Remove ALL containers (use with caution)\ncrictl rm -a -f\n\n# Remove ALL pods (use with caution)\ncrictl rmp -a -f\n\n# Remove ALL images (use with caution)\ncrictl rmi -a\n\n# Remove crictl config\nsudo rm -f /etc/crictl/crictl.yaml\n</code></pre>"},{"location":"008-crictl/#additional-resources","title":"Additional Resources","text":""},{"location":"008-crictl/#quick-reference-commands","title":"Quick Reference Commands","text":"<pre><code># Images\ncrictl images                  # List images\ncrictl pull &lt;image&gt;           # Pull image\ncrictl rmi &lt;image&gt;            # Remove image\ncrictl inspecti &lt;image&gt;       # Inspect image\n\n# Containers\ncrictl ps                     # List running containers\ncrictl ps -a                  # List all containers\ncrictl inspect &lt;container&gt;    # Inspect container\ncrictl logs &lt;container&gt;       # View logs\ncrictl exec -it &lt;container&gt;   # Execute command\ncrictl stats                  # Container stats\n\n# Pods\ncrictl pods                   # List pods\ncrictl runp &lt;config&gt;          # Create pod\ncrictl stopp &lt;pod&gt;            # Stop pod\ncrictl rmp &lt;pod&gt;              # Remove pod\ncrictl inspectp &lt;pod&gt;         # Inspect pod\n\n# System\ncrictl version                # Version info\ncrictl info                   # Runtime info\n</code></pre>"},{"location":"008-crictl/#useful-debugging-tips","title":"Useful Debugging Tips","text":"<ol> <li>Always check logs first: <code>crictl logs &lt;container-id&gt;</code></li> <li>Use <code>-v</code> flag for verbose output: Provides more details</li> <li>Combine with jq for JSON parsing: <code>crictl inspect &lt;id&gt; | jq .</code></li> <li>Use \u2013state flag to filter: Quickly find stopped containers</li> <li>Export CONTAINER_RUNTIME_ENDPOINT: Save typing for repeated commands</li> <li>Use watch for monitoring: <code>watch -n 2 crictl stats</code></li> </ol>"},{"location":"008-crictl/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Issue: \u201cerror reading server preface: http2: frame too large\u201d or \u201cCRI v1 image API\u201d error</p> <pre><code># Problem: Trying to connect to Docker socket instead of containerd\n# Docker doesn't support CRI protocol directly\n\n# Solution 1: Use containerd socket (macOS/Docker Desktop)\nmkdir -p ~/.config/crictl\ncat &gt; ~/.config/crictl/crictl.yaml &lt;&lt;EOF\nruntime-endpoint: unix:///var/run/containerd/containerd.sock\nimage-endpoint: unix:///var/run/containerd/containerd.sock\ntimeout: 10\nEOF\n\n# Solution 2: Find correct socket location\nls -la /var/run/containerd/containerd.sock\nls -la /run/containerd/containerd.sock\n\n# Solution 3: Test with explicit endpoint\ncrictl --runtime-endpoint unix:///var/run/containerd/containerd.sock version\n</code></pre> <p>Issue: \u201cconnection refused\u201d error</p> <pre><code># Solution: Check runtime socket exists and crictl config\nls -la /var/run/containerd/containerd.sock\ncat ~/.config/crictl/crictl.yaml\ncat /etc/crictl/crictl.yaml\n\n# Verify containerd is running (macOS/Docker Desktop)\nps aux | grep containerd\n\n# Check Docker Desktop is running\ndocker version\n</code></pre> <p>Issue: Permission denied</p> <pre><code># Solution: Run with sudo or add user to docker/containerd group\nsudo crictl ps\n\n# Or add user to docker group (Linux)\nsudo usermod -aG docker $USER\nnewgrp docker\n\n# On macOS with Docker Desktop, usually no sudo needed\n# Just ensure Docker Desktop is running\n</code></pre> <p>Issue: Container not starting</p> <pre><code># Solution: Check logs and inspect container\ncrictl logs &lt;container-id&gt;\ncrictl inspect &lt;container-id&gt; | jq '.status'\n\n# Check if container exists\ncrictl ps -a | grep &lt;container-name&gt;\n\n# Check pod status\ncrictl pods\n</code></pre> <p>Issue: \u201cnamespace not found\u201d on macOS</p> <pre><code># crictl shows containers from containerd namespace, not Docker namespace\n# To see Docker containers, you need to use Docker CLI\n\n# List containerd namespaces\nsudo ctr --address /var/run/containerd/containerd.sock namespaces list\n\n# List containers in specific namespace\nsudo ctr --address /var/run/containerd/containerd.sock --namespace k8s.io containers list\n\n# Note: Docker containers run in 'moby' namespace usually\nsudo ctr --address /var/run/containerd/containerd.sock --namespace moby containers list\n</code></pre>"},{"location":"008-crictl/#documentation-links","title":"Documentation Links","text":"<ul> <li>Official Documentation: https://github.com/kubernetes-sigs/cri-tools</li> <li>CRI Specification: https://github.com/kubernetes/cri-api</li> <li>Containerd: https://containerd.io/</li> <li>Kubernetes Debugging: https://kubernetes.io/docs/tasks/debug/</li> </ul>"},{"location":"009-dive-layers/","title":"009-dive-layers","text":""},{"location":"009-dive-layers/#lab-009-inspect-docker-image-layers-with-dive","title":"Lab 009 - Inspect Docker Image Layers with Dive","text":"<ul> <li>This lab introduces the <code>dive</code> tool for analyzing Docker image layers.</li> <li><code>dive</code> is a tool for exploring each layer in a Docker image, helping you understand what\u2019s changed in each layer and identify ways to optimize your images.</li> <li>In this lab, we\u2019ll create a multi-layer Docker image and use <code>dive</code> to inspect its layers.</li> <li>By the end of this lab, you\u2019ll understand how Docker images are built layer by layer and how to use <code>dive</code> for image analysis.</li> </ul>"},{"location":"009-dive-layers/#what-is-dive","title":"What is Dive?","text":"<ul> <li><code>dive</code> is a tool for exploring the contents of Docker images.</li> <li>It allows you to see what files were added, modified, or removed in each layer.</li> <li>This is useful for optimizing image size, understanding image composition, and debugging build issues.</li> <li><code>dive</code> can be run as a Docker container itself or installed locally.</li> </ul>"},{"location":"009-dive-layers/#01-setup-dive","title":"01. Setup Dive","text":"<ul> <li>First, let\u2019s pull the <code>dive</code> image from Docker Hub.</li> <li>If <code>dive</code> is not installed locally, we can use it via Docker.</li> </ul> <pre><code># Pull the dive image\ndocker pull wagoodman/dive\n</code></pre> <ul> <li>Check if <code>dive</code> is installed locally. If not, we\u2019ll alias it to run via Docker.</li> </ul> <pre><code># Check if dive is installed\nif ! command -v dive &amp;&gt; /dev/null\nthen\n  echo \"dive could not be found, using Docker alias...\"\n  # Alias dive to run via Docker\n  alias dive=\"docker run -ti --rm -v /var/run/docker.sock:/var/run/docker.sock docker.io/wagoodman/dive\"\nfi\n</code></pre>"},{"location":"009-dive-layers/#02-create-a-multi-layer-dockerfile","title":"02. Create a Multi-Layer Dockerfile","text":"<ul> <li>Let\u2019s create a Dockerfile with several layers to demonstrate how <code>dive</code> works.</li> <li>Each <code>RUN</code> command creates a new layer.</li> </ul> <pre><code># Create the Dockerfile\ncat &lt;&lt; EOF &gt; Dockerfile\n### Layer 00\nFROM alpine\n\n## Layer 01\nWORKDIR /__app\n\n## Layer 02\nRUN echo \"Hello World\" &gt; file1.txt\n\n## Layer 03\nRUN echo \"10.10.10.10\" &gt; /etc/hosts\n\n## Layer 04\nRUN cat /etc/hosts &gt; hosts.txt\n\nEOF\n</code></pre>"},{"location":"009-dive-layers/#03-build-the-image","title":"03. Build the Image","text":"<ul> <li>Build the Docker image from the Dockerfile.</li> </ul> <pre><code># Build the image\ndocker build -t nirgeier/docker-labs-07-dive -f Dockerfile .\n</code></pre>"},{"location":"009-dive-layers/#04-print-the-dockerfile-layers","title":"04. Print the Dockerfile Layers","text":"<ul> <li>Let\u2019s review what each layer does:</li> </ul> <pre><code>echo \"=== Dockerfile Layers ===\"\necho \"Layer 00: FROM alpine\"\necho \"Layer 01: WORKDIR /__app\"\necho \"Layer 02: RUN echo \\\"Hello World\\\" &gt; file1.txt\"\necho \"Layer 03: RUN echo \\\"10.10.10.10\\\" &gt; /etc/hosts\"\necho \"Layer 04: RUN cat /etc/hosts &gt; hosts.txt\"\necho \"=========================\"\n</code></pre>"},{"location":"009-dive-layers/#05-inspect-layers-with-dive","title":"05. Inspect Layers with Dive","text":"<ul> <li>Now, let\u2019s use <code>dive</code> to inspect the image layers.</li> <li><code>dive</code> will analyze the image and show you what\u2019s in each layer.</li> <li>We\u2019ll also generate a JSON output file for further analysis.</li> </ul> <pre><code># Run dive on the image and generate JSON output\ndive nirgeier/docker-labs-07-dive --json output.json\n</code></pre> <ul> <li>When <code>dive</code> runs, you\u2019ll see an interactive interface showing:</li> <li>The layers on the left</li> <li>File changes in each layer on the right</li> <li>Use arrow keys to navigate, and press <code>Ctrl+C</code> to exit</li> </ul>"},{"location":"009-dive-layers/#06-analyze-the-json-output","title":"06. Analyze the JSON Output","text":"<ul> <li>After running <code>dive</code>, we can analyze the <code>output.json</code> file.</li> <li>Let\u2019s use <code>jq</code> to extract information about files changed in layers 2 and above.</li> </ul> <pre><code># Search for files changed in layers starting from index 2\njq '.layer[] | select(.index &gt;= 2) | \"\\(.command) -&gt; \\(.fileList[]?.path)\"' output.json\n</code></pre> <ul> <li>This will show you which files were added or modified in each layer.</li> </ul>"},{"location":"009-dive-layers/#07-clean-up","title":"07. Clean Up","text":"<ul> <li>Remove the created image and files.</li> </ul> <pre><code># Remove the image\ndocker rmi nirgeier/docker-labs-07-dive\n\n# Remove the Dockerfile and output.json\nrm -f Dockerfile output.json\n</code></pre>"},{"location":"010-bake/","title":"010-bake","text":""},{"location":"010-bake/#lab-010-docker-bake","title":"Lab 010 - Docker Bake","text":""},{"location":"010-bake/#table-of-contents","title":"Table of Contents","text":"<ul> <li>1. Introduction</li> <li>What is Docker <code>Docker Bake</code>?</li> <li>What is Docker <code>BuildKit</code>?</li> <li>Key Features</li> <li>Comparison: Docker Bake vs Docker Compose</li> <li>Docker Bake syntax</li> <li>Common Commands</li> <li>Advanced Features</li> <li>Multi-Stage Builds with Matrix</li> <li>Build Secrets</li> <li>Cache Configuration / Build Caching</li> <li>Cache Configuration / Build Caching Workflow</li> <li>Target Inheritance</li> </ul>"},{"location":"010-bake/#1-introduction","title":"1. Introduction","text":""},{"location":"010-bake/#what-is-docker-docker-bake","title":"What is Docker <code>Docker Bake</code>?","text":"<ul> <li> <p>\ud83d\udc4d <code>Docker Bake</code> is a feature of <code>BuildKit</code> / <code>Docker Buildx</code> that allows you    to define and orchestrate complex builds using a high-level build tool that uses to build Docker images defined in configuration files.</p> </li> <li> <p>\ud83d\udc4d <code>Docker Bake</code> is written in a declarative language (<code>HCL</code>, <code>JSON</code>, or <code>YAML</code>). </p> </li> <li> <p>\ud83d\udc4d <code>Docker Bake</code> is designed for building multiple images or targets concurrently, making it ideal for monorepos, microservices, or any project with several <code>Dockerfiles</code>.</p> </li> <li> <p>\ud83d\udc4d <code>Docker Bake</code> extends beyond single <code>Dockerfile</code>s to support complex build scenarios with multiple targets, platforms, and configurations.</p> </li> <li> <p>\ud83d\udc4d <code>Docker Bake</code> is designed for CI/CD pipelines, multi-platform builds, and complex build workflows.</p> </li> </ul>"},{"location":"010-bake/#what-is-docker-buildkit","title":"What is Docker <code>BuildKit</code>?","text":"<ul> <li> <p>\ud83d\udc4d <code>BuildKit</code> is a modern build subsystem for Docker that improves performance, storage management, and caching  </p> </li> <li> <p>\ud83d\udc4d <code>BuildKit</code> is the engine behind <code>Docker Bake</code>, enabling advanced features like multi-platform builds, caching, and build secrets</p> </li> <li> <p>\ud83d\udc4d <code>BuildKit</code> is the default build engine for Docker, replacing the traditional docker build mechanism.</p> </li> <li> <p>\ud83d\udc4d <code>BuildKit</code> allows for parallel builds, advanced caching, and better resource utilization.</p> </li> <li> <p>\ud83d\udc4d <code>BuildKit</code> supports advanced features like build secrets, SSH forwarding, and more.</p> </li> <li> <p>\ud83d\udc4d <code>BuildKit</code> is a key component of the new Docker Engine 20.10 release, which includes the <code>buildkit</code> subcommand and the <code>docker buildx</code> command.</p> </li> </ul>"},{"location":"010-bake/#key-features","title":"Key Features","text":"Feature Description Advanced BuildKit Features Leverage BuildKit for caching, multi-platform builds, and advanced outputs. Advanced caching Sophisticated caching strategies for faster builds Build matrix Define multiple build configurations and targets Build secrets Securely pass sensitive information during builds Cache configuration Fine-tune caching strategies for faster builds CI/CD integration Ideal for automated build pipelines and workflows Concurrent Builds Build multiple images in parallel with a single command. Custom build arguments Specify different build arguments for each target Custom build contexts Specify different directories for each target Custom Dockerfiles Use different Dockerfiles for each target Declarative Build Configuration Define build targets, groups, arguments, tags, and more in a single file. Declarative syntax Use HCL, JSON, or YAML to define build configurations Extensibility Supports custom build steps and plugins Flexible File Formats Supports HCL (HashiCorp Configuration Language), JSON, and YAML (Compose extension). Group targets Organize multiple build targets into logical groups Inheritance Reuse common configurations across multiple targets Integration with Docker Compose You can use Compose files as Bake files for seamless migration. Matrix Builds Easily define build matrices for different platforms, versions, or configurations. Multi-platform builds Build for multiple architectures simultaneously (ARM, AMD64, etc.) Variable interpolation Use variables and functions for dynamic configurations"},{"location":"010-bake/#comparison-docker-bake-vs-docker-compose","title":"Comparison: Docker Bake vs Docker Compose","text":"Feature Docker Bake Docker Compose Purpose Build orchestration Service orchestration File Format HCL, JSON, YAML (Compose) YAML Parallel Builds Yes No Multi-platform Yes (via BuildKit) Limited Service Deploy No Yes Caching Advanced BuildKit caching Basic Inheritance Yes No CI/CD Ideal for CI/CD pipelines Limited Extensibility Supports custom build steps Limited Advanced Advanced build features Basic <p>[!WARNING]  <code>Docker Bake</code> requires Docker Engine v20.10.0 or higher. <code>Docker Bake</code> requires BuildKit for advanced build features.</p>"},{"location":"010-bake/#docker-bake-syntax","title":"Docker Bake syntax","text":"<p>[!IMPORTANT]  <code>docker-bake.hcl</code> is a declarative build configuration file format.  </p> <ul> <li>Here\u2019s a basic <code>docker-bake.hcl</code> file structure:</li> <li>It uses the HashiCorp Configuration Language (HCL) syntax for defining build configurations.</li> <li>This example defines two targets: <code>frontend</code> and <code>backend-api</code>, each with its own context, Dockerfile, tags, platforms, and build arguments.</li> </ul> <pre><code># Define variables\nvariable \"TAG\" {\n  default = \"latest\"\n}\n\n# Define a user variable for tagging images\n# This can be your Docker Hub username or any identifier\nvariable \"USER\" {\n  default = \"username\"\n}\n\n# Define a group of targets for default builds\ngroup \"default\" {\n  targets = [\"frontend\", \"backend-api\"]\n}\n\n# Frontend service\ntarget \"frontend\" {\n  # Directory containing the frontend code\n  context  = \"./frontend\"           \n\n  # Use a specific Dockerfile for production\n  dockerfile = \"Dockerfile.prod\" \n\n  # Tag the image with user and tag         \n  tags     = [\"${USER}/frontend:${TAG}\"]    \n\n  # Build for multiple architectures\n  platforms  = [\"linux/amd64\", \"linux/arm64\"]   \n\n  # Pass build-time variables to the Dockerfile \n  args = {\n    # Set Node.js environment to production\n    NODE_ENV = \"production\" \n\n    # Set API URL for the frontend\n    API_URL = \"https://api.codewizard.com\"\n  }\n}\n\n# Node.js backend service\ntarget \"backend-api\" {\n  context  = \"./backend\" \n  dockerfile = \"Dockerfile\"\n  tags     = [\"${USER}/backend:${TAG}\"]\n  platforms  = [\"linux/amd64\", \"linux/arm64\"]\n   args = {\n    NODE_ENV = \"production\"\n  }\n}\n</code></pre> <ul> <li>Here is another example of a <code>Docker Bake</code> configuration file: in JSON</li> </ul> <pre><code>{\n  \"variable\": {\n    \"TAG\": {\n      \"default\": \"latest\"\n    },\n    \"USER\": {\n      \"default\": \"username\"\n    }\n  },\n  \"group\": {\n    \"default\": {\n      \"targets\": [\"frontend\", \"backend-api\"]\n    }\n  },\n  \"target\": {\n    \"frontend\": {\n      \"context\": \"./frontend\",\n      \"dockerfile\": \"Dockerfile.prod\",\n      \"tags\": [\"${USER}/frontend:${TAG}\"],\n      \"platforms\": [\"linux/amd64\", \"linux/arm64\"],\n      \"args\": {\n        \"NODE_ENV\": \"production\",\n        \"API_URL\": \"https://api.codewizard.com\"\n      }\n    },\n    \"backend-api\": {\n      \"context\": \"./backend\",\n      \"dockerfile\": \"Dockerfile\",\n      \"tags\": [\"${USER}/backend:${TAG}\"],\n      \"platforms\": [\"linux/amd64\", \"linux/arm64\"],\n      \"args\": {\n        \"NODE_ENV\": \"production\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"010-bake/#common-commands","title":"Common Commands","text":"Feature Description Command Build Default Group Build all targets in the default group <code>docker buildx bake</code> Build Specific Target Build a specific target by name <code>docker buildx bake &lt;target&gt;</code> Build with Custom Variables Override variables for a specific build <code>docker buildx bake --set &lt;target&gt;.&lt;var&gt;=&lt;value&gt;</code> Build and Push Build images and push them to a registry <code>docker buildx bake --push</code> Build for Specific Platform Build images for a specific platform architecture <code>docker buildx bake --platform &lt;platform&gt;</code> View Build Configuration Print the effective build configuration <code>docker buildx bake --print</code> Build with Custom File Use a custom bake file instead of the default <code>docker buildx bake -f &lt;file&gt;</code>"},{"location":"010-bake/#advanced-features","title":"Advanced Features","text":""},{"location":"010-bake/#multi-stage-builds-with-matrix","title":"Multi-Stage Builds with Matrix","text":"<ul> <li>What is a Build Matrix?</li> <li>A build matrix allows you to create multiple image variations from a single configuration. </li> <li>This is useful when you need to build multiple versions of your application or service.</li> <li>For example, you might need to build different versions of your application for different environments (e.g., development, staging, production).</li> <li>By using a build matrix, you can specify multiple combinations of values for each configuration option.</li> <li> <p>Instead of writing separate targets for each combination, Docker Bake automatically generates all possible combinations.</p> </li> <li> <p>Example: Building multiple Node.js versions for different environments</p> </li> </ul> <pre><code>target \"app\" {\n  matrix = {\n    version = [\"18\", \"20\"]\n    env = [\"dev\", \"prod\"]\n  }\n\n  name = \"app-node${version}-${env}\"\n  context = \".\"\n  dockerfile = \"Dockerfile\"\n  tags = [\"myapp:node${version}-${env}\"]\n\n  args = {\n    NODE_VERSION = \"${version}\"\n    NODE_ENV     = \"${env}\"\n  }\n}\n</code></pre> <ul> <li>Quiz: What will be the output of the above example?</li> </ul> Answer <ul> <li>app-node18-dev</li> <li>app-node18-prod</li> <li>app-node20-dev</li> <li>app-node20-prod</li> </ul>    - Each build will use the specified Node.js version and environment.   - The `name` field dynamically constructs the image name based on the matrix values.   - The `args` field passes the Node.js version and environment as build arguments to the Dockerfile.   - The `tags` field tags the built images with the corresponding Node.js version and environment.   - The `context` and `dockerfile` fields specify the build context and Dockerfile to use for all builds.   - The `matrix` field defines the combinations of `version` and `env` to build."},{"location":"010-bake/#build-secrets","title":"Build Secrets","text":"<ul> <li><code>Build secrets</code> allow you to securely pass sensitive information (like API keys, passwords, or certificates) to your Docker build process without including them in the final image or build history.</li> <li>This is particularly useful for keeping sensitive data out of your Docker images and ensuring that it is only available during the build process. </li> <li><code>Build secrets</code> can be stored in a secure location, such as a secure vault or a secret management service, and then referenced during the build process.</li> <li><code>Build secrets</code> are mounted into the build environment at runtime, allowing you to use them without exposing them in the final image.</li> <li><code>Build secrets</code> are not stored in the final image layers, ensuring that sensitive information is not leaked.</li> <li><code>Build secrets</code> are only available during the build process and are not accessible to the final image or container.</li> <li><code>Build secrets</code> are defined in the <code>docker-bake.hcl</code> file using the <code>secret</code> field.</li> <li>You can use the <code>--secret</code> flag to pass secrets to the build process.</li> <li> <p>Secrets can also be defined in the Dockerfile using the <code>RUN --mount=type=secret</code> syntax.</p> </li> <li> <p>Example: Using a secret file during build</p> </li> </ul> <pre><code>target \"secure-app\" {\n  context = \".\"\n  dockerfile = \"Dockerfile\"\n  secret = [\n    \"id=mysecret,src=./secret.txt\"\n  ]\n  tags = [\"myapp:secure\"]\n}\n</code></pre> <ul> <li><code>Dockerfile</code>:</li> </ul> <pre><code>FROM node:18\n\n# Use the secret during build (it wont be in the final image)\n# as mentioned and explained above\n\nRUN --mount=type=secret,id=mysecret \\\n    API_KEY=$(cat /run/secrets/mysecret) &amp;&amp; \\\n    npm install --registry=https://registry.example.com\n</code></pre>"},{"location":"010-bake/#cache-configuration-build-caching","title":"Cache Configuration / Build Caching","text":"<ul> <li><code>Docker Bake</code> supports advanced caching strategies to speed up builds and reduce resource usage.</li> <li>Caching allows you to reuse previously built layers, which can significantly speed up the build process</li> <li><code>Docker Bake</code> can use different cache sources, such as local files, remote registries, or GitHub Actions cache.</li> <li>Caching can be configured using the <code>cache-from</code> and <code>cache-to</code> fields in the <code>docker-bake.hcl</code> file.</li> <li>Caching can also be configured using the <code>--cache-from</code> and <code>--cache-to</code> flags when running the <code>docker buildx bake</code> command.</li> <li>Caching can be used to speed up builds by reusing previously built layers, which can significantly reduce build times.</li> <li>Caching can also be used to reduce resource usage by avoiding unnecessary rebuilds of unchanged layers.</li> <li>Caching can be used to share build layers between different builds, which can further speed up the build process.</li> <li>Caching can be used to optimize the build process by reusing previously built layers, which can significantly reduce build times.</li> <li>Caching can reduce build times from minutes to seconds for unchanged code.</li> <li>Example: Using GitHub Actions cache</li> </ul> <pre><code>target \"cached-app\" {\n  context = \".\"\n  dockerfile = \"Dockerfile\"\n  cache-from = [\"type=gha\"]\n  cache-to = [\"type=gha,mode=max\"]\n  tags = [\"myapp:cached\"]\n}\n</code></pre> <p>Cache Types:</p> Type Description <code>type=gha</code> GitHub Actions cache (for CI/CD) <code>type=local</code> Local filesystem cache <code>type=registry</code> Docker registry cache"},{"location":"010-bake/#cache-configuration-build-caching-workflow","title":"Cache Configuration / Build Caching Workflow","text":"<p><code>mermaid flowchart TD     A[First build] --&gt;|Takes full time, saves cache| B[Second build]     B --&gt;|Reuses cached layers, builds only changed parts| C[Result]     C --&gt;|Significantly faster build times| D[End]</code></p>"},{"location":"010-bake/#target-inheritance","title":"Target Inheritance","text":"<ul> <li><code>Docker Bake</code> allows you to create a base configuration and reuse it across multiple targets. </li> <li>This follows the DRY (Don\u2019t Repeat Yourself) principle - define common settings once and inherit them.</li> </ul> <p>Example: Sharing common settings across multiple builds</p> Setting Description <code>target \"base\"</code> This is a base target that defines common build settings <code>context = \".\"</code> Uses the current directory as the build context <code>dockerfile = \"Dockerfile\"</code> Uses the default Dockerfile <code>platforms = [\"linux/amd64\", \"linux/arm64\"]</code> Builds for both AMD64 and ARM64 architectures <code>tags = [\"myapp:latest\"]</code> Sets the default tag for the image <code>cache-from = [\"type=gha\"]</code> Uses GitHub Actions cache for the build <code>cache-to = [\"type=gha,mode=max\"]</code> Saves the cache to GitHub Actions cache with <pre><code># Base target with common settings\ntarget \"base\" {\n  context = \".\"\n  dockerfile = \"Dockerfile\"\n  platforms = [\"linux/amd64\", \"linux/arm64\"]\n  tags = [\"myapp:latest\"]\n  cache-from = [\"type=gha\"]\n  cache-to = [\"type=gha,mode=max\"]\n}\n\n# Example: Using inheritance to define common settings (1)\ntarget \"web\" {\n  inherits = [\"base\"]\n  tags = [\"myapp/web:latest\"]\n  target = \"web\"\n}\n\n# Example: Using inheritance to define common settings (2)\ntarget \"api\" {\n  inherits = [\"base\"]\n  tags = [\"myapp/api:latest\"]\n  target = \"api\"\n}\n</code></pre> <p>How it works:</p> <p><code>mermaid flowchart TD     A[Base target] --&gt;|Defines common settings | B[Child targets]     B --&gt;|Inherit from base and add their specific settings| C[Result]     C --&gt;|Both web and api targets automatically get the same platforms and build context| D[End]</code></p> <p>Benefits:</p> <ul> <li>Consistency: Sharing - ensures consistent build configurations</li> <li>Reusability: All targets use the same base configuration</li> <li>Maintainability: Supports multiple targets with the same settings platforms in one place, affects all children</li> <li>Cleaner code: No repetitive configuration</li> <li>DRY principle: Avoids duplication of common settings</li> <li>Flexibility: Each target can still have its own specific settings</li> <li>Scalability: Easily add new targets with shared settings</li> </ul>"},{"location":"011-Security%26Trust/","title":"011-Security&Trust","text":""},{"location":"011-Security%26Trust/#lab-011-docker-security-trust","title":"Lab 011 - Docker Security &amp; Trust","text":"<ul> <li>This lab covers advanced Docker security features and best practices for container security and privilege management.</li> <li>You\u2019ll learn about reducing the attack surface, implementing the Principle of Least Privilege, and using Docker\u2019s security mechanisms to protect your containers.</li> <li>Topics include non-root user execution, Linux capabilities, security options, and mandatory access control.</li> <li>By the end of this lab, you\u2019ll understand how to build and run secure Docker containers.</li> </ul>"},{"location":"011-Security%26Trust/#table-of-contents","title":"Table of Contents","text":"<ul> <li>\ud83d\udee1\ufe0f Non-Root User Execution with the <code>USER</code> Instruction</li> <li>How to Use <code>USER</code></li> <li>\ud83d\udd12 Advanced Security Issues and Features</li> <li>1. Privileged Containers (<code>--privileged</code>)</li> <li>2. Linux Capabilities (<code>--cap-drop</code>, <code>--cap-add</code>)</li> <li>3. Preventing Privilege Escalation</li> <li>4. Mandatory Access Control (MAC)</li> <li>5. User Namespace Remapping (UserNS)</li> <li>\ud83d\udd11 Summary of Security Best Practices</li> </ul> <ul> <li>Docker\u2019s advanced features offer critical mechanisms for container security and privilege management, primarily revolving around reducing the attack surface. </li> <li>The key is to adhere to the Principle of Least Privilege (PoLP).</li> </ul>"},{"location":"011-Security%26Trust/#non-root-user-execution-with-the-user-instruction","title":"\ud83d\udee1\ufe0f Non-Root User Execution with the <code>USER</code> Instruction","text":"<ul> <li>By default, the process inside a Docker container runs as the <code>root user (UID 0)</code>, which is a major security risk. </li> <li>If an attacker successfully exploits a vulnerability in the application, they gain root access inside the container. </li> <li>Depending on the container\u2019s configuration and any underlying kernel vulnerabilities, this could potentially lead to a container breakout and root access to the host machine.</li> <li>The <code>USER</code> instruction in a <code>Dockerfile</code> is essential for mitigating this risk:</li> </ul>"},{"location":"011-Security%26Trust/#how-to-use-user","title":"How to Use <code>USER</code>","text":"<ol> <li>Create a Non-Root User</li> <li>Use a <code>RUN</code> instruction to create a dedicated user and group before switching the user.     <pre><code># Create an unprivileged user (e.g., 'appuser' with UID 1001)\nRUN adduser -D appuser\n\n# Set the ownership of the application directory to the new user\nRUN mkdir /app &amp;&amp; chown -R appuser:appuser /app\n\n# Switch to the non-root user for all subsequent instructions and runtime\nUSER appuser \n\nWORKDIR /app\n# ... rest of your application commands (e.g., CMD)\n</code></pre></li> </ol> <p>adduser -D</p> <p>Using <code>adduser -D</code> (on Alpine) creates a system user without a password or home directory, which is more secure.</p>"},{"location":"011-Security%26Trust/#best-practices-for-permissions","title":"Best Practices for Permissions:","text":""},{"location":"011-Security%26Trust/#file-permissions","title":"File Permissions","text":"<ul> <li>Ensure the non-root user has the necessary read, write, and execute permissions for all files, directories, or temporary spaces the application needs. </li> <li>This often requires running <code>chown</code> in the Dockerfile.</li> </ul>"},{"location":"011-Security%26Trust/#multi-stage-builds","title":"Multi-Stage Builds","text":"<ul> <li>Use multi-stage builds to perform privileged operations (like installing system packages with <code>apt</code> or <code>yum</code>) in a \u201cbuilder\u201d stage run as root, and then copy only the necessary artifacts into a minimal, non-root \u201cruntime\u201d stage. </li> <li>This prevents residual root tools or sensitive build-time files from existing in the final image.</li> </ul>"},{"location":"011-Security%26Trust/#bind-ports-1024","title":"Bind Ports &gt; 1024","text":"<ul> <li>Only the root user can bind to privileged ports (0-1023). </li> <li>If your application runs as non-root, it must bind to ports 1024 or higher (e.g., port 8080).</li> </ul>"},{"location":"011-Security%26Trust/#user","title":"User","text":"<ul> <li>Always specify a non-root user with the <code>USER</code> instruction in your Dockerfile to prevent running as root.</li> <li>Avoid using <code>sudo</code> inside containers; instead, configure permissions properly at build time.</li> <li>Consider using well-known non-root users like</li> </ul>"},{"location":"011-Security%26Trust/#privileged-containers","title":"Privileged Containers","text":"<ul> <li>Avoid running containers with the <code>--privileged</code> flag, as it grants excessive permissions and can lead to host compromise.</li> <li>Instead, use specific capability additions (<code>--cap-add</code>) if certain elevated privileges are necessary.</li> <li>Always review and minimize the capabilities your container needs.</li> <li>Consider using tools like <code>seccomp</code> to restrict system calls your container can make.</li> </ul>"},{"location":"011-Security%26Trust/#advanced-security-issues-and-features","title":"\ud83d\udd12 Advanced Security Issues and Features","text":"<ul> <li>Beyond running as a non-root user, Docker provides several advanced features to lock down container security:</li> </ul>"},{"location":"011-Security%26Trust/#1-privileged-containers-privileged","title":"1. Privileged Containers (<code>--privileged</code>)","text":"<ul> <li> <p>A privileged container is the most dangerous security configuration and should be avoided at all costs unless absolutely necessary (e.g., for running Docker-in-Docker or a tool that needs to interact directly with the host kernel).</p> </li> <li> <p>Security Issue: </p> <ul> <li>Running a container with the <code>--privileged</code> flag grants it all Linux Capabilities (see below) and allows it to access all devices on the host. In a privileged container, the root user inside the container is essentially equivalent to the root user on the host machine. A container breakout is almost guaranteed.</li> <li>Mitigation: NEVER use <code>--privileged</code> in production.    Instead, identify the specific capabilities your application needs and grant only those using the <code>--cap-add</code> flag.</li> </ul> </li> </ul>"},{"location":"011-Security%26Trust/#2-linux-capabilities-cap-drop-cap-add","title":"2. Linux Capabilities (<code>--cap-drop</code>, <code>--cap-add</code>)","text":"<ul> <li>Linux Capabilities are a finer-grained way to manage root permissions. </li> <li>Traditional Unix divides processes into two categories: root (UID 0) and unprivileged. </li> <li> <p>Capabilities break down the powers of the root user into discrete units.</p> </li> <li> <p>By default, Docker grants a set of \u201csafe\u201d capabilities and drops dangerous ones.</p> </li> <li>Best Practice: Use the <code>--cap-drop=ALL</code> flag to remove all capabilities, then use <code>--cap-add</code> to grant only the handful that the application truly requires (PoLP).     <pre><code># Runs the container with no capabilities except NET_BIND_SERVICE\n# A container that needs to bind to a low-numbered port (e.g., port 80) \n# only needs the `NET_BIND_SERVICE` capability.\ndocker run --cap-drop=ALL --cap-add=NET_BIND_SERVICE my-image\n</code></pre></li> </ul>"},{"location":"011-Security%26Trust/#3-preventing-privilege-escalation","title":"3. Preventing Privilege Escalation","text":"<ul> <li> <p>Even if a container starts as non-root, a malicious process could attempt to escalate its privileges.</p> </li> <li> <p><code>no-new-privileges</code>: Use the <code>--security-opt=no-new-privileges</code> flag to prevent a process from gaining new privileges via mechanisms like <code>setuid</code> or <code>setgid</code> binaries. This is a crucial security layer.</p> </li> </ul>"},{"location":"011-Security%26Trust/#4-mandatory-access-control-mac","title":"4. Mandatory Access Control (MAC)","text":"<ul> <li>Docker integrates with two major Linux security modules for deeper kernel-level protection:</li> </ul> Feature Description Purpose Seccomp (Secure Computing) Filters which system calls (syscalls) a container process can make to the Linux kernel. Blocks dangerous syscalls that could be used for container breakout, even if the process is running as root. Docker uses a restrictive default profile. AppArmor (Application Armor) Creates Mandatory Access Control (MAC) profiles that limit what files, network resources, and other capabilities a container can access. Provides an extra layer of defense-in-depth by confining the container process\u2019s access to host resources. Docker loads a moderately protective <code>docker-default</code> profile."},{"location":"011-Security%26Trust/#5-user-namespace-remapping-userns","title":"5. User Namespace Remapping (UserNS)","text":"<ul> <li> <p>This is one of the strongest isolation features for mitigating the risk of a container breakout.</p> </li> <li> <p>How it Works: It maps the root user (UID 0) inside the container to an unprivileged user (a high UID, e.g., 100000) on the host machine.</p> </li> <li>Security Benefit: If an attacker does manage to escape the container, they only have the privileges of the unprivileged mapped user on the host, not actual root access. This significantly reduces the potential for host compromise. This feature can be enabled at the Docker daemon level.</li> </ul>"},{"location":"011-Security%26Trust/#summary-of-security-best-practices","title":"\ud83d\udd11 Summary of Security Best Practices","text":"Security Principle Docker Feature/Instruction Impact Least Privilege <code>USER non-root</code> in <code>Dockerfile</code> Prevents an exploit from gaining root access inside the container. Runtime Hardening <code>--cap-drop=ALL</code>, <code>--cap-add=&lt;needed-caps&gt;</code> Removes unnecessary superuser powers, reducing the attack surface. Kernel Isolation Seccomp/AppArmor Limits the dangerous operations (syscalls, file access) a process can perform. No Escalation <code>--security-opt=no-new-privileges</code> Prevents a non-root process from gaining root powers during execution. Host Protection User Namespace Remapping Ensures that an escaped container process runs as an unprivileged user on the host."},{"location":"011-Security%26Trust/#running-the-demos","title":"Running the Demos","text":"<p>This lab includes individual demo scripts for each security topic:</p> Demo Script Description <code>demo1-nonroot.sh</code> Demonstrates non-root user execution <code>demo2-capabilities.sh</code> Shows Linux capabilities management <code>demo3-security-options.sh</code> Demonstrates security options like no-new-privileges <code>demo4-mac.sh</code> Checks Mandatory Access Control (Seccomp/AppArmor) status <code>demo5-userns.sh</code> Explores User Namespace Remapping configuration <p>To run a demo:</p> <pre><code>chmod +x demo1-nonroot.sh\n./demo1-nonroot.sh\n</code></pre> <p>Each demo is self-contained with automatic cleanup.</p>"},{"location":"012-gvisor/","title":"012 - gVisor Lab","text":"<ul> <li>This lab demonstrates the use of gVisor, a sandbox runtime for containers that provides an additional layer of security by intercepting and filtering system calls.</li> </ul>"},{"location":"012-gvisor/#overview","title":"Overview","text":"<ul> <li><code>gVisor</code> is an application <code>kernel</code>, written in Go, that implements a substantial portion of the Linux system call interface. </li> <li>It provides a strong isolation boundary between the application and the host kernel, making it harder for attackers to compromise the host system even if they gain control of a container.</li> </ul>"},{"location":"012-gvisor/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker installed</li> <li>gVisor runtime installed (<code>runsc</code>)</li> <li>Basic understanding of Docker and system calls</li> </ul>"},{"location":"012-gvisor/#installation","title":"Installation","text":"<ul> <li>To install gVisor:</li> </ul> <pre><code># Install gVisor\ncurl -fsSL https://gvisor.dev/archive.key | sudo gpg --dearmor -o /usr/share/keyrings/gvisor-archive-keyring.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/gvisor-archive-keyring.gpg] https://storage.googleapis.com/gvisor/releases release main\" | sudo tee /etc/apt/sources.list.d/gvisor.list &gt; /dev/null\nsudo apt-get update &amp;&amp; sudo apt-get install -y runsc\n</code></pre>"},{"location":"012-gvisor/#examples","title":"Examples","text":""},{"location":"012-gvisor/#example-1-blocking-user-creation","title":"Example 1: Blocking User Creation","text":"<ul> <li> <p>This example demonstrates how to use gVisor with a <code>seccomp</code> profile to block user creation syscalls.</p> <p>Files:</p> <ul> <li><code>demo.sh</code>: Script to run the demo</li> <li><code>block-user-creation.json</code>: Seccomp profile that blocks user-related syscalls</li> </ul> <p>Run the demo:</p> <pre><code>./demo.sh\n</code></pre> </li> <li> <p>This will attempt to create a user inside a container running with gVisor and the seccomp profile. </p> </li> <li>The operation should fail, demonstrating the security isolation.</li> </ul>"},{"location":"012-gvisor/#example-2-blocking-mount-operations","title":"Example 2: Blocking Mount Operations","text":"<ul> <li>This example shows how to restrict mount operations using gVisor and seccomp.</li> </ul> <p>Files:</p> <ul> <li><code>demo-mount.sh</code>: Script to run the mount demo</li> <li><code>block-mount.json</code>: Seccomp profile that blocks mount-related syscalls</li> <li><code>Dockerfile</code>: Alpine image that attempts to mount tmpfs</li> </ul> <p>Run the demo:</p> <pre><code>./demo-mount.sh\n</code></pre> <ul> <li>This will build an Alpine image and attempt to mount a <code>tmpfs</code> inside the container. </li> <li>The mount operation should be blocked.</li> </ul>"},{"location":"012-gvisor/#key-concepts","title":"Key Concepts","text":"<ul> <li>Seccomp Profiles: JSON files that define which syscalls are allowed or blocked</li> <li>gVisor Runtime: <code>runsc</code> provides the sandboxed execution environment</li> <li>System Call Filtering: Prevents potentially dangerous operations</li> </ul>"},{"location":"012-gvisor/#additional-resources","title":"Additional Resources","text":"<ul> <li>gVisor Documentation</li> <li>Seccomp Profiles</li> <li>Docker Runtime Options</li> </ul>"},{"location":"013-Cgroup/","title":"013-Cgroup","text":""},{"location":"013-Cgroup/#lab-013-resource-isolation-with-linux-cgroups","title":"Lab 013 - Resource Isolation with Linux Cgroups","text":"<ul> <li>This lab covers resource isolation using Linux Cgroups in Docker containers.</li> <li>You will learn how to limit CPU, memory, and other resources for containers to prevent resource contention and ensure fair sharing.</li> <li>By the end of this lab, you will understand how to use Docker commands to enforce resource constraints.</li> </ul>"},{"location":"013-Cgroup/#cpu-limits","title":"CPU Limits","text":"<ul> <li>Use <code>--cpus</code> to limit CPU usage as a fraction of available cores.</li> </ul> <pre><code># Limit container to 0.5 CPU cores\ndocker run -d --cpus=0.5 --name cpu-limited nginx\n\n# Check resource usage\ndocker stats cpu-limited\n\n# Clean up\ndocker stop cpu-limited\ndocker rm cpu-limited\n</code></pre>"},{"location":"013-Cgroup/#memory-limits","title":"Memory Limits","text":"<ul> <li>Use <code>--memory</code> to set a hard memory limit.</li> </ul> <pre><code># Limit container to 128MB RAM\ndocker run -d --memory=128m --name mem-limited nginx\n\n# Check resource usage\ndocker stats mem-limited\n\n# Test memory limit by running a memory-intensive process\ndocker run --memory=50m stress --vm 1 --vm-bytes 100m\n\n# Clean up\ndocker stop mem-limited\ndocker rm mem-limited\n</code></pre>"},{"location":"013-Cgroup/#cpu-sets","title":"CPU Sets","text":"<ul> <li>Use <code>--cpuset-cpus</code> to pin container to specific CPU cores.</li> </ul> <pre><code># Pin container to CPU cores 0 and 1\ndocker run -d --cpuset-cpus=0,1 --name cpu-pinned nginx\n\n# Check which CPUs the container is using\ndocker exec cpu-pinned cat /proc/self/status | grep Cpus_allowed\n\n# Clean up\ndocker stop cpu-pinned\ndocker rm cpu-pinned\n</code></pre>"},{"location":"013-Cgroup/#combined-resource-limits","title":"Combined Resource Limits","text":"<ul> <li>Combine multiple resource constraints for comprehensive control.</li> </ul> <pre><code># Limit both CPU and memory\ndocker run -d --cpus=1.0 --memory=256m --name combined-limits nginx\n\n# Check all resource limits\ndocker inspect combined-limits | grep -A 10 \"HostConfig\"\n\n# Clean up\ndocker stop combined-limits\ndocker rm combined-limits\n</code></pre>"},{"location":"013-Cgroup/#monitoring-resource-usage","title":"Monitoring Resource Usage","text":"<ul> <li>Use <code>docker stats</code> to monitor container resource usage in real-time.</li> </ul> <pre><code># Start multiple containers with different limits\ndocker run -d --cpus=0.5 --memory=128m --name container1 nginx\ndocker run -d --cpus=1.0 --memory=256m --name container2 nginx\n\n# Monitor resource usage\ndocker stats\n\n# Clean up\ndocker stop container1 container2\ndocker rm container1 container2\n</code></pre>"},{"location":"014-DockerDaemon/","title":"014-DockerDaemon","text":""},{"location":"014-DockerDaemon/#lab-014-docker-daemon","title":"Lab 014 - Docker Daemon","text":"<ul> <li>This lab covers the Docker daemon (dockerd), its configuration, and advanced features.</li> <li>You\u2019ll learn how to customize the Docker daemon behavior, configure private registries, enable rootless mode, and implement various security and performance optimizations.</li> <li>Topics include daemon configuration file, logging options, storage drivers, network settings, and experimental features.</li> <li>By the end of this lab, you\u2019ll understand how to configure and manage the Docker daemon for production environments.</li> </ul>"},{"location":"014-DockerDaemon/#table-of-contents","title":"Table of Contents","text":"<ul> <li>\ud83d\udc33 Understanding the Docker Daemon</li> <li>\u2699\ufe0f Docker Daemon Configuration</li> <li>Configuration File Location</li> <li>Basic Configuration Structure</li> <li>\ud83d\udd27 Common Daemon Configurations</li> <li>Logging Configuration</li> <li>Storage Configuration</li> <li>Network Configuration</li> <li>Security Configuration</li> <li>\ud83c\udfe2 Private Registry Configuration</li> <li>\ud83d\udc64 Rootless Docker</li> <li>\ud83d\ude80 Experimental Features</li> <li>\ud83d\udcca Monitoring and Debugging</li> <li>\ud83d\udd12 Security Best Practices</li> </ul>"},{"location":"014-DockerDaemon/#understanding-the-docker-daemon","title":"\ud83d\udc33 Understanding the Docker Daemon","text":"<p>The Docker daemon (<code>dockerd</code>) is the persistent process that manages Docker containers, images, networks, and volumes. It listens for Docker API requests and manages Docker objects.</p>"},{"location":"014-DockerDaemon/#key-responsibilities","title":"Key Responsibilities","text":"<ul> <li>Container Management: Creating, starting, stopping, and monitoring containers</li> <li>Image Management: Pulling, pushing, and building images</li> <li>Network Management: Creating and managing container networks</li> <li>Volume Management: Handling persistent data storage</li> <li>API Server: Providing REST API for Docker client communication</li> </ul>"},{"location":"014-DockerDaemon/#daemon-lifecycle","title":"Daemon Lifecycle","text":"<pre><code># Check if daemon is running\ndocker version\n\n# View daemon info\ndocker info\n\n# Restart daemon (Linux)\nsudo systemctl restart docker\n\n# View daemon logs (Linux)\nsudo journalctl -u docker -f\n</code></pre>"},{"location":"014-DockerDaemon/#docker-daemon-configuration","title":"\u2699\ufe0f Docker Daemon Configuration","text":""},{"location":"014-DockerDaemon/#configuration-file-location","title":"Configuration File Location","text":"<p>The Docker daemon can be configured using a JSON configuration file:</p> <p>Linux/macOS: <code>/etc/docker/daemon.json</code> Windows: <code>C:\\ProgramData\\docker\\config\\daemon.json</code></p>"},{"location":"014-DockerDaemon/#basic-configuration-structure","title":"Basic Configuration Structure","text":"<pre><code>{\n  \"debug\": false,\n  \"tls\": true,\n  \"tlscert\": \"/var/docker/server.pem\",\n  \"tlskey\": \"/var/docker/serverkey.pem\",\n  \"hosts\": [\"tcp://0.0.0.0:2376\"],\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"storage-driver\": \"overlay2\",\n  \"insecure-registries\": [\"myregistry.com:5000\"],\n  \"registry-mirrors\": [\"https://mirror.gcr.io\"]\n}\n</code></pre>"},{"location":"014-DockerDaemon/#common-daemon-configurations","title":"\ud83d\udd27 Common Daemon Configurations","text":""},{"location":"014-DockerDaemon/#logging-configuration","title":"Logging Configuration","text":"<p>Configure how Docker logs container output and daemon events:</p> <pre><code>{\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\",\n    \"labels\": \"production_status\",\n    \"env\": \"os,customer\"\n  }\n}\n</code></pre> <p>Available log drivers:</p> <ul> <li><code>json-file</code> (default): JSON formatted logs</li> <li><code>syslog</code>: System logging</li> <li><code>journald</code>: systemd journal</li> <li><code>fluentd</code>: Fluentd logging</li> <li><code>awslogs</code>: Amazon CloudWatch</li> <li><code>splunk</code>: Splunk logging</li> </ul>"},{"location":"014-DockerDaemon/#storage-configuration","title":"Storage Configuration","text":"<p>Configure storage driver and options:</p> <pre><code>{\n  \"storage-driver\": \"overlay2\",\n  \"storage-opts\": [\n    \"overlay2.override_kernel_check=true\"\n  ],\n  \"data-root\": \"/var/lib/docker\"\n}\n</code></pre> <p>Common storage drivers:</p> <ul> <li><code>overlay2</code> (recommended for modern Linux)</li> <li><code>btrfs</code> (for Btrfs filesystems)</li> <li><code>zfs</code> (for ZFS filesystems)</li> <li><code>devicemapper</code> (legacy, device mapper)</li> </ul>"},{"location":"014-DockerDaemon/#network-configuration","title":"Network Configuration","text":"<p>Configure networking options:</p> <pre><code>{\n  \"bridge\": \"docker0\",\n  \"fixed-cidr\": \"192.168.65.0/24\",\n  \"default-gateway\": \"192.168.65.1\",\n  \"dns\": [\"8.8.8.8\", \"8.8.4.4\"],\n  \"dns-opts\": [\"timeout:2\"],\n  \"dns-search\": [\"example.com\"],\n  \"iptables\": true,\n  \"ip-forward\": true\n}\n</code></pre>"},{"location":"014-DockerDaemon/#security-configuration","title":"Security Configuration","text":"<pre><code>{\n  \"userns-remap\": \"default\",\n  \"no-new-privileges\": true,\n  \"seccomp-profile\": \"/etc/docker/seccomp.json\",\n  \"selinux-enabled\": true,\n  \"live-restore\": true,\n  \"icc\": false,\n  \"userland-proxy\": false\n}\n</code></pre>"},{"location":"014-DockerDaemon/#private-registry-configuration","title":"\ud83c\udfe2 Private Registry Configuration","text":""},{"location":"014-DockerDaemon/#adding-insecure-registries","title":"Adding Insecure Registries","text":"<p>For registries without TLS certificates:</p> <pre><code>{\n  \"insecure-registries\": [\n    \"myregistry.com:5000\",\n    \"registry.internal.company.com\"\n  ]\n}\n</code></pre>"},{"location":"014-DockerDaemon/#registry-mirrors","title":"Registry Mirrors","text":"<p>Use registry mirrors to cache images:</p> <pre><code>{\n  \"registry-mirrors\": [\n    \"https://mirror.gcr.io\",\n    \"https://dockerhub.mirror.com\"\n  ]\n}\n</code></pre>"},{"location":"014-DockerDaemon/#authentication","title":"Authentication","text":"<p>Configure authentication for private registries:</p> <pre><code>{\n  \"auths\": {\n    \"https://index.docker.io/v1/\": {\n      \"auth\": \"dXNlcjpwYXNzd29yZA==\"\n    },\n    \"myregistry.com:5000\": {\n      \"auth\": \"dXNlcjpwYXNzd29yZA==\"\n    }\n  }\n}\n</code></pre>"},{"location":"014-DockerDaemon/#example-working-with-private-registry","title":"Example: Working with Private Registry","text":"<pre><code># Tag image for private registry\ndocker tag myapp:latest myregistry.com:5000/myapp:v1.0\n\n# Push to private registry\ndocker push myregistry.com:5000/myapp:v1.0\n\n# Pull from private registry\ndocker pull myregistry.com:5000/myapp:v1.0\n\n# Login to registry (if required)\ndocker login myregistry.com:5000\n</code></pre>"},{"location":"014-DockerDaemon/#rootless-docker","title":"\ud83d\udc64 Rootless Docker","text":"<p>Rootless Docker allows running the Docker daemon without root privileges, improving security by reducing the attack surface.</p>"},{"location":"014-DockerDaemon/#installation","title":"Installation","text":"<pre><code># Install rootless Docker\ncurl -fsSL https://get.docker.com/rootless | sh\n\n# Start rootless Docker\nsystemctl --user start docker\n\n# Enable on boot\nsystemctl --user enable docker\n\n# Add to PATH\nexport PATH=/home/$USER/bin:$PATH\nexport DOCKER_HOST=unix:///run/user/$(id -u)/docker.sock\n</code></pre>"},{"location":"014-DockerDaemon/#configuration","title":"Configuration","text":"<p>Rootless Docker uses different paths and configurations:</p> <pre><code># Rootless Docker socket\nexport DOCKER_HOST=unix:///run/user/$(id -u)/docker.sock\n\n# Rootless Docker data directory\nexport XDG_DATA_HOME=/home/$USER/.local/share\n\n# Rootless Docker config\nexport DOCKER_CONFIG=/home/$USER/.config/docker\n</code></pre>"},{"location":"014-DockerDaemon/#limitations","title":"Limitations","text":"<ul> <li>Some features may not work (e.g., AppArmor, checkpoint/restore)</li> <li>Port binding below 1024 requires additional setup</li> <li>Some storage drivers may have limitations</li> <li>Network features may be restricted</li> </ul>"},{"location":"014-DockerDaemon/#benefits","title":"Benefits","text":"<ul> <li>Security: No root access required</li> <li>Isolation: User-specific Docker environment</li> <li>Compliance: Meets security requirements for multi-tenant environments</li> </ul>"},{"location":"014-DockerDaemon/#experimental-features","title":"\ud83d\ude80 Experimental Features","text":"<p>Enable experimental features for cutting-edge functionality:</p> <pre><code>{\n  \"experimental\": true\n}\n</code></pre> <p>Available experimental features:</p> <ul> <li>BuildKit: Advanced build engine with improved performance</li> <li>Squash: Squash layers to reduce image size</li> <li>Checkpoint/Restore: Save and restore container state</li> <li>Rootless mode: Run daemon without root (now stable)</li> </ul>"},{"location":"014-DockerDaemon/#buildkit-configuration","title":"BuildKit Configuration","text":"<pre><code>{\n  \"experimental\": true,\n  \"features\": {\n    \"buildkit\": true\n  }\n}\n</code></pre> <p>Using BuildKit:</p> <pre><code># Enable BuildKit\nexport DOCKER_BUILDKIT=1\n\n# Build with BuildKit\ndocker build -t myapp .\n\n# Use advanced BuildKit features\ndocker build --target production -t myapp .\n</code></pre>"},{"location":"014-DockerDaemon/#monitoring-and-debugging","title":"\ud83d\udcca Monitoring and Debugging","text":""},{"location":"014-DockerDaemon/#daemon-monitoring","title":"Daemon Monitoring","text":"<pre><code># View daemon info\ndocker info\n\n# System-wide information\ndocker system info\n\n# Disk usage\ndocker system df\n\n# Events stream\ndocker events\n\n# Daemon logs\nsudo journalctl -u docker -f\n</code></pre>"},{"location":"014-DockerDaemon/#debugging-configuration","title":"Debugging Configuration","text":"<pre><code>{\n  \"debug\": true,\n  \"log-level\": \"debug\",\n  \"metrics-addr\": \"127.0.0.1:9323\"\n}\n</code></pre>"},{"location":"014-DockerDaemon/#health-checks","title":"Health Checks","text":"<p>Monitor daemon health:</p> <pre><code># Check daemon responsiveness\ndocker version\n\n# System events\ndocker system events --since 1h\n\n# Container events\ndocker events --filter type=container\n</code></pre>"},{"location":"014-DockerDaemon/#security-best-practices","title":"\ud83d\udd12 Security Best Practices","text":"<p>Always use TLS for daemon communication:</p> <pre><code>{\n  \"tls\": true,\n  \"tlscert\": \"/etc/docker/server.pem\",\n  \"tlskey\": \"/etc/docker/serverkey.pem\",\n  \"tlsverify\": true\n}\n</code></pre> <p>Enable user namespace remapping:</p> <pre><code>{\n  \"userns-remap\": \"default\"\n}\n</code></pre> <p>Use custom seccomp profiles:</p> <pre><code>{\n  \"seccomp-profile\": \"/etc/docker/seccomp.json\"\n}\n</code></pre> <p>Enable mandatory access control:</p> <pre><code>{\n  \"selinux-enabled\": true\n}\n</code></pre> <p>Enable detailed audit logging:</p> <pre><code>{\n  \"log-driver\": \"syslog\",\n  \"log-opts\": {\n    \"syslog-facility\": \"daemon\"\n  }\n}\n</code></pre> <p>Avoid insecure configurations:</p> <pre><code>{\n  \"icc\": false,\n  \"no-new-privileges\": true,\n  \"userland-proxy\": false\n}\n</code></pre>"},{"location":"014-DockerDaemon/#tls-configuration","title":"\ud83d\udd10 TLS Configuration","text":""},{"location":"014-DockerDaemon/#user-namespace","title":"\ud83d\udc65 User Namespace","text":""},{"location":"014-DockerDaemon/#seccomp-profiles","title":"\ud83d\udee1\ufe0f Seccomp Profiles","text":""},{"location":"014-DockerDaemon/#selinuxapparmor","title":"\ud83d\udd12 SELinux/AppArmor","text":""},{"location":"014-DockerDaemon/#audit-logging","title":"\ud83d\udcca Audit Logging","text":""},{"location":"014-DockerDaemon/#disable-insecure-features","title":"\ud83d\udeab Disable Insecure Features","text":""},{"location":"014-DockerDaemon/#lab-exercises","title":"\ud83d\udccb Lab Exercises","text":"<ol> <li> <p>Configure Basic Daemon Settings</p> <ul> <li>Create <code>/etc/docker/daemon.json</code> with basic configuration</li> <li>Restart Docker daemon and verify settings</li> </ul> </li> <li> <p>Set Up Private Registry</p> <ul> <li>Configure insecure registry in daemon.json</li> <li>Push and pull images from private registry</li> </ul> </li> <li> <p>Enable Rootless Docker</p> <ul> <li>Install and configure rootless Docker</li> <li>Test container operations without root</li> </ul> </li> <li> <p>Configure Logging</p> <ul> <li>Set up JSON logging with rotation</li> <li>View and analyze container logs</li> </ul> </li> <li> <p>Security Hardening</p> <ul> <li>Enable user namespaces</li> <li>Configure seccomp profiles</li> <li>Set up TLS authentication</li> </ul> </li> </ol>"},{"location":"014-DockerDaemon/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li>Docker Daemon Configuration</li> <li>Private Registry Setup</li> <li>Rootless Docker</li> <li>Docker Security Best Practices</li> <li>BuildKit Documentation</li> </ul>"},{"location":"015-Networking/","title":"015-Networking","text":""},{"location":"015-Networking/#lab-015-docker-networking","title":"Lab 015 - Docker Networking","text":"<ul> <li>This lab covers Docker networking fundamentals, including network drivers, custom networks, and advanced networking features.</li> <li>You\u2019ll learn how to create and manage container networks, configure network connectivity, and implement service discovery.</li> <li>Topics include bridge networks, overlay networks, host networking, and network troubleshooting.</li> <li>By the end of this lab, you\u2019ll understand how to design and manage container networking for various deployment scenarios.</li> </ul>"},{"location":"015-Networking/#table-of-contents","title":"Table of Contents","text":"<ul> <li>\ud83c\udf10 Understanding Docker Networking</li> <li>\ud83d\udd17 Network Drivers</li> <li>Bridge Network</li> <li>Host Network</li> <li>None Network</li> <li>Overlay Network</li> <li>Macvlan Network</li> <li>\u2699\ufe0f Custom Networks</li> <li>Creating Custom Networks</li> <li>Network Configuration</li> <li>\ud83d\udd0c Container Networking</li> <li>Connecting Containers</li> <li>Port Mapping</li> <li>Service Discovery</li> <li>\ud83d\ude80 Advanced Networking</li> <li>Network Plugins</li> <li>DNS Configuration</li> <li>Network Security</li> <li>\ud83d\udd27 Networking Commands</li> <li>\ud83d\udcca Monitoring and Troubleshooting</li> <li>\ud83d\udd12 Networking Best Practices</li> </ul>"},{"location":"015-Networking/#understanding-docker-networking","title":"\ud83c\udf10 Understanding Docker Networking","text":"<p>Docker networking enables containers to communicate with each other and external networks. Docker provides several network drivers to suit different use cases.</p>"},{"location":"015-Networking/#key-concepts","title":"Key Concepts","text":"<ul> <li>Network Drivers: Define how containers connect to networks</li> <li>Bridge Networks: Default network for single-host communication</li> <li>Overlay Networks: Multi-host networking for Swarm clusters</li> <li>Host Networks: Direct access to host network stack</li> <li>None Networks: Isolated containers with no networking</li> </ul>"},{"location":"015-Networking/#default-networks","title":"Default Networks","text":"<p>Docker creates three default networks:</p> <pre><code># List all networks\ndocker network ls\n\n# Inspect default bridge network\ndocker network inspect bridge\n</code></pre>"},{"location":"015-Networking/#network-drivers","title":"\ud83d\udd17 Network Drivers","text":""},{"location":"015-Networking/#bridge-network","title":"Bridge Network","text":"<p>The default network driver for containers. Creates an internal network on the host.</p> <p>Characteristics:</p> <ul> <li>Containers can communicate with each other</li> <li>Containers get IP addresses from Docker\u2019s subnet</li> <li>Port mapping required for external access</li> </ul> <p>Example:</p> <pre><code># Run container on bridge network\ndocker run -d --name web nginx\n\n# Inspect container network\ndocker inspect web | grep -A 10 NetworkSettings\n</code></pre>"},{"location":"015-Networking/#host-network","title":"Host Network","text":"<p>Containers share the host\u2019s network stack directly.</p> <p>Characteristics:</p> <ul> <li>No network isolation</li> <li>Best performance</li> <li>No port conflicts</li> <li>Limited to single host</li> </ul> <p>Example:</p> <pre><code># Run container with host networking\ndocker run -d --network host --name web nginx\n</code></pre>"},{"location":"015-Networking/#none-network","title":"None Network","text":"<p>Completely isolated containers with no network access.</p> <p>Characteristics:</p> <ul> <li>No network interfaces</li> <li>Maximum isolation</li> <li>Manual network setup required</li> </ul> <p>Example:</p> <pre><code># Run container with no networking\ndocker run -d --network none --name isolated alpine sleep 3600\n</code></pre>"},{"location":"015-Networking/#overlay-network","title":"Overlay Network","text":"<p>Multi-host networking for Docker Swarm clusters.</p> <p>Characteristics:</p> <ul> <li>Spans multiple hosts</li> <li>Built-in service discovery</li> <li>Load balancing</li> <li>Requires Swarm mode</li> </ul> <p>Example:</p> <pre><code># Create overlay network (in Swarm)\ndocker network create -d overlay my-overlay\n\n# Run service on overlay network\ndocker service create --network my-overlay --name web nginx\n</code></pre>"},{"location":"015-Networking/#macvlan-network","title":"Macvlan Network","text":"<p>Assigns MAC addresses to containers, making them appear as physical devices.</p> <p>Characteristics:</p> <ul> <li>Layer 2 networking</li> <li>Direct layer 2 access</li> <li>No port mapping needed</li> <li>Requires promiscuous mode on host interface</li> </ul> <p>Example:</p> <pre><code># Create macvlan network\ndocker network create -d macvlan \\\n  --subnet=192.168.1.0/24 \\\n  --gateway=192.168.1.1 \\\n  -o parent=eth0 \\\n  my-macvlan\n\n# Run container on macvlan\ndocker run -d --network my-macvlan --name web nginx\n</code></pre>"},{"location":"015-Networking/#custom-networks","title":"\u2699\ufe0f Custom Networks","text":""},{"location":"015-Networking/#creating-custom-networks","title":"Creating Custom Networks","text":"<p>Create user-defined networks for better control.</p> <pre><code># Create bridge network\ndocker network create my-bridge\n\n# Create network with custom subnet\ndocker network create --subnet 172.20.0.0/16 my-custom-net\n\n# Create network with options\ndocker network create \\\n  --driver bridge \\\n  --subnet 172.25.0.0/16 \\\n  --gateway 172.25.0.1 \\\n  --opt \"com.docker.network.bridge.name\"=\"my-bridge\" \\\n  my-network\n</code></pre>"},{"location":"015-Networking/#network-configuration","title":"Network Configuration","text":"<p>Configure network settings for containers.</p> <pre><code># Connect container to network\ndocker network connect my-network web\n\n# Disconnect from network\ndocker network disconnect bridge web\n\n# Run container with specific IP\ndocker run -d --network my-network --ip 172.20.0.10 --name web nginx\n\n# Inspect network\ndocker network inspect my-network\n</code></pre>"},{"location":"015-Networking/#container-networking","title":"\ud83d\udd0c Container Networking","text":""},{"location":"015-Networking/#connecting-containers","title":"Connecting Containers","text":"<p>Enable communication between containers.</p> <pre><code># Create network\ndocker network create app-network\n\n# Run database\ndocker run -d --network app-network --name db postgres\n\n# Run app connected to same network\ndocker run -d --network app-network --name app myapp\n\n# Containers can communicate by name\ndocker exec app ping db\n</code></pre>"},{"location":"015-Networking/#port-mapping","title":"Port Mapping","text":"<p>Expose container ports to host.</p> <pre><code># Map single port\ndocker run -d -p 8080:80 --name web nginx\n\n# Map multiple ports\ndocker run -d -p 8080:80 -p 8443:443 --name web nginx\n\n# Map to specific host interface\ndocker run -d -p 192.168.1.100:8080:80 --name web nginx\n\n# Dynamic port mapping\ndocker run -d -P --name web nginx\n</code></pre>"},{"location":"015-Networking/#service-discovery","title":"Service Discovery","text":"<p>Automatic service discovery in user-defined networks.</p> <pre><code># Create network\ndocker network create --driver bridge app-net\n\n# Run services\ndocker run -d --network app-net --name redis redis\ndocker run -d --network app-net --name web -e REDIS_HOST=redis myapp\n\n# Services resolve by container name\ndocker exec web nslookup redis\n</code></pre>"},{"location":"015-Networking/#advanced-networking","title":"\ud83d\ude80 Advanced Networking","text":""},{"location":"015-Networking/#network-plugins","title":"Network Plugins","text":"<p>Extend Docker networking with plugins.</p> <pre><code># Install network plugin (example: weave)\ndocker plugin install weaveworks/net-plugin:latest_release\n\n# Create network with plugin\ndocker network create -d weave my-weave-net\n</code></pre>"},{"location":"015-Networking/#dns-configuration","title":"DNS Configuration","text":"<p>Configure DNS for containers.</p> <pre><code># Use custom DNS\ndocker run -d --dns 8.8.8.8 --name web nginx\n\n# Use custom DNS search domains\ndocker run -d --dns-search example.com --name web nginx\n\n# Inspect DNS configuration\ndocker exec web cat /etc/resolv.conf\n</code></pre>"},{"location":"015-Networking/#network-security","title":"Network Security","text":"<p>Secure container communications.</p> <pre><code># Create encrypted overlay network\ndocker network create -d overlay \\\n  --opt encrypted \\\n  my-secure-net\n\n# Use network with iptables rules\ndocker network create --driver bridge \\\n  --opt \"com.docker.network.bridge.enable_icc\"=\"false\" \\\n  isolated-net\n</code></pre>"},{"location":"015-Networking/#networking-commands","title":"\ud83d\udd27 Networking Commands","text":""},{"location":"015-Networking/#network-management","title":"Network Management","text":"<pre><code># List networks\ndocker network ls\n\n# Create network\ndocker network create my-network\n\n# Remove network\ndocker network rm my-network\n\n# Prune unused networks\ndocker network prune\n</code></pre>"},{"location":"015-Networking/#container-network-commands","title":"Container Network Commands","text":"<pre><code># Connect container to network\ndocker network connect my-network container_name\n\n# Disconnect container from network\ndocker network disconnect bridge container_name\n\n# Inspect container networks\ndocker inspect container_name | jq .NetworkSettings.Networks\n</code></pre>"},{"location":"015-Networking/#troubleshooting-commands","title":"Troubleshooting Commands","text":"<pre><code># Check network connectivity\ndocker exec web ping google.com\n\n# View network interfaces\ndocker exec web ip addr\n\n# Check routing table\ndocker exec web ip route\n\n# View iptables rules\nsudo iptables -L -n\n</code></pre>"},{"location":"015-Networking/#monitoring-and-troubleshooting","title":"\ud83d\udcca Monitoring and Troubleshooting","text":""},{"location":"015-Networking/#network-monitoring","title":"Network Monitoring","text":"<pre><code># View network usage\ndocker network ls -q | xargs docker network inspect | jq '.[].Containers | length'\n\n# Monitor network traffic (requires tools)\ndocker run -d --net container:web nicolaka/netshoot tcpdump -i eth0\n\n# Check container connectivity\ndocker exec web curl -I http://other-container\n</code></pre>"},{"location":"015-Networking/#common-issues","title":"Common Issues","text":"<ul> <li>Container can\u2019t reach internet: Check DNS and gateway configuration</li> <li>Containers can\u2019t communicate: Verify network connectivity and firewall rules</li> <li>Port conflicts: Check host port usage</li> <li>Network isolation: Ensure containers are on the same network</li> </ul>"},{"location":"015-Networking/#debugging-steps","title":"Debugging Steps","text":"<pre><code># 1. Check container network settings\ndocker inspect container_name | jq .NetworkSettings\n\n# 2. Verify network connectivity\ndocker exec container_name ping 8.8.8.8\n\n# 3. Check DNS resolution\ndocker exec container_name nslookup google.com\n\n# 4. Inspect network details\ndocker network inspect network_name\n\n# 5. View Docker daemon logs\nsudo journalctl -u docker -f\n</code></pre>"},{"location":"015-Networking/#networking-best-practices","title":"\ud83d\udd12 Networking Best Practices","text":"<p>Prefer user-defined networks over default bridge for better isolation and service discovery.</p> <pre><code>docker network create app-network\ndocker run -d --network app-network --name app myapp\n</code></pre> <p>Separate applications into different networks for security.</p> <pre><code>docker network create frontend\ndocker network create backend\ndocker network create database\n</code></pre> <p>Only expose necessary ports and use specific IP bindings.</p> <pre><code>docker run -d -p 127.0.0.1:8080:80 --name web nginx\n</code></pre> <p>Enable encryption for sensitive communications.</p> <pre><code>docker network create -d overlay --opt encrypted secure-net\n</code></pre> <p>Regularly monitor and audit network communications.</p> <pre><code>docker network ls\ndocker network inspect &lt;network&gt; | jq .Containers\n</code></pre> <p>Remove unused networks to prevent clutter.</p> <pre><code>docker network prune\n</code></pre>"},{"location":"015-Networking/#use-user-defined-networks","title":"\ud83c\udf09 Use User-Defined Networks","text":""},{"location":"015-Networking/#implement-network-segmentation","title":"\ud83d\udd12 Implement Network Segmentation","text":""},{"location":"015-Networking/#minimize-port-exposure","title":"\ud83d\udeaa Minimize Port Exposure","text":""},{"location":"015-Networking/#use-encrypted-networks","title":"\ud83d\udd10 Use Encrypted Networks","text":""},{"location":"015-Networking/#monitor-network-traffic","title":"\ud83d\udcca Monitor Network Traffic","text":""},{"location":"015-Networking/#clean-up-unused-networks","title":"\ud83e\uddf9 Clean Up Unused Networks","text":""},{"location":"015-Networking/#lab-exercises","title":"\ud83d\udccb Lab Exercises","text":"<ol> <li> <p>Explore Default Networks</p> <ul> <li>List all Docker networks</li> <li>Inspect the bridge network configuration</li> <li>Run containers on default networks</li> </ul> </li> <li> <p>Create Custom Networks</p> <ul> <li>Create a user-defined bridge network</li> <li>Run containers on the custom network</li> <li>Test service discovery between containers</li> </ul> </li> <li> <p>Port Mapping and Exposure</p> <ul> <li>Run a web server with port mapping</li> <li>Access the application from host</li> <li>Test different port mapping options</li> </ul> </li> <li> <p>Network Isolation</p> <ul> <li>Create multiple networks</li> <li>Connect containers to specific networks</li> <li>Verify isolation between networks</li> </ul> </li> <li> <p>Advanced Networking</p> <ul> <li>Set up overlay networking (if Swarm available)</li> <li>Configure DNS settings</li> <li>Implement network security measures</li> </ul> </li> </ol>"},{"location":"015-Networking/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li>Docker Networking Overview</li> <li>Network Drivers</li> <li>Docker Swarm Networking</li> <li>Network Security</li> <li>Networking Best Practices</li> </ul>"},{"location":"016-Advanced-Build/","title":"016-Advanced-Build","text":""},{"location":"016-Advanced-Build/#lab-016-advanced-build","title":"Lab 016 - Advanced Build","text":"<ul> <li>This lab covers advanced Docker build techniques using BuildKit and BuildX.</li> <li>You will learn how to leverage BuildKit for faster and more efficient builds, and use BuildX to build multi-platform images locally.</li> <li>By the end of this lab, you will understand how to build Docker images for multiple architectures and platforms using the Docker CLI.</li> </ul>"},{"location":"016-Advanced-Build/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Desktop or Docker Engine with BuildX support</li> <li>Basic understanding of Dockerfiles and Docker CLI</li> </ul>"},{"location":"016-Advanced-Build/#buildkit","title":"BuildKit","text":"<p>BuildKit is an improved backend for building Docker images. It provides:</p> <ul> <li>Faster builds through parallel processing</li> <li>Better caching mechanisms</li> <li>Support for advanced Dockerfile features</li> <li>Improved security with rootless builds</li> </ul>"},{"location":"016-Advanced-Build/#enabling-buildkit","title":"Enabling BuildKit","text":"<p>BuildKit is enabled by default in Docker Desktop. For Docker Engine, you can enable it by setting the environment variable:</p> <pre><code>export DOCKER_BUILDKIT=1\n</code></pre> <p>Or add it to your shell profile:</p> <pre><code>echo 'export DOCKER_BUILDKIT=1' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"016-Advanced-Build/#buildkit-features","title":"BuildKit Features","text":"<ul> <li>Parallel builds: Build stages can run in parallel</li> <li>Better caching: More granular cache invalidation</li> <li>Secrets management: Secure handling of sensitive data during builds</li> <li>Multi-stage builds: Improved support for multi-stage Dockerfiles</li> </ul> <p>Example Dockerfile using BuildKit features:</p> <pre><code># syntax=docker/dockerfile:1\n\nFROM alpine:latest AS base\nRUN apk add --no-cache git\n\nFROM base AS build\nWORKDIR /app\nCOPY . .\nRUN echo \"Building application...\"\n\nFROM alpine:latest\nCOPY --from=build /app /app\nCMD [\"echo\", \"Application built with BuildKit\"]\n</code></pre>"},{"location":"016-Advanced-Build/#buildx","title":"BuildX","text":"<p>BuildX is a Docker CLI plugin that extends the build capabilities with BuildKit. It provides:</p> <ul> <li>Multi-platform builds</li> <li>Advanced build options</li> <li>Custom build drivers</li> <li>Bake support for complex builds</li> </ul>"},{"location":"016-Advanced-Build/#installing-buildx","title":"Installing BuildX","text":"<p>BuildX comes pre-installed with Docker Desktop. For Docker Engine:</p> <pre><code># Download and install BuildX\nmkdir -p ~/.docker/cli-plugins\ncurl -L https://github.com/docker/buildx/releases/latest/download/buildx-linux-amd64 -o ~/.docker/cli-plugins/docker-buildx\nchmod +x ~/.docker/cli-plugins/docker-buildx\n</code></pre>"},{"location":"016-Advanced-Build/#building-multi-platform-images-locally","title":"Building Multi-Platform Images Locally","text":"<p>BuildX allows you to build images for multiple platforms simultaneously. To build for all platforms locally, you need to enable QEMU emulation:</p> <pre><code># Enable QEMU emulation for cross-platform builds\ndocker run --privileged --rm tonistiigi/binfmt --install all\n</code></pre> <p>Or using the Docker image for this purpose:</p> <pre><code># Use the docker/binfmt image to enable multi-platform support\ndocker run --privileged --rm docker/binfmt:a7996909642ee92942dcd6cff44b9b95f08dad64c\n</code></pre>"},{"location":"016-Advanced-Build/#using-tonistiigibinfmt-for-qemu-emulation","title":"Using tonistiigi/binfmt for QEMU Emulation","text":"<p>The tonistiigi/binfmt project provides a Docker image that installs QEMU and binfmt_misc support, enabling cross-platform architecture emulation. This is essential for building Docker images for different CPU architectures on your local machine.</p> <p>What it does:</p> <ul> <li>Installs QEMU user-mode emulation for various architectures</li> <li>Configures binfmt_misc to automatically use QEMU when running foreign binaries</li> <li>Enables building and testing multi-platform Docker images locally</li> </ul> <p>Installation and Setup:</p> <pre><code># Install QEMU and binfmt support for all architectures\ndocker run --privileged --rm tonistiigi/binfmt --install all\n\n# Install specific architectures only\ndocker run --privileged --rm tonistiigi/binfmt --install amd64,arm64,arm\n\n# Check installed formats\ndocker run --privileged --rm tonistiigi/binfmt\n\n# Uninstall (if needed)\ndocker run --privileged --rm tonistiigi/binfmt --uninstall all\n</code></pre> <p>Supported Architectures:</p> <ul> <li><code>amd64</code> (x86-64)</li> <li><code>arm64</code> (ARM 64-bit)</li> <li><code>arm</code> (ARM 32-bit)</li> <li><code>ppc64le</code> (PowerPC 64-bit little-endian)</li> <li><code>s390x</code> (IBM System z)</li> <li><code>riscv64</code> (RISC-V 64-bit)</li> <li>And more\u2026</li> </ul> <p>Persistent Setup: To make the setup persistent across Docker daemon restarts, you can create a systemd service or add it to your Docker startup script.</p> <p>Verification: After installation, verify that binfmt is working:</p> <pre><code># Check binfmt_misc entries\ncat /proc/sys/fs/binfmt_misc/qemu-aarch64\n\n# Test with a simple command\ndocker run --rm arm64v8/alpine uname -m  # Should show aarch64\n</code></pre> <p>Common Issues:</p> <ul> <li>Permission denied: Run with <code>--privileged</code> flag</li> <li>Already installed: The tool is idempotent, running it multiple times is safe</li> <li>Docker Desktop: May require restarting Docker Desktop after installation</li> </ul> <p>This tool is the foundation for local multi-platform Docker builds, allowing you to emulate different architectures without needing physical hardware.</p>"},{"location":"016-Advanced-Build/#building-on-macos","title":"Building on macOS","text":"<p>On macOS, Docker Desktop provides built-in support for multi-platform builds, but for full cross-platform emulation (especially when building ARM images on Intel Macs or vice versa), you need to set up QEMU using the Docker binfmt image.</p> <p>Prerequisites:</p> <ul> <li>Docker Desktop for Mac (latest version)</li> <li>At least 4GB of RAM allocated to Docker</li> </ul> <p>Setup QEMU on macOS:</p> <pre><code># Enable binfmt support for multi-architecture emulation\ndocker run --privileged --rm docker/binfmt:a7996909642ee92942dcd6cff44b9b95f08dad64c\n\n# Verify the setup\ndocker buildx inspect --bootstrap\n</code></pre> <p>Supported Platforms on macOS:</p> <ul> <li><code>linux/amd64</code> (Intel/AMD)</li> <li><code>linux/arm64</code> (Apple Silicon)</li> <li><code>linux/arm/v7</code> (32-bit ARM)</li> <li><code>linux/arm/v6</code> (Raspberry Pi)</li> </ul> <p>Example: Building for all platforms on macOS:</p> <pre><code># Create a builder with docker-container driver for better isolation\ndocker buildx create --use --name mac-multi-builder --driver docker-container\n\n# Build for all supported platforms\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64,linux/arm/v7,linux/arm/v6 \\\n  -t myapp:all-platforms \\\n  --push \\\n  .\n\n# For local testing (load only native platform)\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  -t myapp:native \\\n  --load \\\n  .\n</code></pre> <p>Troubleshooting macOS builds:</p> <ul> <li>If builds fail with QEMU errors, restart Docker Desktop</li> <li>Ensure Docker Desktop has enough RAM (8GB+ recommended for multi-platform builds)</li> <li>Use <code>--progress=plain</code> for detailed build logs</li> <li>Check available platforms: <code>docker buildx inspect --bootstrap | grep Platforms</code></li> </ul>"},{"location":"016-Advanced-Build/#basic-multi-platform-build","title":"Basic Multi-Platform Build","text":"<pre><code># Create a new builder instance\ndocker buildx create --use --name multi-platform-builder\n\n# Build for multiple platforms\ndocker buildx build --platform linux/amd64,linux/arm64,linux/arm/v7 -t myapp:multi .\n\n# Build and push to registry\ndocker buildx build --platform linux/amd64,linux/arm64,linux/arm/v7 -t myregistry.com/myapp:multi --push .\n</code></pre>"},{"location":"016-Advanced-Build/#advanced-buildx-commands","title":"Advanced BuildX Commands","text":"<ul> <li>List builders:</li> </ul> <pre><code>docker buildx ls\n</code></pre> <ul> <li>Inspect builder:</li> </ul> <pre><code>docker buildx inspect multi-platform-builder\n</code></pre> <ul> <li>Build with custom output:</li> </ul> <pre><code>docker buildx build --platform linux/amd64,linux/arm64 -t myapp:multi --output type=local,dest=./dist .\n</code></pre> <ul> <li>Build with bake (using docker-bake.hcl file):</li> </ul> <pre><code>docker buildx bake\n</code></pre>"},{"location":"016-Advanced-Build/#example-multi-platform-nodejs-application","title":"Example: Multi-Platform Node.js Application","text":"<p>Create a sample application:</p> <pre><code>mkdir multi-platform-example\ncd multi-platform-example\n\n# Create package.json\ncat &lt;&lt;EOF &gt; package.json\n{\n  \"name\": \"multi-platform-app\",\n  \"version\": \"1.0.0\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"start\": \"node index.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\"\n  }\n}\nEOF\n\n# Create index.js\ncat &lt;&lt;EOF &gt; index.js\nconst express = require('express');\nconst app = express();\nconst port = process.env.PORT || 3000;\n\napp.get('/', (req, res) =&gt; {\n  res.json({\n    message: 'Hello from multi-platform Docker app!',\n    platform: process.arch,\n    timestamp: new Date().toISOString()\n  });\n});\n\napp.listen(port, () =&gt; {\n  console.log(\\`App listening on port \\${port}\\`);\n});\nEOF\n\n# Create Dockerfile\ncat &lt;&lt;EOF &gt; Dockerfile\nFROM node:18-alpine\n\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\n\nCOPY . .\nEXPOSE 3000\nCMD [\"npm\", \"start\"]\nEOF\n</code></pre> <p>Build for multiple platforms:</p> <pre><code># Enable multi-platform support\ndocker run --privileged --rm docker/binfmt:a7996909642ee92942dcd6cff44b9b95f08dad64c\n\n# Create and use builder\ndocker buildx create --use --name multi-builder\n\n# Build for multiple platforms\ndocker buildx build --platform linux/amd64,linux/arm64,linux/arm/v7 -t multi-platform-node:latest --load .\n\n# Test the built image\ndocker run -p 3000:3000 multi-platform-node:latest\ncurl localhost:3000\n</code></pre>"},{"location":"016-Advanced-Build/#buildx-bake-for-complex-builds","title":"BuildX Bake for Complex Builds","text":"<p>Create a <code>docker-bake.hcl</code> file for complex multi-target builds:</p> <pre><code>group \"default\" {\n  targets = [\"app\", \"debug\"]\n}\n\ntarget \"app\" {\n  context = \".\"\n  dockerfile = \"Dockerfile\"\n  platforms = [\"linux/amd64\", \"linux/arm64\"]\n  tags = [\"myapp:latest\"]\n}\n\ntarget \"debug\" {\n  inherits = [\"app\"]\n  dockerfile = \"Dockerfile.debug\"\n  tags = [\"myapp:debug\"]\n}\n</code></pre> <p>Build using bake:</p> <pre><code>docker buildx bake\n</code></pre>"},{"location":"016-Advanced-Build/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>QEMU issues: Ensure QEMU is properly installed for cross-platform emulation</li> <li>Builder not found: Use <code>docker buildx create --use</code> to create a new builder</li> <li>Platform not supported: Check available platforms with <code>docker buildx inspect --bootstrap</code></li> <li>Build failures: Use <code>--progress=plain</code> for detailed build output</li> </ul>"},{"location":"016-Advanced-Build/#cleanup","title":"Cleanup","text":"<pre><code># Remove builder\ndocker buildx rm multi-platform-builder\n\n# Clean up images\ndocker image rm myapp:multi multi-platform-node:latest\n</code></pre> <p>This lab demonstrates the power of BuildKit and BuildX for advanced Docker builds, enabling efficient and multi-platform container development.</p>"},{"location":"100-Hands-On/","title":"100-Hands-On","text":""},{"location":"100-Hands-On/#lab-100-basic-docker-hands-on","title":"Lab 100 - Basic Docker Hands-On","text":"<ul> <li>In this lab we will create a simple NodeJs server and run it inside a docker container. </li> <li>Next, we will create a second container which will print some text to the screen. </li> <li>We will also create a docker hub account and push our images to the cloud.</li> </ul>"},{"location":"100-Hands-On/#table-of-contents","title":"Table of Contents","text":"<ul> <li>1. Verify Docker installation</li> <li>2. Building our NodeJs server</li> <li>3. Test our server code</li> <li>3.1. Test if the server is running</li> <li>3.2. Stop the server</li> <li>4. Creating Docker containers</li> <li>4.1. Create <code>Dockerfile</code></li> <li>5. Build the Docker image</li> <li>5.1. Verifying that the container was created</li> <li>5.2. Testing the image</li> <li>5.3 Test if the server is running and listening:</li> <li>6. Container with arguments</li> </ul>"},{"location":"100-Hands-On/#1-verify-docker-installation","title":"1. Verify Docker installation","text":"<ul> <li>Run the following command in the shell to verify that Docker is installed and running</li> </ul> <pre><code>docker run node\n</code></pre>"},{"location":"100-Hands-On/#2-building-our-nodejs-server","title":"2. Building our NodeJs server","text":"<ul> <li>In this section we will create a simple NodeJs server and later on we will run it inside a docker container.</li> <li>First, we will create a folder for our server code and then we will create the server code file.</li> </ul> <pre><code># Create the desired folder\nmkdir hello-docker\n# Switch to the created directory\ncd hello-docker\n</code></pre> <ul> <li>Create our server code file (copy the code into this file) <code>server.js</code></li> </ul> <pre><code>// import the HTTP module\nvar http = require('http');\n\n// Define a port we want to listen to\nconst PORT=8080;\n\n// We need a function which handles requests and send response\nfunction handleRequest(request, response){\n  response.end('It Works!! Path Hit: ' + request.url);\n}\n\n// Create a server\nvar server = http.createServer(handleRequest);\n\n// Start our server\nserver.listen(PORT, function(){\n  //Callback triggered when server is successfully listening. Hurray!\n  console.log(\"Server listening on: http://localhost:%s\", PORT);\n});\n</code></pre>"},{"location":"100-Hands-On/#3-test-our-server-code","title":"3. Test our server code","text":"<ul> <li>You can run the server code using NodeJs by executing the following command.</li> <li>This will run the server and listen to port 8080</li> </ul> <pre><code>node server.js\n</code></pre>"},{"location":"100-Hands-On/#31-test-if-the-server-is-running","title":"3.1. Test if the server is running","text":"<ul> <li>If you are using Cloud Shell, you can test it by clicking on the most left icon (web preview) and open port 8080 which is our server port</li> <li>If you are running it locally, you can test it by opening your browser </li> <li>Use the following URL in your browser <code>http://localhost:8080</code></li> <li>You should see the following message in your browser or terminal   <pre><code>It Works!! Path Hit: /\n</code></pre></li> </ul>"},{"location":"100-Hands-On/#32-stop-the-server","title":"3.2. Stop the server","text":"<ul> <li>Type CTRL+C twice to stop the server</li> </ul>"},{"location":"100-Hands-On/#4-creating-docker-containers","title":"4. Creating Docker containers","text":""},{"location":"100-Hands-On/#41-create-dockerfile","title":"4.1. Create <code>Dockerfile</code>","text":"<ul> <li>In the same folder create the create a file called <code>Dockerfile</code> and add the following content:   <pre><code># Base image for Node.js\nFROM node:latest\n\n# Set the working directory in the container\nWORKDIR /usr/src/app\n\n# Copy the server file into the container \n# (Don`t forget the dot at the end)\nCOPY server.js .\n\n# Expose port 8080\n# This is the port our server will listen to\nEXPOSE 8080\n\n# Start the Node.js server\nCMD [ \"node\", \"server.js\" ]\n</code></pre></li> <li>This Dockerfile does the following:</li> <li>Uses the latest Node.js image as the base image</li> <li>Sets the working directory inside the container to <code>/usr/src/app</code></li> <li>Copies the <code>server.js</code> file from the current directory into the container\u2019s working directory</li> <li>Exposes port 8080 so that it can be accessed from outside the container</li> <li>Specifies the command to run when the container starts, which is <code>node server.js</code></li> </ul> <p>[!NOTE]  Make sure that the <code>Dockerfile</code> is in the same directory as the <code>server.js</code> file.</p> <p>[!IMPORTANT]  The <code>COPY</code> command in the Dockerfile is used to copy files from the host machine into the container. The first argument is the source file (in this case, <code>server.js</code>), and the second argument is the destination path inside the container (<code>.</code> means the current working directory in the container).</p>"},{"location":"100-Hands-On/#5-build-the-docker-image","title":"5. Build the Docker image","text":"<ul> <li> <p>In this step we will build the Docker image using the <code>Dockerfile</code> we created in the previous step.</p> <p>[!IMPORTANT]  Make sure you are in the same directory where the <code>Dockerfile</code> and <code>server.js</code> files are located.</p> </li> <li> <p>Build the image using docker build with the following parameters   <pre><code>--t = Tag name which will be attached to the container\n.   = The Context to the Dockerfile (current folder in our case)\n\n# Sample command to build the image\ndocker build -t hello-node:v1 .\n</code></pre></p> </li> </ul>"},{"location":"100-Hands-On/#51-verifying-that-the-container-was-created","title":"5.1. Verifying that the container was created","text":"<ul> <li>Let\u2019s verify that the image was created successfully by listing all the images on our system</li> <li>Run the following command to list all Docker images:   <pre><code>docker images\n</code></pre></li> <li>You should see an output similar to this:   <pre><code>REPOSITORY          TAG       IMAGE ID       CREATED          SIZE\nhello-node          v1        123456789abc   10 seconds ago   200MB\nnode                latest    abcdef123456   2 days ago       150MB\n</code></pre></li> </ul>"},{"location":"100-Hands-On/#52-testing-the-image","title":"5.2. Testing the image","text":"<ul> <li>Now we can run the container using the image we just created</li> <li>Execute <code>docker run</code> command with the following flags:</li> </ul> Option Description <code>-d</code> Run container in background (daemon mode) <code>-p</code> Map internal port 8080 to external port 8080 <code>hello-node:v1</code> The name of the image we just created <pre><code># Run the container in the background\ndocker run -d -p 8080:8080 hello-node:v1\n</code></pre>"},{"location":"100-Hands-On/#53-test-if-the-server-is-running-and-listening","title":"5.3 Test if the server is running and listening:","text":"<ul> <li>If you are using Cloud Shell, you can test it by clicking on the most left icon (web preview) and open port <code>8080</code> which is our server port</li> <li>If you are running it locally, you can test it by opening your browser </li> <li>Use the following URL in your browser <code>http://localhost:8080</code></li> <li>You should see the following message in your browser or terminal   <pre><code>It Works!! Path Hit: /\n</code></pre></li> </ul>"},{"location":"100-Hands-On/#6-container-with-arguments","title":"6. Container with arguments","text":"<ul> <li>Let\u2019s test another container which will print content to screen</li> </ul> <p>[!WARNING] You might get the following error:</p> <p>docker: [DEPRECATION NOTICE] Docker Image Format v1 and Docker Image manifest version 2, schema 1 support is disabled by default and will be removed in an upcoming release.</p> <ul> <li>Run the following command to run a container with arguments   <pre><code>docker run docker/whalesay cowsay boo\n</code></pre></li> <li>You should see the following output in your terminal   <pre><code>________\n&lt; boo &gt;\n--------\n        \\  ^__^\n        \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n</code></pre></li> </ul>"},{"location":"Tasks/","title":"DockerLabs Tasks","text":"<ul> <li>Welcome to the DockerLabs Tasks section.</li> <li>Each folder below contains a hands-on task/exercise that you can complete independently to practice specific Docker skills.</li> <li>Follow the README file in each task for detailed instructions and solutions.</li> </ul>"},{"location":"Tasks/#task-index","title":"Task Index","text":""},{"location":"Tasks/#docker-cli-tasks","title":"Docker CLI Tasks","text":"Task Description DockerCommit In-class exercise for capturing container changes with <code>docker commit</code>. DockerDebug Debugging challenge: troubleshoot a crashing Flask container and fix missing configurations. DockerLogs In-class exercise for running cowsay container, managing logs, and debugging."},{"location":"Tasks/#dockerfile-tasks","title":"Dockerfile Tasks","text":"Task Description DockerfileAdvanced Advanced Dockerfile exercise covering build arguments, parameterized ports, and Node.js time server. MultiStage In-class exercise for creating multi-stage Dockerfiles with alpine and node images. <p>Happy learning and hacking with Docker!</p>"},{"location":"Tasks/DockerCLI/DockerCommit/","title":"DockerCommit","text":""},{"location":"Tasks/DockerCLI/DockerCommit/#in-class-exercise-docker-commit-workflow","title":"In-Class Exercise - Docker Commit Workflow","text":"<ul> <li>Start an <code>alpine</code> container and keep it running for modifications</li> <li>Create a new file inside the running container</li> <li>Use <code>docker commit</code> to capture a new image with the file included</li> <li>Run a container from the committed image and verify the file exists</li> <li>Hint: Combine <code>docker run</code>, <code>docker exec</code>, <code>docker commit</code>, and <code>docker run --rm</code></li> </ul> Solution"},{"location":"Tasks/DockerCLI/DockerCommit/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Run a modifiable alpine container</li> </ol> <pre><code>docker run -d --name alpine-commit alpine:latest sleep infinity\n</code></pre> <ol> <li>Write a file inside the running container</li> </ol> <pre><code>docker exec alpine-commit sh -c \"echo 'Persisted with docker commit' &gt; /opt/commit-note.txt\"\n</code></pre> <ol> <li>Validate the file inside the original container (optional check)</li> </ol> <pre><code>docker exec alpine-commit cat /opt/commit-note.txt\n</code></pre> <ol> <li>Create a new image from the modified container</li> </ol> <pre><code>docker commit alpine-commit alpine-with-note:latest\n</code></pre> <ol> <li>Run a container from the committed image and verify the file exists</li> </ol> <pre><code>docker run --rm alpine-with-note:latest cat /opt/commit-note.txt\n</code></pre> <p>Expected output:</p> <pre><code>Persisted with docker commit\n</code></pre> <ol> <li>Clean up resources</li> </ol> <pre><code>docker rm -f alpine-commit\ndocker image rm alpine-with-note:latest\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerCommit/#explanation","title":"Explanation","text":"<ul> <li>docker run -d \u2026 sleep infinity: Starts a container that stays alive for edits</li> <li>docker exec \u2026 echo \u2018\u2026\u2019 &gt; file: Writes a file into the running container</li> <li>docker commit: Captures the container\u2019s filesystem changes into a new image</li> <li>docker run \u2013rm new-image cat file: Launches the new image, verifies the persistent file, and removes the container when done</li> <li>Cleanup commands: Remove the temporary container and image to free resources</li> </ul>"},{"location":"Tasks/DockerCLI/DockerDebug/","title":"In-Class Exercise - Docker Container Debugging Challenge","text":""},{"location":"Tasks/DockerCLI/DockerDebug/#the-challenge","title":"The Challenge","text":"<p>A web application container is crashing immediately after startup, and you need to debug it using Docker tools and techniques. Your mission: identify the root cause and fix the issue without modifying the original Dockerfile until you\u2019ve diagnosed the problem.</p>"},{"location":"Tasks/DockerCLI/DockerDebug/#scenario","title":"Scenario","text":"<p>You\u2019ve inherited a Python Flask application that worked yesterday but now fails to start. The container exits with code 1, and you need to investigate:</p> <ul> <li>Why is the container crashing?</li> <li>What files or configurations are missing?</li> <li>How can you inspect a container that won\u2019t stay running?</li> <li>Can you fix it interactively before updating the Dockerfile?</li> </ul>"},{"location":"Tasks/DockerCLI/DockerDebug/#task-checklist","title":"Task Checklist","text":"<ul> <li>Build the provided broken Docker image</li> <li>Attempt to run it and observe the failure</li> <li>Use Docker debugging techniques to inspect the crashed container</li> <li>Override the entrypoint to keep the container alive for investigation</li> <li>Explore the filesystem and identify the missing configuration file</li> <li>Fix the issue interactively and verify the application works</li> <li>Update the Dockerfile with the permanent fix</li> <li>Document your debugging process</li> </ul>"},{"location":"Tasks/DockerCLI/DockerDebug/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Identify the root cause without looking at the solution first</li> <li>Successfully get the application running using debugging techniques</li> <li>Demonstrate at least two different debugging methods (e.g., <code>docker logs</code>, entrypoint override, <code>docker exec</code>)</li> <li>Apply a permanent fix to the Dockerfile</li> </ul>"},{"location":"Tasks/DockerCLI/DockerDebug/#tips","title":"Tips","text":"<ul> <li><code>docker logs &lt;container&gt;</code> shows output even from crashed containers</li> <li><code>docker run --entrypoint /bin/sh</code> can override the startup command</li> <li><code>docker exec</code> requires a running container, but <code>docker run -it</code> with an overridden entrypoint keeps it alive</li> <li>The <code>--rm</code> flag is helpful during debugging to avoid container clutter</li> <li>Use <code>docker inspect</code> to see container configuration and state</li> </ul> Solution"},{"location":"Tasks/DockerCLI/DockerDebug/#broken-application-files","title":"Broken Application Files","text":""},{"location":"Tasks/DockerCLI/DockerDebug/#apppy","title":"<code>app.py</code>","text":"<pre><code>from flask import Flask\nimport json\n\napp = Flask(__name__)\n\n# Load configuration\nwith open('/app/config.json', 'r') as f:\n    config = json.load(f)\n\n@app.route('/')\ndef hello():\n    return f\"Hello from {config['app_name']}! Running on port {config['port']}\\n\"\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=config['port'])\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#requirementstxt","title":"<code>requirements.txt</code>","text":"<pre><code>Flask==3.0.0\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#dockerfile-broken-version","title":"<code>Dockerfile</code> (Broken Version)","text":"<pre><code># syntax=docker/dockerfile:1\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY app.py .\n\n# Missing: config.json is NOT copied!\n\nEXPOSE 5000\n\nCMD [\"python\", \"app.py\"]\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#step-by-step-debugging-solution","title":"Step-by-Step Debugging Solution","text":""},{"location":"Tasks/DockerCLI/DockerDebug/#1-build-the-broken-image","title":"1. Build the Broken Image","text":"<pre><code>docker build -t broken-flask-app .\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#2-attempt-to-run-this-will-fail","title":"2. Attempt to Run (This Will Fail)","text":"<pre><code>docker run --rm --name flask-debug -p 5000:5000 broken-flask-app\n</code></pre> <p>Observation: Container exits immediately with error.</p>"},{"location":"Tasks/DockerCLI/DockerDebug/#3-check-the-logs","title":"3. Check the Logs","text":"<pre><code># If using --rm, run without it first to preserve the container\ndocker run --name flask-debug -p 5000:5000 broken-flask-app\n\n# In another terminal\ndocker logs flask-debug\n</code></pre> <p>Expected Output:</p> <pre><code>Traceback (most recent call last):\n  File \"/app/app.py\", line 6, in &lt;module&gt;\n    with open('/app/config.json', 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/app/config.json'\n</code></pre> <p>Diagnosis: Missing <code>config.json</code> file!</p>"},{"location":"Tasks/DockerCLI/DockerDebug/#4-debug-by-overriding-the-entrypoint","title":"4. Debug by Overriding the Entrypoint","text":"<pre><code>docker run --rm -it --entrypoint /bin/sh broken-flask-app\n</code></pre> <p>Inside the container:</p> <pre><code>ls -la /app/\n# Shows: app.py, requirements.txt - but NO config.json!\n\n# Verify Python can't find it\npython -c \"open('/app/config.json')\"\n# Error: No such file or directory\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#5-create-the-missing-configuration-file","title":"5. Create the Missing Configuration File","text":"<p>Create <code>config.json</code> locally:</p> <pre><code>{\n  \"app_name\": \"Flask Debug Demo\",\n  \"port\": 5000\n}\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#6-fix-interactively-with-volume-mount","title":"6. Fix Interactively with Volume Mount","text":"<pre><code># Mount the config file into the container for testing\ndocker run --rm -p 5000:5000 \\\n  -v $(pwd)/config.json:/app/config.json \\\n  broken-flask-app\n</code></pre> <p>Test the application:</p> <pre><code>curl http://localhost:5000\n</code></pre> <p>Expected Output:</p> <pre><code>Hello from Flask Debug Demo! Running on port 5000\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#7-apply-permanent-fix-to-dockerfile","title":"7. Apply Permanent Fix to Dockerfile","text":"<pre><code># syntax=docker/dockerfile:1\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY app.py .\nCOPY config.json .\n\nEXPOSE 5000\n\nCMD [\"python\", \"app.py\"]\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#8-rebuild-and-verify","title":"8. Rebuild and Verify","text":"<pre><code>docker build -t fixed-flask-app .\ndocker run --rm -p 5000:5000 fixed-flask-app\n</code></pre> <p>Test again:</p> <pre><code>curl http://localhost:5000\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#9-cleanup","title":"9. Cleanup","text":"<pre><code>docker rm -f flask-debug  # If you created it without --rm\ndocker image rm broken-flask-app fixed-flask-app\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerDebug/#key-debugging-techniques-demonstrated","title":"Key Debugging Techniques Demonstrated","text":"<ol> <li>Container Logs: <code>docker logs &lt;container&gt;</code> - View stdout/stderr from crashed containers</li> <li>Entrypoint Override: <code>docker run --entrypoint /bin/sh</code> - Start a shell instead of the app</li> <li>Interactive Exploration: <code>docker run -it</code> - Explore the container filesystem</li> <li>Volume Mounting: <code>-v</code> flag - Test fixes without rebuilding</li> <li>Container Inspection: <code>docker inspect &lt;container&gt;</code> - View full container config</li> <li>Process Monitoring: <code>docker top &lt;container&gt;</code> - See running processes (if container stays up)</li> </ol>"},{"location":"Tasks/DockerCLI/DockerDebug/#common-docker-debugging-commands-reference","title":"Common Docker Debugging Commands Reference","text":"<pre><code># View logs from a stopped container\ndocker logs &lt;container&gt;\n\n# Start container with shell access\ndocker run --rm -it --entrypoint /bin/sh &lt;image&gt;\n\n# Execute command in running container\ndocker exec -it &lt;container&gt; /bin/sh\n\n# Inspect container configuration\ndocker inspect &lt;container&gt;\n\n# View container filesystem changes\ndocker diff &lt;container&gt;\n\n# Copy files from container to host\ndocker cp &lt;container&gt;:/path/to/file ./local-path\n\n# View container resource usage\ndocker stats &lt;container&gt;\n\n# See running processes\ndocker top &lt;container&gt;\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerLogs/","title":"DockerLogs","text":""},{"location":"Tasks/DockerCLI/DockerLogs/#in-class-exercise-docker-logs-and-container-management","title":"In-Class Exercise - Docker Logs and Container Management","text":"<ul> <li>Run a <code>cowsay</code> Docker container with a custom message</li> <li>Send a message to the cowsay container (e.g., \u201cHello from Docker!\u201d)</li> <li>Stop the container after execution</li> <li>Extract and save the container logs to the host machine for debugging purposes</li> <li>Hint: Use <code>docker run</code>, <code>docker logs</code>, and output redirection</li> </ul> Solution"},{"location":"Tasks/DockerCLI/DockerLogs/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Run the cowsay container with a custom message</li> </ol> <pre><code>docker run --name my-cowsay docker/whalesay cowsay \"Hello from Docker!\"\n</code></pre> <ol> <li>Verify the container has stopped</li> </ol> <p>The container stops automatically after execution. You can verify with:</p> <pre><code>docker ps -a | grep my-cowsay\n</code></pre> <ol> <li>Grab the logs and save to host machine</li> </ol> <pre><code>docker logs my-cowsay &gt; cowsay-logs.txt\n</code></pre> <ol> <li>View the saved logs</li> </ol> <pre><code>cat cowsay-logs.txt\n</code></pre> <p>Expected output in <code>cowsay-logs.txt</code>:</p> <pre><code> ______________________\n&lt; Hello from Docker! &gt;\n ----------------------\n    \\\n     \\\n      \\     \n                    ##        .            \n              ## ## ##       ==            \n           ## ## ## ##      ===            \n       /\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"___/ ===        \n  ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ /  ===- ~~~   \n       \\______ o          __/            \n        \\    \\        __/             \n          \\____\\______/   \n</code></pre> <ol> <li>Clean up (optional)</li> </ol> <pre><code># Remove the container\ndocker rm my-cowsay\n\n# Remove the log file\nrm cowsay-logs.txt\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerLogs/#alternative-using-a-different-cowsay-image","title":"Alternative: Using a Different Cowsay Image","text":"<p>If <code>docker/whalesay</code> is not available, you can build your own:</p> <p>Dockerfile:</p> <pre><code>FROM alpine:latest\nRUN apk add --no-cache cowsay\nENTRYPOINT [\"/usr/bin/cowsay\"]\nCMD [\"Hello Docker!\"]\n</code></pre> <p>Build and run:</p> <pre><code>docker build -t my-cowsay .\ndocker run --name cowsay-test my-cowsay \"Hello from Docker!\"\ndocker logs cowsay-test &gt; cowsay-logs.txt\n</code></pre>"},{"location":"Tasks/DockerCLI/DockerLogs/#explanation","title":"Explanation","text":"<ul> <li>docker run \u2013name: Assigns a name to the container for easy reference</li> <li>cowsay \u201cmessage\u201d: Passes the message to the cowsay command</li> <li>docker logs: Retrieves all stdout/stderr output from the container</li> <li>&gt; cowsay-logs.txt: Redirects the log output to a file on the host machine</li> <li>The container stops automatically after the command completes</li> </ul>"},{"location":"Tasks/DockerCLI/DockerLogs/#bonus-running-in-detached-mode","title":"Bonus: Running in Detached Mode","text":"<p>For containers that run longer:</p> <pre><code># Run in detached mode\ndocker run -d --name my-cowsay-bg docker/whalesay /bin/sh -c \"cowsay 'Background task' &amp;&amp; sleep 30\"\n\n# Get logs while running\ndocker logs my-cowsay-bg\n\n# Follow logs in real-time\ndocker logs -f my-cowsay-bg\n\n# Stop the container\ndocker stop my-cowsay-bg\n\n# Save logs after stopping\ndocker logs my-cowsay-bg &gt; cowsay-bg-logs.txt\n</code></pre>"},{"location":"Tasks/DockerFile/DockerfileAdvanced/","title":"In-Class Exercise - Parameterized Node.js Time Server","text":"<p>Build a lightweight Node.js web server image that prints the current time and listens on a build-time configurable port.</p>"},{"location":"Tasks/DockerFile/DockerfileAdvanced/#task-checklist","title":"Task Checklist","text":"<ul> <li>Use the minimal Node.js HTTP server (<code>server.js</code>) in the task folder.</li> <li>Use a Docker build argument to set the port value (<code>LISTEN_PORT</code>) and use it in the DockerFile</li> <li>Verify that the container print the message when it called</li> </ul> <p>Requirements &amp;&amp; Tips</p> <ul> <li><code>docker build</code> accepts <code>--build-arg LISTEN_PORT=&lt;port&gt;</code> and succeeds without manual edits</li> <li>Running the image with <code>docker run --rm -p &lt;port&gt;:&lt;port&gt;</code> serves the current time on the chosen port</li> <li>Changing <code>LISTEN_PORT</code> during build changes both the exposed port in the image metadata and the runtime listener</li> <li>The container process logs which port it is using when it starts</li> <li>Use <code>ARG</code> in the Dockerfile to capture the build-time value and <code>ENV</code> to pass it to the Node.js process</li> <li>Always bind to <code>0.0.0.0</code> so Docker can forward traffic into the container</li> <li>A <code>curl</code> request or <code>docker run --rm image curl http://localhost:&lt;port&gt;</code> is a quick way to verify the response</li> </ul> <p>Additional Task</p> <ul> <li>Once you have completed the task, change the port and test it again to ensure the server responds on the new port.</li> </ul> Solution"},{"location":"Tasks/DockerFile/DockerfileAdvanced/#1-project-files","title":"1. Project Files","text":"<p><code>server.js</code></p> <pre><code>const http = require(\"http\");\n\nconst requestedPort = parseInt(process.env.LISTEN_PORT || \"8080\", 10);\nconst port = Number.isNaN(requestedPort) ? 8080 : requestedPort;\n\nconst server = http.createServer((req, res) =&gt; {\n  const message = `Current time: ${new Date().toISOString()}\\n`;\n  res.writeHead(200, { \"Content-Type\": \"text/plain\" });\n  res.end(message);\n});\n\nserver.listen(port, \"0.0.0.0\", () =&gt; {\n  console.log(`Listening on port ${port}`);\n});\n</code></pre> <p><code>Dockerfile</code></p> <pre><code># syntax=docker/dockerfile:1\nFROM node:20-alpine\n\nARG LISTEN_PORT=8080\n\nWORKDIR /usr/src/app\n\nCOPY server.js ./\n\nENV LISTEN_PORT=${LISTEN_PORT}\n\nEXPOSE ${LISTEN_PORT}\n\nCMD [\"node\", \"server.js\"]\n</code></pre>"},{"location":"Tasks/DockerFile/DockerfileAdvanced/#2-build-the-image","title":"2. Build the Image","text":"<pre><code>docker build --build-arg LISTEN_PORT=9090 -t node-time-server .\n</code></pre>"},{"location":"Tasks/DockerFile/DockerfileAdvanced/#3-run-and-test","title":"3. Run and Test","text":"<pre><code>docker run --rm -p 9090:9090 node-time-server\n</code></pre> <p>In another terminal, verify the output:</p> <pre><code>curl http://localhost:9090\n</code></pre> <p>Expected response:</p> <pre><code>Current time: 2025-10-26T12:34:56.789Z\n</code></pre>"},{"location":"Tasks/DockerFile/MultiStage/","title":"MultiStage","text":""},{"location":"Tasks/DockerFile/MultiStage/#in-class-exercise-multi-stage-dockerfile","title":"In-Class Exercise - Multi-Stage Dockerfile","text":"<ul> <li>Create a <code>multi-stage</code> docker file that will build 2 images</li> <li>The first image will be based on <code>alpine</code> and will create a file named <code>alpine.txt</code> with the content: <code>This is alpine image</code></li> <li>The second image will be based on <code>node</code> and will create a file named <code>node.txt</code> with the content: <code>This is node image</code></li> <li>The final image should be based on <code>alpine</code> and should copy the files which you created from the previous stages and display their content when the container will run.</li> <li>Hint: Use the <code>COPY --from=</code> command to copy files from previous stages</li> </ul> Solution"},{"location":"Tasks/DockerFile/MultiStage/#dockerfile-solution","title":"Dockerfile Solution","text":"<p>Create a file named <code>Dockerfile-exercise</code>:</p> <pre><code># First stage: Alpine image\nFROM  alpine AS alpine-stage\nRUN   echo \"This is alpine image\" &gt; alpine.txt\n\n# Second stage: Node image\nFROM  node AS node-stage\nRUN   echo \"This is node image\" &gt; node.txt\n\n# Final stage: Alpine with files from previous stages\nFROM  alpine\nCOPY  --from=alpine-stage alpine.txt  .\nCOPY  --from=node-stage node.txt      .\n\n# Run the command to display contents\nCMD   cat alpine.txt &amp;&amp; cat node.txt\n</code></pre>"},{"location":"Tasks/DockerFile/MultiStage/#build-and-test","title":"Build and Test","text":"<p>Build the image:</p> <pre><code>docker build -f Dockerfile-exercise -t exercise-solution .\n</code></pre> <p>Run the container:</p> <pre><code>docker run exercise-solution\n</code></pre> <p>Expected output:</p> <pre><code>This is alpine image\nThis is node image\n</code></pre>"},{"location":"Tasks/DockerFile/MultiStage/#explanation","title":"Explanation","text":"<ol> <li>First Stage (alpine-stage): Based on <code>alpine</code>, creates <code>alpine.txt</code> with the required content</li> <li>Second Stage (node-stage): Based on <code>node</code>, creates <code>node.txt</code> with the required content</li> <li>Final Stage: Based on <code>alpine</code> (lightweight), copies both files from previous stages using <code>COPY --from=&lt;stage-name&gt;</code> and displays their content when run</li> </ol>"}]}